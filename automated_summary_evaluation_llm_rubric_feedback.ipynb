{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16rzCEir-3WyU2xJobpiuSnjGvjfBtkDB",
      "authorship_tag": "ABX9TyODowjSPQUvG/BLZ270ysko",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baker-jr-john/automated-summary-evaluation-llm/blob/main/automated_summary_evaluation_llm_rubric_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P_OlYgvXG2jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83577661-c5a3-4b6c-b699-12c84fecfd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Columns: ['essay_id', 'score', 'full_text', 'assignment', 'prompt_name', 'economically_disadvantaged', 'student_disability_status', 'ell_status', 'race_ethnicity', 'gender', 'source_text_1', 'source_text_2', 'source_text_3', 'source_text_4']\n",
            "\n",
            "Shape: (24728, 14)\n",
            "\n",
            "First few rows:\n",
            "               essay_id  score  \\\n",
            "0  AAAVUP14319000159574      4   \n",
            "1  AAAVUP14319000159542      2   \n",
            "2  AAAVUP14319000159461      3   \n",
            "3  AAAVUP14319000159420      2   \n",
            "4  AAAVUP14319000159419      2   \n",
            "\n",
            "                                           full_text  \\\n",
            "0  The author suggests that studying Venus is wor...   \n",
            "1  NASA is fighting to be alble to to go to Venus...   \n",
            "2  \"The Evening Star\", is one of the brightest po...   \n",
            "3  The author supports this idea because from rea...   \n",
            "4  How the author supports this idea is that he s...   \n",
            "\n",
            "                                          assignment      prompt_name  \\\n",
            "0  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "1  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "2  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "3  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "4  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "\n",
            "       economically_disadvantaged            student_disability_status  \\\n",
            "0      Economically disadvantaged      Identified as having disability   \n",
            "1  Not economically disadvantaged  Not identified as having disability   \n",
            "2      Economically disadvantaged      Identified as having disability   \n",
            "3      Economically disadvantaged  Not identified as having disability   \n",
            "4      Economically disadvantaged  Not identified as having disability   \n",
            "\n",
            "  ell_status          race_ethnicity gender  \\\n",
            "0         No  Black/African American      F   \n",
            "1         No         Hispanic/Latino      F   \n",
            "2         No                   White      M   \n",
            "3        Yes         Hispanic/Latino      F   \n",
            "4        Yes         Hispanic/Latino      M   \n",
            "\n",
            "                                       source_text_1 source_text_2  \\\n",
            "0  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "1  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "2  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "3  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "4  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "\n",
            "  source_text_3 source_text_4  \n",
            "0           NaN           NaN  \n",
            "1           NaN           NaN  \n",
            "2           NaN           NaN  \n",
            "3           NaN           NaN  \n",
            "4           NaN           NaN  \n",
            "\n",
            "Unique prompts:\n",
            "prompt_name\n",
            "Driverless cars                     6170\n",
            "Facial action coding system         4883\n",
            "Exploring Venus                     4480\n",
            "The Face on Mars                    3015\n",
            "\"A Cowboy Who Rode the Waves\"       2175\n",
            "Does the electoral college work?    2046\n",
            "Car-free cities                     1959\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Score distribution:\n",
            "score\n",
            "1    1751\n",
            "2    6847\n",
            "3    9021\n",
            "4    5553\n",
            "5    1356\n",
            "6     200\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Load the dataset - use comma separator (default for CSV)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                 encoding='ISO-8859-1')\n",
        "\n",
        "# Explore the structure\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"\\nShape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check what types of assignments/prompts exist\n",
        "print(\"\\nUnique prompts:\")\n",
        "print(df['prompt_name'].value_counts())\n",
        "\n",
        "# Look at score distribution\n",
        "print(\"\\nScore distribution:\")\n",
        "print(df['score'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the actual assignment prompts to understand task types\n",
        "print(\"=\" * 80)\n",
        "for prompt in df['prompt_name'].unique():\n",
        "    subset = df[df['prompt_name'] == prompt]\n",
        "    print(f\"\\n{prompt} ({len(subset)} responses)\")\n",
        "    print(f\"Score range: {subset['score'].min()}-{subset['score'].max()}\")\n",
        "    print(\"\\nAssignment:\")\n",
        "    print(subset['assignment'].iloc[0][:300] + \"...\")  # First 300 chars\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "JVwaIb36Fmr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9919b10-5329-4e21-dec3-3d35424961cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "\n",
            "Exploring Venus (4480 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "In \"The Challenge of Exploring Venus,\" the author suggests studying Venus is a worthy pursuit despite the dangers it presents. Using details from the article, write an essay evaluating how well the author supports this idea. Be sure to include: a claim that evaluates how well the author supports the...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Facial action coding system (4883 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "In the article \"Making Mona Lisa Smile,\" the author describes how a new technology called the Facial Action Coding System enables computers to identify human emotions. Using details from the article, write an essay arguing whether the use of this technology to read the emotional expressions of stude...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "The Face on Mars (3015 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "You have read the article 'Unmasking the Face on Mars.' Imagine you are a scientist at NASA discussing the Face with someone who thinks it was created by aliens. Using information in the article, write an argumentative essay to convince someone that the Face is just a natural landform.Be sure to inc...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\"A Cowboy Who Rode the Waves\" (2175 responses)\n",
            "Score range: 1-5\n",
            "\n",
            "Assignment:\n",
            "You have just read the article, 'A Cowboy Who Rode the Waves.' Luke's participation in the Seagoing Cowboys program allowed him to experience adventures and visit many unique places. Using information from the article, write an argument from Luke's point of view convincing others to participate in t...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Driverless cars (6170 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "In the article √¢¬Ä¬úDriverless Cars are Coming,√¢¬Ä¬ù the author presents both positive and negative aspects of driverless cars. Using details from the article, create an argument for or against the development of these cars.  Be sure to include: your position on driverless cars; appropriate details from...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Does the electoral college work? (2046 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Car-free cities (1959 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise a...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for Exploring Venus responses\n",
        "venus_df = df[df['prompt_name'] == 'Exploring Venus'].copy()\n",
        "\n",
        "print(f\"Total Venus responses: {len(venus_df)}\")\n",
        "print(f\"\\nScore distribution:\")\n",
        "print(venus_df['score'].value_counts().sort_index())\n",
        "\n",
        "# Look at the source text\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SOURCE TEXT:\")\n",
        "print(\"=\"*80)\n",
        "print(venus_df['source_text_1'].iloc[0])\n",
        "\n",
        "# Examine sample responses across score levels\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAMPLE RESPONSES BY SCORE LEVEL:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for score in sorted(venus_df['score'].unique()):\n",
        "    print(f\"\\n--- SCORE {score} EXAMPLE ---\")\n",
        "    sample = venus_df[venus_df['score'] == score].iloc[0]\n",
        "    print(sample['full_text'][:400] + \"...\")"
      ],
      "metadata": {
        "id": "BrHaKRsxGigk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d52af7f-777b-416a-bd9e-d2de5e5d6a74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Venus responses: 4480\n",
            "\n",
            "Score distribution:\n",
            "score\n",
            "1     567\n",
            "2    1419\n",
            "3    1469\n",
            "4     808\n",
            "5     175\n",
            "6      42\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n",
            "SOURCE TEXT:\n",
            "================================================================================\n",
            "The Challenge of Exploring Venus\n",
            "Venus, sometimes called the √¢¬Ä¬úEvening Star,√¢¬Ä¬ù is one of the brightest points of light in the night sky, making it simple for even and amateur stargazer to spot. However, this nickname is misleading since Venus is actually a planet. While Venus is simple to see from the distant but safe vantage point of Earth, it has proved a very challenging place to examine more closely. \n",
            "Often referred to as Earth's √¢¬Ä¬útwin,√¢¬Ä¬ù Venus is the closest planet to Earth in terms of density and size, and occasionally the closest in distance too. Earth, Venus, and Mars, our other planetary neighbor, orbit the sun at different speeds. These differences in speed mean that sometimes we are closer to Mars and other times to Venus. Because Venus is sometimes right around the corner - in space terms - humans have spent numerous spacecraft to land on this cloud-draped world. Each previous mission was unmanned, and for good reason, since no spacecraft survived the landing for more than a few hours. Maybe this issue explains why not a single spaceship has touched down of Venus in more than three decades. Numberous factors contribute to Venus's reputation as a challenging planet for humans to study, despite its proximity to us. \n",
            "A thick atmosphere of almost 97 percent carbon dioxide blankets Venus. Even more challenging are the clouds of highly corrosive sulfuric acid in Venus's atmosphere. On the planet's surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet. These conditions are far more extreme than anything humans encounter on Earth; such an environment would crush even a submarine accustomed to diving to the deepest parts of our oceans and would liquefy many metals. Also notable, Venus has the hottest surface temperature of any planet in our solar system, even though Mercury is closer to our sun. Beyond high presure and heat, Venusian geology and weather present additional impediments like erupting volcanoes, powerful earthquakes, and frequent lightning strikes to probes seeking to land on its surface. \n",
            "If our sister is so inhospitable, why are scientists even discussing further visits to its surface? Astronomers are fascinated by Venus beccause it may well once have been the most Earth-like planet in our solar system. Long ago, Venus was probably covered largely with oceans and could have supported various forms of life, just like Earth. Today, Venus still has some features that are analogous to those on Earth. The planet has a surface of rocky sediment and includes familiar features such as valleys, mountains, and craters. Furthermore, recall that Venus can sometimes be our nearest option for a planetary visit, a crucial consideration given the long time frames of space travel. The value of returning to Venus seems indisputable, but what are the options for making such a mission both safe and scientifically productive?\n",
            "The National Aeronautics and Space Administration (NASA) has one particularly compelling idea for sending humans to study Venus. NASA's possible solution to the hostile conditions on the surface of Venus would allow scientists to float above the fray. Imagine a blimp-like vehicle hovering 30 or so miles above the roiling Venusian landscape. Just as our jet airplanes travel at a higher altitude to fly over many storms, a vehicle hovering over Venus would avoid the unfriendly ground conditions by staying up and out of their way. At thirty-plus miles above the surface, temperatures would still be toasty at around 170 degrees Farenheit, but the air pressure would be close to that of sea level on Earth. Solar power would be plentiful, and radiation would not exceed Earth levels. Not easy conditions, but survivable for humans.\n",
            "However, peering at Venus from a ship orbiting or hovering safely far above the planet can provide only limited insight on ground conditions rendering standard forms of photography and videography ineffective. More importantly, researchers cannot take samples of rock, gas, or anything else, from a distance. Therefore, scientists seeking to conduct a thorough mission to understand Venus would need to get up close and personal despite the risks. Or maybe we should think of them as challenges. Many researchers are working on innovattions that would allow our machines to last long enough to contribute meaningfully to our knowledge of Venus. \n",
            "NASA is working on other approaches to studying Venus. For example, some simplified electronics made of silicon carbide have been tested in a chamber simuulating the chaos of Venus's surface and have laster for three weeks in such conditions. Another project is looking back to an old technology called mechanical computers. These devices were first envisioned in the 1800s and played an important role int he 1940s during World War II. The thought of computers existing in those days may sound shocking, but these devices make calculations by using gears and levers and do not require electronics at all. Modern commputers are enormously powerful, flexible, and quick, but tend to be more delicate when it comes to extreme physical conditions. Just imagine exposing a cell phone or tablet to acid or heat capable of melting tin. By comparison, systems that use mechanical parts can be made mroe resistant to pressure, heat, and other forces. \n",
            "Striving to meet the challenge presented by Venus has value, not only because of the insight to be gained on the planet itself, but also because human curiousity will likely lead us into many equally intimidating endeavors. Our travels on Earth and beyond should not be limited by dangers and doubts but should be expanded to meet the very edges of imagination and innovation.\n",
            "\n",
            "================================================================================\n",
            "SAMPLE RESPONSES BY SCORE LEVEL:\n",
            "================================================================================\n",
            "\n",
            "--- SCORE 1 EXAMPLE ---\n",
            "In the story of √Ç¬®The Challenge of Exploring Venus√Ç¬® Venus is one of the brightest point of light in the night sky, It√Ç¬¥s also the second planet from our sun. From earth people can see Venus from a safe distance. The Earth has a planet that is closer to it and it√Ç¬¥s called Venus. Earth and Veus are often referred as twins. Venus has blanets of thick atmosphere of 97 percent carbon dioxide. The mor...\n",
            "\n",
            "--- SCORE 2 EXAMPLE ---\n",
            "NASA is fighting to be alble to to go to Venus . They have been researching diffrent methods on how to sustaine life on the planet . In the text it says that \"Our travels on earth and beyond should not be limited by dangers but should be expanded ..\"(8) Yes we are trying to figer out our planet earth still but there may be diffrent ways we can help explore the ocean and lower in the earths core .\n",
            "...\n",
            "\n",
            "--- SCORE 3 EXAMPLE ---\n",
            "\"The Evening Star\", is one of the brightest points of the light on the sky at night. Venus is a planet, Also Venus is the second planet\n",
            "\n",
            "from the sun. Venus is a simple to see from the distant but safe vantage point on Earth. It proved that a very challeging place to examine more closely on Earth. It is reffered to Earths twin. Venus is also the closeset planet to Earth and has density and size.\n",
            "\n",
            "...\n",
            "\n",
            "--- SCORE 4 EXAMPLE ---\n",
            "The author suggests that studying Venus is worthy enough even though it is very dangerous. The author mentioned that on the planet's surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet . His solution to survive this weather that is dangerous to us humans is to allow them to float above the fray. A \"bl...\n",
            "\n",
            "--- SCORE 5 EXAMPLE ---\n",
            "In the passage, \"The Challenge of Exploring Venus,\" the author supports that studying Venus is a worthy pursuit despite the dangers it presents. The author starts with facts about Venus to just bring general facts the the public in the passage. The author does not support his idea in the passage well. The author points out more dangers than he points out the reasons that pursuing Venus is a benefi...\n",
            "\n",
            "--- SCORE 6 EXAMPLE ---\n",
            "The author's claim of studying Venus is a worthy pursuit because Venus is closely related to Earth, Venus has a enviroment that is similar to Earth, and scientists want to explore more of what Venus has to offer.\n",
            "\n",
            "The first claim of why the author supports scientists studying Venus is that Venus is closely related to Earth. In the passage, it states,\" Often referred to as Earth's twin, Venus is th...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Calculate proportional samples (36 total based on original 6-point distribution)\n",
        "# Proportions: 1=13%, 2=32%, 3=33%, 4=18%, 5=4%, 6=1%\n",
        "samples_needed = {\n",
        "    1: 5,   # ~13% (567/4480)\n",
        "    2: 11,  # ~32% (1,419/4480)\n",
        "    3: 12,  # ~33% (1,469/4480)\n",
        "    4: 6,   # ~18% (808/4480)\n",
        "    5: 2,   # ~4% (175/4480)\n",
        "    6: 0    # ~1% (42/4480) - too few to sample reliably, we'll grab these separately\n",
        "}\n",
        "\n",
        "# For score 6, let's just include all available or sample very carefully\n",
        "# Since there are only 42 total, we could include 1-2 in the validation set\n",
        "\n",
        "sampled_rows = []\n",
        "for score, n_samples in samples_needed.items():\n",
        "    if n_samples > 0:\n",
        "        score_subset = venus_df[venus_df['score'] == score]\n",
        "        if len(score_subset) >= n_samples:\n",
        "            sample = score_subset.sample(n=n_samples, random_state=42)\n",
        "            sampled_rows.append(sample)\n",
        "\n",
        "# For score 6, sample 1 if we want to include it\n",
        "score_6_subset = venus_df[venus_df['score'] == 6]\n",
        "if len(score_6_subset) > 0:\n",
        "    score_6_sample = score_6_subset.sample(n=1, random_state=42)\n",
        "    sampled_rows.append(score_6_sample)\n",
        "\n",
        "venus_validation_sample = pd.concat(sampled_rows)\n",
        "\n",
        "print(f\"\\nSampled {len(venus_validation_sample)} Venus responses for validation\")\n",
        "print(\"\\n6-point score distribution in sample:\")\n",
        "print(venus_validation_sample['score'].value_counts().sort_index())\n",
        "print(\"\\nPercentages:\")\n",
        "print(venus_validation_sample['score'].value_counts(normalize=True).sort_index() * 100)\n",
        "\n",
        "# Save validation sample\n",
        "venus_validation_sample.to_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_venus_36.csv', index=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved validation sample (6-point scale)!\")"
      ],
      "metadata": {
        "id": "5Kx5_6GEHlfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247cfaed-77b3-4431-fd00-76c3f6c5b0ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sampled 37 Venus responses for validation\n",
            "\n",
            "6-point score distribution in sample:\n",
            "score\n",
            "1     5\n",
            "2    11\n",
            "3    12\n",
            "4     6\n",
            "5     2\n",
            "6     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentages:\n",
            "score\n",
            "1    13.513514\n",
            "2    29.729730\n",
            "3    32.432432\n",
            "4    16.216216\n",
            "5     5.405405\n",
            "6     2.702703\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "‚úÖ Saved validation sample (6-point scale)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# QUICK TEST: Generate 3 Synthetic Examples\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive, userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Load Venus source text\n",
        "df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                 encoding='ISO-8859-1')\n",
        "venus_df = df[df['prompt_name'] == 'Exploring Venus']\n",
        "VENUS_SOURCE = venus_df['source_text_1'].iloc[0]\n",
        "VENUS_ASSIGNMENT = venus_df['assignment'].iloc[0]\n",
        "\n",
        "# Rubric\n",
        "RUBRIC = \"\"\"\n",
        "COMPLETENESS (1-5): Coverage of main ideas and supporting details\n",
        "ACCURACY (1-5): Factual correctness and faithful representation\n",
        "COHERENCE (1-5): Organization, transitions, logical flow\n",
        "CONCISENESS (1-5): Appropriate length without repetition\n",
        "\"\"\"\n",
        "\n",
        "def generate_example(essay_id, score, error_type, instructions, word_target):\n",
        "    prompt = f\"\"\"You are simulating a grade 7-8 middle school student writing an evaluative essay.\n",
        "\n",
        "ASSIGNMENT: {VENUS_ASSIGNMENT}\n",
        "\n",
        "SOURCE TEXT: {VENUS_SOURCE}\n",
        "\n",
        "RUBRIC: {RUBRIC}\n",
        "\n",
        "TASK: Write a student response earning score {score}/6 with these characteristics:\n",
        "{instructions}\n",
        "\n",
        "Target length: {word_target} words\n",
        "Use authentic middle school vocabulary and style.\n",
        "Write only the student essay (no meta-commentary):\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You simulate authentic middle school writing for research.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.9,\n",
        "            max_tokens=800\n",
        "        )\n",
        "\n",
        "        text = response.choices[0].message.content.strip()\n",
        "\n",
        "        return {\n",
        "            'essay_id': essay_id,\n",
        "            'score': score,\n",
        "            'full_text': text,\n",
        "            'synthetic_flag': True,\n",
        "            'target_error_pattern': error_type,\n",
        "            'word_count': len(text.split()),\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'assignment': VENUS_ASSIGNMENT,\n",
        "            'prompt_name': 'Exploring Venus',\n",
        "            'source_text_1': VENUS_SOURCE\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# TEST: Generate 3 examples\n",
        "configs = [\n",
        "    {'essay_id': 'SYNTH_V_01_S1', 'score': 1, 'error_type': 'Severe incompleteness + fabrication',\n",
        "     'word_target': '100-150',\n",
        "     'instructions': 'Cover only 1-2 superficial details. Include 2-3 fabricated facts. Show fundamental misunderstanding. Random organization.'},\n",
        "\n",
        "    {'essay_id': 'SYNTH_V_04_S2', 'score': 2, 'error_type': 'Completeness gap',\n",
        "     'word_target': '150-200',\n",
        "     'instructions': 'Identify main claim correctly but provide only 1-2 vague examples. Omit specific evidence (temperatures, NASA solutions). Very superficial.'},\n",
        "\n",
        "    {'essay_id': 'SYNTH_V_11_S3', 'score': 3, 'error_type': 'Good content, weak coherence',\n",
        "     'word_target': '220-250',\n",
        "     'instructions': 'Cover all main ideas with adequate detail. Use awkward transitions. Random ordering. Choppy flow. Good content, poor organization.'},\n",
        "]\n",
        "\n",
        "results = []\n",
        "for i, cfg in enumerate(configs, 1):\n",
        "    print(f\"[{i}/3] Generating {cfg['essay_id']}...\", end=\" \")\n",
        "    result = generate_example(**cfg)\n",
        "    if result:\n",
        "        results.append(result)\n",
        "        print(f\"‚úì ({result['word_count']} words)\")\n",
        "        print(f\"Preview: {result['full_text'][:200]}...\\n\")\n",
        "    time.sleep(1)\n",
        "\n",
        "# Save test results\n",
        "test_df = pd.DataFrame(results)\n",
        "test_path = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/test_synthetic_3.csv'\n",
        "test_df.to_csv(test_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Generated {len(results)} test examples\")\n",
        "print(f\"üìÅ Saved to: {test_path}\")\n",
        "print(\"\\nüëÄ Review these examples. If they look good, proceed to full generation!\")"
      ],
      "metadata": {
        "id": "qhg3B2EA7w6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f2006e-d1a4-4136-ac7b-09082b6cb2a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[1/3] Generating SYNTH_V_01_S1... ‚úì (126 words)\n",
            "Preview: The article \"The Challenge of Exploring Venus\" says studying Venus is important even though it‚Äôs dangerous. The author talks about how Venus has really high temperatures and acid clouds, which makes i...\n",
            "\n",
            "[2/3] Generating SYNTH_V_04_S2... ‚úì (190 words)\n",
            "Preview: In \"The Challenge of Exploring Venus,\" the author argues that studying Venus is a worthy pursuit even though it is dangerous. I think the author does an okay job of supporting this idea, but not very ...\n",
            "\n",
            "[3/3] Generating SYNTH_V_11_S3... ‚úì (230 words)\n",
            "Preview: In ‚ÄúThe Challenge of Exploring Venus,‚Äù the author argues that studying Venus is a worthy pursuit even though it presents many dangers. The evidence provided supports this idea, but it could be organiz...\n",
            "\n",
            "‚úÖ Generated 3 test examples\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/test_synthetic_3.csv\n",
            "\n",
            "üëÄ Review these examples. If they look good, proceed to full generation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# REGENERATE 2 EXAMPLES WITH REFINED PROMPTS\n",
        "# ========================================\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Load Venus source text (if not already loaded)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                 encoding='ISO-8859-1')\n",
        "venus_df = df[df['prompt_name'] == 'Exploring Venus']\n",
        "VENUS_SOURCE = venus_df['source_text_1'].iloc[0]\n",
        "VENUS_ASSIGNMENT = venus_df['assignment'].iloc[0]\n",
        "\n",
        "# Rubric\n",
        "RUBRIC = \"\"\"\n",
        "COMPLETENESS (1-5): Coverage of main ideas and supporting details\n",
        "ACCURACY (1-5): Factual correctness and faithful representation\n",
        "COHERENCE (1-5): Organization, transitions, logical flow\n",
        "CONCISENESS (1-5): Appropriate length without repetition\n",
        "\"\"\"\n",
        "\n",
        "# Generation function\n",
        "def generate_example(essay_id, score, error_type, instructions, word_target):\n",
        "    prompt = f\"\"\"You are simulating a grade 7-8 middle school student writing an evaluative essay.\n",
        "\n",
        "ASSIGNMENT: {VENUS_ASSIGNMENT}\n",
        "\n",
        "SOURCE TEXT: {VENUS_SOURCE}\n",
        "\n",
        "RUBRIC: {RUBRIC}\n",
        "\n",
        "TASK: Write a student response earning score {score}/6 with these characteristics:\n",
        "{instructions}\n",
        "\n",
        "Target length: {word_target} words\n",
        "Use authentic middle school vocabulary and style.\n",
        "Write only the student essay (no meta-commentary):\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You simulate authentic middle school writing for research.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.9,\n",
        "            max_tokens=800\n",
        "        )\n",
        "\n",
        "        text = response.choices[0].message.content.strip()\n",
        "\n",
        "        return {\n",
        "            'essay_id': essay_id,\n",
        "            'score': score,\n",
        "            'full_text': text,\n",
        "            'synthetic_flag': True,\n",
        "            'target_error_pattern': error_type,\n",
        "            'word_count': len(text.split()),\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'assignment': VENUS_ASSIGNMENT,\n",
        "            'prompt_name': 'Exploring Venus',\n",
        "            'source_text_1': VENUS_SOURCE\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# ========================================\n",
        "# REFINED CONFIGURATIONS (THE KEY CHANGES)\n",
        "# ========================================\n",
        "\n",
        "refined_configs = [\n",
        "    # SCORE 1 - REVISED for more chaos\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_01_S1_REVISED',\n",
        "        'score': 1,\n",
        "        'error_type': 'Severe incompleteness + fabrication',\n",
        "        'word_target': '100-150',\n",
        "        'instructions': \"\"\"Cover only 1-2 superficial details like \"Venus is bright\" or \"it's hot.\"\n",
        "Include 2-3 fabricated facts (e.g., say \"hotter than the sun\" or \"NASA already went there\").\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump between totally unrelated ideas with NO logical connections\n",
        "- NO clear introduction-body-conclusion structure\n",
        "- Let ideas trail off or suddenly change direction mid-thought\n",
        "- Use only simple transitions: \"Also,\" \"And,\" or just start new sentences randomly\n",
        "- Make at least 2-3 sentences that don't connect to anything around them\n",
        "- Reader should feel confused trying to follow your point\n",
        "\n",
        "Example of scattered style you should use:\n",
        "\"Venus is really hot I think. Also there's blimps or something? The article talks about dangers but I can't remember. And they should explore Mars instead because it's better. Venus has acid maybe. I heard NASA already landed there but it broke. Also space is cool.\"\n",
        "\n",
        "Show you fundamentally misunderstood the assignment. Make it feel random and unfocused.\"\"\"\n",
        "    },\n",
        "\n",
        "    # SCORE 3 - REVISED for choppier flow\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_11_S3_REVISED',\n",
        "        'score': 3,\n",
        "        'error_type': 'Good content, weak coherence',\n",
        "        'word_target': '220-250',\n",
        "        'instructions': \"\"\"Cover ALL main ideas with GOOD specific details:\n",
        "- Dangers: 800¬∞F temperature, sulfuric acid, 97% CO2 atmosphere, 90x pressure\n",
        "- Solutions: NASA's blimp at 30 miles altitude, mechanical computers, silicon carbide\n",
        "- Value: Venus may have had oceans, Earth's twin, scientific curiosity\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing,\" \"So,\" \"Plus\"\n",
        "- NEVER use sophisticated ones: \"Furthermore,\" \"Additionally,\" \"Moreover,\" \"In conclusion\"\n",
        "- Present good ideas but in somewhat random order - jump between topics\n",
        "- Make each paragraph feel disconnected from the previous one\n",
        "\n",
        "Example of choppy style you should use:\n",
        "\"The author talks about Venus being super dangerous. It's like 800 degrees with sulfuric acid everywhere and 97% carbon dioxide. Also NASA has this idea about using blimps to float above Venus at like 30 miles up. And the temperature would still be hot but humans could survive. Plus Venus might have had oceans a long time ago so that's why scientists care. Another thing is they're making mechanical computers that can handle the extreme heat and pressure.\"\n",
        "\n",
        "Reader should think: \"This student clearly understood the article and has good details, but the organization and flow are rough. It feels choppy.\"\n",
        "\n",
        "DO NOT write a polished conclusion that ties everything together - make it feel more abrupt.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# ========================================\n",
        "# GENERATE THE 2 REVISED EXAMPLES\n",
        "# ========================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GENERATING 2 REVISED EXAMPLES WITH REFINED PROMPTS\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "\n",
        "revised_results = []\n",
        "for i, cfg in enumerate(refined_configs, 1):\n",
        "    print(f\"[{i}/2] Generating {cfg['essay_id']}...\")\n",
        "    print(f\"Target: {cfg['error_type']}\")\n",
        "    print()\n",
        "\n",
        "    result = generate_example(**cfg)\n",
        "\n",
        "    if result:\n",
        "        revised_results.append(result)\n",
        "        print(f\"‚úì Generated! ({result['word_count']} words)\\n\")\n",
        "        print(f\"FULL TEXT:\")\n",
        "        print(\"-\"*60)\n",
        "        print(result['full_text'])\n",
        "        print(\"-\"*60)\n",
        "        print()\n",
        "\n",
        "    time.sleep(2)  # Rate limiting\n",
        "\n",
        "# ========================================\n",
        "# SAVE REVISED EXAMPLES\n",
        "# ========================================\n",
        "\n",
        "if revised_results:\n",
        "    revised_df = pd.DataFrame(revised_results)\n",
        "    revised_path = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/test_synthetic_REVISED.csv'\n",
        "    revised_df.to_csv(revised_path, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ REGENERATION COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üìÅ Saved to: {revised_path}\")\n",
        "    print()\n",
        "    print(\"üìä COMPARISON:\")\n",
        "    print(f\"  Original Score 1: 129 words, somewhat coherent\")\n",
        "    print(f\"  Revised Score 1:  {revised_results[0]['word_count']} words\")\n",
        "    print()\n",
        "    print(f\"  Original Score 3: 241 words, too smooth\")\n",
        "    print(f\"  Revised Score 3:  {revised_results[1]['word_count']} words\")\n",
        "    print()\n",
        "    print(\"üîç REVIEW THE TEXT ABOVE\")\n",
        "    print(\"   Check if Score 1 now feels scattered/chaotic\")\n",
        "    print(\"   Check if Score 3 now feels choppy but has good content\")\n",
        "    print()\n",
        "    print(\"‚úÖ If satisfied ‚Üí Proceed to STEP 2\")\n",
        "    print(\"‚ùå If not quite right ‚Üí Adjust instructions and regenerate\")"
      ],
      "metadata": {
        "id": "sFOWrXRhi7az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae38490-f31f-4630-84ad-34da628c17e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "============================================================\n",
            "GENERATING 2 REVISED EXAMPLES WITH REFINED PROMPTS\n",
            "============================================================\n",
            "\n",
            "[1/2] Generating SYNTH_V_01_S1_REVISED...\n",
            "Target: Severe incompleteness + fabrication\n",
            "\n",
            "‚úì Generated! (130 words)\n",
            "\n",
            "FULL TEXT:\n",
            "------------------------------------------------------------\n",
            "Venus is really bright in the night sky. Also, Venus is super hot, even hotter than the sun. I think the article talks about how dangerous it is to explore Venus, but I can‚Äôt remember why. There are blimps or something that NASA wants to use to study it, but I‚Äôm not sure how that works. And, they should just explore Mars instead because it's better and cooler. Venus has acid in the air, which sounds scary. I heard NASA already landed there but it broke. Plus, space is cool. The author says studying Venus might help us learn, but it seems like too much trouble. I don‚Äôt really see why we should care about a planet that‚Äôs so dangerous. There‚Äôs probably other planets that are easier to check out.\n",
            "------------------------------------------------------------\n",
            "\n",
            "[2/2] Generating SYNTH_V_11_S3_REVISED...\n",
            "Target: Good content, weak coherence\n",
            "\n",
            "‚úì Generated! (234 words)\n",
            "\n",
            "FULL TEXT:\n",
            "------------------------------------------------------------\n",
            "In \"The Challenge of Exploring Venus,\" the author says that studying Venus is a worthy pursuit even though it‚Äôs really dangerous. The author talks about Venus being super dangerous. It's like 800 degrees with sulfuric acid everywhere and 97% carbon dioxide. And the pressure is 90 times what we have on Earth, which would crush most spacecraft. So, these conditions make it really hard for humans to explore Venus directly.\n",
            "\n",
            "But there are also solutions the author mentions. NASA has this idea about using blimps to float above Venus at like 30 miles up. This way, they can avoid the harsh conditions on the surface. The temperature would still be hot, but humans could survive better up there. Another thing is they're making mechanical computers that can handle the extreme heat and pressure on Venus. These computers use gears and levers instead of electronics, which get ruined in those conditions.\n",
            "\n",
            "Also, Venus might have had oceans a long time ago, so that's why scientists care. It's called Earth's twin, and it could‚Äôve supported life in the past. Plus, studying Venus could help us understand more about our own planet and the challenges we face with climate change. The author points out that human curiosity will lead us to explore these dangerous places, which is pretty cool. Overall, the article shows that even though studying Venus is risky, the knowledge we can gain is important.\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚úÖ REGENERATION COMPLETE!\n",
            "============================================================\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/test_synthetic_REVISED.csv\n",
            "\n",
            "üìä COMPARISON:\n",
            "  Original Score 1: 129 words, somewhat coherent\n",
            "  Revised Score 1:  130 words\n",
            "\n",
            "  Original Score 3: 241 words, too smooth\n",
            "  Revised Score 3:  234 words\n",
            "\n",
            "üîç REVIEW THE TEXT ABOVE\n",
            "   Check if Score 1 now feels scattered/chaotic\n",
            "   Check if Score 3 now feels choppy but has good content\n",
            "\n",
            "‚úÖ If satisfied ‚Üí Proceed to STEP 2\n",
            "‚ùå If not quite right ‚Üí Adjust instructions and regenerate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "COMPLETE SYNTHETIC EXAMPLES GENERATOR - REFINED VERSION\n",
        "Generates 23 synthetic Venus summaries with improved authenticity\n",
        "- Score 1: Enhanced chaotic, scattered organization\n",
        "- Score 3: Enhanced choppy flow with good content\n",
        "- Scores 2, 4, 5: Unchanged (already working well)\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ===========================================\n",
        "# CONFIGURATION\n",
        "# ===========================================\n",
        "\n",
        "# Set your OpenAI API key\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# File paths\n",
        "AUTHENTIC_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_venus_36.csv'\n",
        "SYNTHETIC_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_synthetic_23.csv'\n",
        "COMBINED_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_combined_60.csv'\n",
        "\n",
        "# ===========================================\n",
        "# LOAD VENUS SOURCE TEXT\n",
        "# ===========================================\n",
        "\n",
        "def load_venus_source():\n",
        "    \"\"\"Load the Venus article text from the ASAP dataset\"\"\"\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                     encoding='ISO-8859-1')\n",
        "    venus_df = df[df['prompt_name'] == 'Exploring Venus']\n",
        "    source_text = venus_df['source_text_1'].iloc[0]\n",
        "    assignment = venus_df['assignment'].iloc[0]\n",
        "    return source_text, assignment\n",
        "\n",
        "VENUS_SOURCE, VENUS_ASSIGNMENT = load_venus_source()\n",
        "\n",
        "# ===========================================\n",
        "# RUBRIC\n",
        "# ===========================================\n",
        "\n",
        "RUBRIC = \"\"\"\n",
        "RUBRIC FOR VENUS SUMMARY EVALUATION (1-5 scale per dimension):\n",
        "\n",
        "COMPLETENESS (1-5):\n",
        "5: Comprehensive coverage of all main ideas with strong supporting details\n",
        "4: Covers main ideas with good supporting details, minor gaps acceptable\n",
        "3: Covers basic main ideas but missing some key supporting details\n",
        "2: Partial coverage with significant gaps\n",
        "1: Minimal coverage, major ideas missing\n",
        "\n",
        "ACCURACY (1-5):\n",
        "5: All information factually correct\n",
        "4: Mostly accurate with only minor imprecisions\n",
        "3: Generally accurate but with some notable errors\n",
        "2: Multiple factual errors or significant misrepresentations\n",
        "1: Major factual errors, invented details, fundamental misunderstandings\n",
        "\n",
        "COHERENCE (1-5):\n",
        "5: Excellent organization with smooth transitions and clear logical flow\n",
        "4: Well-organized with generally good transitions\n",
        "3: Basic organization but with awkward transitions or logical gaps\n",
        "2: Poor organization, weak transitions, difficult to follow\n",
        "1: Incoherent, random organization, no clear structure\n",
        "\n",
        "CONCISENESS (1-5):\n",
        "5: Appropriately concise (200-250 words), no unnecessary repetition\n",
        "4: Reasonably concise (250-280 words), minimal redundancy\n",
        "3: Somewhat verbose (280-320 words) or with noticeable repetition\n",
        "2: Too long (320-400 words) with significant repetition\n",
        "1: Extremely brief (<150 words) or excessively long (>400 words)\n",
        "\"\"\"\n",
        "\n",
        "# ===========================================\n",
        "# GENERATION FUNCTIONS\n",
        "# ===========================================\n",
        "\n",
        "def create_generation_prompt(score, specific_instructions, word_count_guidance):\n",
        "    \"\"\"Create prompt for generating a synthetic example\"\"\"\n",
        "    return f\"\"\"You are simulating an authentic middle school student (grades 7-8) writing an evaluative essay about whether the author of an article successfully supports their argument. This is for educational research to test an automated assessment system.\n",
        "\n",
        "ASSIGNMENT:\n",
        "{VENUS_ASSIGNMENT}\n",
        "\n",
        "SOURCE TEXT:\n",
        "{VENUS_SOURCE}\n",
        "\n",
        "RUBRIC:\n",
        "{RUBRIC}\n",
        "\n",
        "YOUR TASK:\n",
        "Write a student response that would realistically earn a score of {score} on the 6-point scale based on the rubric above.\n",
        "\n",
        "SPECIFIC REQUIREMENTS FOR THIS SAMPLE:\n",
        "{specific_instructions}\n",
        "\n",
        "WRITING GUIDELINES:\n",
        "- Use vocabulary and sentence structure typical of grades 7-8\n",
        "- Target length: {word_count_guidance} words\n",
        "- Include some natural middle school writing patterns (minor grammar quirks, occasional informal phrasing)\n",
        "- Make it feel authentic - not overly polished or obviously AI-generated\n",
        "- Focus on the CONTENT errors specified above (don't make it artificially bad with excessive spelling/grammar errors)\n",
        "- Stay focused on the Venus exploration topic\n",
        "- Remember: this is evaluating HOW WELL THE AUTHOR SUPPORTS THE IDEA, not just summarizing\n",
        "\n",
        "Write only the student essay response (no meta-commentary):\"\"\"\n",
        "\n",
        "def generate_synthetic_example(example_config, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"Generate a single synthetic example using GPT-4o-Mini\"\"\"\n",
        "\n",
        "    prompt = create_generation_prompt(\n",
        "        score=example_config['score'],\n",
        "        specific_instructions=example_config['instructions'],\n",
        "        word_count_guidance=example_config['word_count']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # ‚úÖ Use Chat Completions via the client\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"You are an expert at simulating authentic middle school \"\n",
        "                        \"student writing for educational research purposes.\"\n",
        "                    )\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                },\n",
        "            ],\n",
        "            temperature=0.9,\n",
        "            max_tokens=800,\n",
        "        )\n",
        "\n",
        "        generated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        return {\n",
        "            'essay_id': example_config['essay_id'],\n",
        "            'score': example_config['score'],\n",
        "            'full_text': generated_text,\n",
        "            'assignment': VENUS_ASSIGNMENT,\n",
        "            'prompt_name': 'Exploring Venus',\n",
        "            'source_text_1': VENUS_SOURCE,\n",
        "            'source_text_2': None,\n",
        "            'source_text_3': None,\n",
        "            'source_text_4': None,\n",
        "            'economically_disadvantaged': 'Synthetic',\n",
        "            'student_disability_status': 'Synthetic',\n",
        "            'ell_status': 'Synthetic',\n",
        "            'race_ethnicity': 'Synthetic',\n",
        "            'gender': 'Synthetic',\n",
        "            'synthetic_flag': True,\n",
        "            'target_error_pattern': example_config['target_error'],\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'generation_model': model,\n",
        "            'word_count': len(generated_text.split())\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating {example_config['essay_id']}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ===========================================\n",
        "# ALL 23 SYNTHETIC EXAMPLE CONFIGURATIONS\n",
        "# ===========================================\n",
        "\n",
        "SYNTHETIC_EXAMPLES = [\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 1 EXAMPLES (3 total) - REFINED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_01_S1',\n",
        "        'score': 1,\n",
        "        'target_error': 'Severe incompleteness + fabrication',\n",
        "        'word_count': '100-150',\n",
        "        'instructions': \"\"\"Cover only 1-2 superficial details like \"Venus is bright\" or \"it's hot.\"\n",
        "Include 2-3 fabricated facts (e.g., say \"hotter than the sun\" or \"NASA already went there\").\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump between totally unrelated ideas with NO logical connections\n",
        "- NO clear introduction-body-conclusion structure\n",
        "- Let ideas trail off or suddenly change direction mid-thought\n",
        "- Use only simple transitions: \"Also,\" \"And,\" or just start new sentences randomly\n",
        "- Make at least 2-3 sentences that don't connect to anything around them\n",
        "- Reader should feel confused trying to follow your point\n",
        "\n",
        "Example scattered style: \"Venus is really hot I think. Also there's blimps or something? The article talks about dangers but I can't remember. And they should explore Mars instead. Venus has acid maybe.\"\n",
        "\n",
        "Show you fundamentally misunderstood the assignment. Make it feel random and unfocused.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_02_S1',\n",
        "        'score': 1,\n",
        "        'target_error': 'Extreme brevity + major misunderstandings',\n",
        "        'word_count': '80-120',\n",
        "        'instructions': \"\"\"Write only 3-5 sentences total (extremely brief).\n",
        "Fundamentally misrepresent the article's main argument (say scientists have already successfully explored Venus when the article is about future plans and challenges).\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump between ideas with no connections\n",
        "- NO structure at all\n",
        "- Treat Venus exploration as if it's already accomplished rather than a future challenge\n",
        "- Miss the evaluative component entirely - don't assess whether the author supported their claim well\n",
        "- Use simple transitions only: \"Also,\" \"And,\" or none\n",
        "- Let thoughts trail off incompletely\n",
        "\n",
        "Show you didn't understand what the article was actually about. Make it feel very confused.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_03_S1',\n",
        "        'score': 1,\n",
        "        'target_error': 'Off-topic rambling + factual confusion',\n",
        "        'word_count': '150-200',\n",
        "        'instructions': \"\"\"Spend most of the essay on tangential topics (other planets, space exploration in general, why space is cool).\n",
        "Confuse Venus with Mars or Mercury in several places.\n",
        "Include information about planets that wasn't in the article at all.\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump wildly between unrelated topics: Venus ‚Üí other planets ‚Üí space careers ‚Üí back to Venus ‚Üí random facts\n",
        "- NO clear focus on the assigned task\n",
        "- Incoherent connections between ideas\n",
        "- Simple or no transitions\n",
        "- Several sentences that feel completely disconnected\n",
        "- Never clearly address whether the author supported their argument\n",
        "\n",
        "Show the student didn't focus on the assigned task and got distracted by tangents.\"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 2 EXAMPLES (7 total) - UNCHANGED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_04_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Completeness gap - missing critical supporting details',\n",
        "        'word_count': '150-200',\n",
        "        'instructions': \"\"\"Correctly identify the main claim (studying Venus is worthy despite dangers).\n",
        "Mention that the author discusses dangers and solutions.\n",
        "BUT only provide 1-2 very vague examples (e.g., \"there are dangers\" without specifying what).\n",
        "Omit key evidence like specific temperatures, NASA's blimp solution, mechanical computers, etc.\n",
        "Show basic understanding but very superficial engagement with the text.\n",
        "Address the evaluation aspect but without sufficient detail to be convincing.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_05_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Accuracy issues - multiple misrepresentations',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Capture the basic structure (dangers ‚Üí solutions ‚Üí why it's worth it).\n",
        "Include several factual errors: wrong temperature (say 600¬∞F instead of 800¬∞F), wrong atmospheric pressure, wrong altitude for NASA's blimp.\n",
        "Misattribute information (e.g., say Mercury is Earth's twin, or confuse which planet has the hottest surface).\n",
        "Mix up timeframes (say missions were recent when they were decades ago).\n",
        "Show the student read the article but remembered details incorrectly.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_06_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Coherence problems - poor organization',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Include relevant content from the article but present it in random order.\n",
        "Jump from dangers to solutions back to dangers to why Venus is interesting with no logical flow.\n",
        "Use very weak or missing transitions (\"Also...\" or \"And another thing...\").\n",
        "Make it hard to follow the argument even though the information is present.\n",
        "Repeat the same point in different places rather than grouping related ideas.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_07_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Conciseness problems - excessive length with repetition',\n",
        "        'word_count': '400-450',\n",
        "        'instructions': \"\"\"Include accurate information about Venus.\n",
        "Repeat the same points 3-4 times using slightly different wording each time.\n",
        "Say things like \"Venus is dangerous because of the heat. The heat on Venus is extreme. The temperatures on Venus are very hot.\"\n",
        "Include unnecessary elaboration on minor details.\n",
        "Make it feel like padding to meet a length requirement.\n",
        "Could easily be cut to 200 words without losing content.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_08_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Quote-heavy with minimal synthesis',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Rely heavily on direct phrases from the article (don't use actual quotation marks, but use near-quotes).\n",
        "String together borrowed phrases with minimal original summarization.\n",
        "Reads like a patchwork: \"The article says [near quote]. It also mentions [near quote]. The author states [near quote].\"\n",
        "Very little original synthesis or paraphrasing.\n",
        "Shows the student didn't process the information, just copied it.\n",
        "Weak evaluation of whether the author's support is effective.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_09_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Shallow coverage - lists facts without connections',\n",
        "        'word_count': '160-200',\n",
        "        'instructions': \"\"\"Write in a bullet-point style or list-like structure even without actual bullets.\n",
        "\"First, Venus is hot. Second, there is acid. Third, NASA has an idea.\"\n",
        "List facts from the article without connecting them or showing relationships.\n",
        "No clear evaluation of the author's argument - just recitation.\n",
        "Miss the analytical component entirely.\n",
        "Each sentence feels disconnected from the previous one.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_10_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Personal opinion intrusion',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Start summarizing the article but then shift into personal opinions.\n",
        "Use phrases like \"I think we should explore Venus because...\" or \"I believe the author is right because I've always been interested in space...\"\n",
        "Include 2-3 paragraphs about the student's own views on space exploration.\n",
        "Lose objectivity required for summary/evaluation.\n",
        "Confuse personal response with evaluation of the author's support.\n",
        "Mix \"the author supports this\" with \"I agree because...\" \"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 3 EXAMPLES (8 total) - REFINED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_11_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good completeness, weak coherence',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Cover ALL main ideas with GOOD specific details:\n",
        "- Dangers: 800¬∞F temperature, sulfuric acid, 97% CO2 atmosphere, 90x pressure\n",
        "- Solutions: NASA's blimp at 30 miles altitude, mechanical computers, silicon carbide\n",
        "- Value: Venus may have had oceans, Earth's twin, scientific curiosity\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing,\" \"So,\" \"Plus\"\n",
        "- NEVER use: \"Furthermore,\" \"Additionally,\" \"Moreover,\" \"In conclusion\"\n",
        "- Present good ideas in somewhat random order - jump between topics\n",
        "- Make each paragraph feel disconnected from the previous one\n",
        "\n",
        "Example choppy style: \"The author talks about Venus being super dangerous. It's like 800 degrees with sulfuric acid. Also NASA has this idea about blimps. And the temperature would be hot but survivable. Plus Venus might have had oceans.\"\n",
        "\n",
        "Reader should think: \"Good content but rough organization.\" DO NOT write polished conclusion.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_12_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good accuracy/completeness, conciseness issues',\n",
        "        'word_count': '320-350',\n",
        "        'instructions': \"\"\"Cover all main ideas with accurate, thorough detail.\n",
        "Include all key facts with correct information.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution AND TOO LONG:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing,\" \"So,\" \"Plus\"\n",
        "- Be moderately too long (320-350 words)\n",
        "- Include some unnecessary elaboration or minor tangential details\n",
        "- Some repetition of ideas\n",
        "- Could be tightened significantly without losing content\n",
        "- Good substance but needs editing\n",
        "- Somewhat random organization\n",
        "\n",
        "Make it feel like the student knows the material well but wrote too much with choppy flow.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_13_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good structure, minor accuracy lapses',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write with decent organization and appropriate length.\n",
        "Include good coverage of main ideas.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS minor errors:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"So,\" \"Plus\"\n",
        "- Include 2-3 minor factual errors (slightly wrong numbers)\n",
        "- Example: say the blimp would be 20 miles up instead of 30, or say 80% carbon dioxide instead of 97%\n",
        "- Errors are small enough that overall understanding is clear\n",
        "- Somewhat choppy flow with weak transitions\n",
        "\n",
        "Otherwise solid summary with adequate evaluation.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_14_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Adequate but mechanical',\n",
        "        'word_count': '200-230',\n",
        "        'instructions': \"\"\"Hit all required elements in a formulaic way.\n",
        "\"The author supports this idea in three ways. First,... Second,... Third,...\"\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution AND mechanical:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"First,\" \"Second,\" \"Third\"\n",
        "- Very five-paragraph-essay structure that feels paint-by-numbers\n",
        "- Overly simplistic sentence structure throughout (mostly simple sentences, few complex ones)\n",
        "- Feels formulaic but technically complete\n",
        "- Adequate but uninspired\n",
        "- Choppy transitions between sections\n",
        "\n",
        "Make it feel like following a template rather than natural writing.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_15_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good content, weak introduction/conclusion',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write strong middle paragraphs with good detail about dangers, solutions, and value.\n",
        "Include specific facts and evidence.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS weak framing:\n",
        "- Use ONLY weak transitions in body: \"Also,\" \"And,\" \"Plus,\" \"So\"\n",
        "- Unclear or missing claim statement in introduction\n",
        "- Introduction jumps straight into details without setting up the evaluation\n",
        "- Abrupt ending or incomplete conclusion that doesn't tie ideas together\n",
        "- The body is strong (score 4 content level) but framing is weak and choppy\n",
        "\n",
        "Make the middle good but the beginning and end feel rough.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_16_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Imbalanced coverage',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write excellent, detailed coverage of the dangers (sulfuric acid, heat, pressure, etc.).\n",
        "Then only 2-3 sentences total on NASA's solutions (very superficial).\n",
        "Barely mention why Venus is scientifically valuable.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution AND imbalanced:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing\"\n",
        "- Show engagement with some sections but uneven attention\n",
        "- Good depth in dangers, inadequate in solutions/value\n",
        "- Choppy flow throughout\n",
        "- Somewhat random organization\n",
        "\n",
        "Make it obvious the student focused on one section and rushed through others.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_17_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Nearly good but with redundancy',\n",
        "        'word_count': '260-290',\n",
        "        'instructions': \"\"\"Write with accurate information and decent structure.\n",
        "Include good evaluation of the author's support.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS redundancy:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Plus,\" \"So\"\n",
        "- Repeat 2-3 points unnecessarily\n",
        "- Example: mention the extreme heat in paragraph 2, then mention it again in paragraph 3 in similar words\n",
        "- Some ideas stated twice without adding new information\n",
        "- Choppy transitions throughout\n",
        "- Could be excellent if tightened and smoothed\n",
        "\n",
        "Make it feel like good understanding but needs editing for flow and conciseness.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_18_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good summary with minor coherence gaps',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write comprehensive and accurate coverage.\n",
        "Include good specific details.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS coherence hiccups:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"So,\" \"Plus\"\n",
        "- Make one paragraph or section feel disconnected from the rest\n",
        "- Include slightly confusing pronoun references (unclear antecedents)\n",
        "- One transition that doesn't quite work\n",
        "- Reader might need to reread one part to understand the connection\n",
        "- Overall good but with noticeable choppiness\n",
        "\n",
        "Make it feel like the content is there but organization could be smoother.\"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 4 EXAMPLES (4 total) - UNCHANGED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_19_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Excellent overall, slightly too lengthy',\n",
        "        'word_count': '290-310',\n",
        "        'instructions': \"\"\"Write a clear, explicit evaluation of how well the author supports the argument.\n",
        "Include comprehensive coverage of dangers (specific examples), solutions (blimp, mechanical computers), and scientific value.\n",
        "Make it accurate throughout with good detail.\n",
        "Organize well with smooth transitions.\n",
        "BUT make it slightly longer than ideal (290-310 words).\n",
        "Could be tightened by 40-60 words without losing substance.\n",
        "Very strong work with only minor conciseness issue.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_20_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Very good but with minor conciseness issue',\n",
        "        'word_count': '250-270',\n",
        "        'instructions': \"\"\"Write with excellent structure, accuracy, and completeness.\n",
        "Include strong evaluation of the author's argument.\n",
        "Make it clear and coherent throughout.\n",
        "BUT include 1-2 sentences that could be tightened.\n",
        "One slightly redundant point or phrase.\n",
        "Example: might say both \"very hot\" and \"extremely high temperatures\" in close proximity.\n",
        "Nearly perfect with just minor tightening needed.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_21_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Strong summary, minor accuracy detail',\n",
        "        'word_count': '230-260',\n",
        "        'instructions': \"\"\"Write with excellent organization, completeness, and conciseness.\n",
        "Include clear evaluation with strong supporting evidence.\n",
        "Use smooth, sophisticated writing.\n",
        "BUT include one small factual error that doesn't undermine the overall argument.\n",
        "Example: say 85 times atmospheric pressure instead of 90, or 750¬∞F instead of 800¬∞F.\n",
        "Error is minor enough that understanding remains strong.\n",
        "Otherwise near-perfect.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_22_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Near-excellent but slightly mechanical',\n",
        "        'word_count': '240-260',\n",
        "        'instructions': \"\"\"Hit all rubric criteria very well.\n",
        "Make it accurate, complete, organized, and reasonably concise.\n",
        "Include clear evaluation with good evidence.\n",
        "BUT lack the sophisticated synthesis and insightful connections of score 5-6.\n",
        "Be slightly formulaic in approach.\n",
        "Very competent and thorough but doesn't have the \"spark\" of exceptional writing.\n",
        "Very good but not quite excellent.\"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 5 EXAMPLES (1 total) - UNCHANGED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_23_S5',\n",
        "        'score': 5,\n",
        "        'target_error': 'Excellent summary with very minor flaw',\n",
        "        'word_count': '230-250',\n",
        "        'instructions': \"\"\"Write a clear, insightful evaluation of how the author builds their argument.\n",
        "Include comprehensive coverage of all key evidence (dangers, NASA solutions, scientific value, mechanical computers, past missions).\n",
        "Make all information accurate and well-synthesized.\n",
        "Use excellent organization with smooth, sophisticated transitions.\n",
        "Be appropriately concise (230-250 words) with no redundancy.\n",
        "Show deep understanding and analytical thinking.\n",
        "BUT include one VERY minor issue (e.g., two ideas that could be connected more explicitly, or one transition that's good but could be slightly smoother).\n",
        "The flaw should be extremely subtle - this is nearly perfect work.\n",
        "Should feel like strong high school or early college writing.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# ===========================================\n",
        "# MAIN GENERATION FUNCTION\n",
        "# ===========================================\n",
        "\n",
        "def generate_all_synthetic_examples(save_path, delay=1.5):\n",
        "    \"\"\"Generate all 23 synthetic examples and save to CSV\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"GENERATING {len(SYNTHETIC_EXAMPLES)} SYNTHETIC EXAMPLES\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\n",
        "        f\"Estimated time: {len(SYNTHETIC_EXAMPLES) * 2:.0f} seconds \"\n",
        "        f\"(~{len(SYNTHETIC_EXAMPLES) * 2 / 60:.0f} minutes)\"\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, example_config in enumerate(SYNTHETIC_EXAMPLES, 1):\n",
        "        print(\n",
        "            f\"[{i:2d}/{len(SYNTHETIC_EXAMPLES)}] \"\n",
        "            f\"{example_config['essay_id']} (Score {example_config['score']})...\",\n",
        "            end=\" \",\n",
        "        )\n",
        "\n",
        "        # ‚úÖ actually generate one example\n",
        "        result = generate_synthetic_example(example_config)\n",
        "\n",
        "        if result is not None:\n",
        "            results.append(result)\n",
        "            word_count = result[\"word_count\"]\n",
        "            print(f\"‚úì ({word_count} words)\")\n",
        "        else:\n",
        "            print(\"‚úó FAILED\")\n",
        "\n",
        "        # Rate limiting\n",
        "        if i < len(SYNTHETIC_EXAMPLES):\n",
        "            time.sleep(delay)\n",
        "\n",
        "    # If all generations failed, bail out gracefully\n",
        "    if not results:\n",
        "        print(\n",
        "            \"\\nNo synthetic examples were generated. \"\n",
        "            \"Check the error messages above (likely an API or config issue).\"\n",
        "        )\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Create DataFrame\n",
        "    synthetic_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save to CSV\n",
        "    synthetic_df.to_csv(save_path, index=False)\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 70)\n",
        "    print(\"‚úÖ GENERATION COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Generated: {len(results)}/{len(SYNTHETIC_EXAMPLES)} examples\")\n",
        "    print(f\"üìÅ Saved to: {save_path}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Score distribution:\")\n",
        "    print(synthetic_df[\"score\"].value_counts().sort_index())\n",
        "    print()\n",
        "\n",
        "    return synthetic_df\n",
        "\n",
        "# ===========================================\n",
        "# COMBINE WITH AUTHENTIC SAMPLES\n",
        "# ===========================================\n",
        "\n",
        "def combine_with_authentic(authentic_path, synthetic_df, output_path):\n",
        "    \"\"\"Combine authentic and synthetic samples into final validation set\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"COMBINING WITH AUTHENTIC SAMPLES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load authentic samples\n",
        "    authentic_df = pd.read_csv(authentic_path)\n",
        "\n",
        "    # Add metadata columns to authentic samples\n",
        "    authentic_df['synthetic_flag'] = False\n",
        "    authentic_df['target_error_pattern'] = 'Authentic student work'\n",
        "    authentic_df['generation_date'] = None\n",
        "    authentic_df['generation_model'] = None\n",
        "    authentic_df['word_count'] = authentic_df['full_text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "    # Combine\n",
        "    combined_df = pd.concat([authentic_df, synthetic_df], ignore_index=True)\n",
        "\n",
        "    # Shuffle to mix authentic and synthetic\n",
        "    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Save\n",
        "    combined_df.to_csv(output_path, index=False)\n",
        "\n",
        "    print()\n",
        "    print(\"‚úÖ COMBINED DATASET CREATED!\")\n",
        "    print(f\"   Authentic samples: {len(authentic_df)} ({len(authentic_df)/len(combined_df)*100:.1f}%)\")\n",
        "    print(f\"   Synthetic samples: {len(synthetic_df)} ({len(synthetic_df)/len(combined_df)*100:.1f}%)\")\n",
        "    print(f\"   Total samples: {len(combined_df)}\")\n",
        "    print()\n",
        "    print(f\"üìÅ Saved to: {output_path}\")\n",
        "    print()\n",
        "    print(\"Final score distribution:\")\n",
        "    print(combined_df['score'].value_counts().sort_index())\n",
        "    print()\n",
        "\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "hyufyNRfm2tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785937f4-2abc-42ff-9151-5a204605be5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# QUICK SANITY CHECK (RUNS WHEN YOU EXECUTE THIS CELL)\n",
        "# ===========================================\n",
        "\n",
        "print(\"Running quick sanity check with one synthetic example...\")\n",
        "test_config = SYNTHETIC_EXAMPLES[0]\n",
        "test_sample = generate_synthetic_example(test_config)\n",
        "\n",
        "print(\"Result is None?\", test_sample is None)\n",
        "if test_sample:\n",
        "    print(\"Sample word_count:\", test_sample[\"word_count\"])\n",
        "    print(test_sample[\"full_text\"][:400], \"...\")\n",
        "    # Optional: stop here while debugging\n",
        "    # import sys\n",
        "    # sys.exit(\"Stopping after sanity check.\")"
      ],
      "metadata": {
        "id": "D9RHW7IxupJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c9d734-54f1-455a-e365-fe44d1c817da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running quick sanity check with one synthetic example...\n",
            "Result is None? False\n",
            "Sample word_count: 149\n",
            "Venus is super bright in the sky. I mean, it‚Äôs like the brightest planet. The article talks about how it‚Äôs really hot, like hotter than the sun or something, which is crazy. Also, NASA went there already and they found some cool stuff. But then they said it was dangerous because of the acid in the clouds. I don't know why they even want to go back since they could just look at Mars, which is way m ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# RUN COMPLETE GENERATION\n",
        "# ===========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SYNTHETIC EXAMPLES GENERATION - REFINED VERSION\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "\n",
        "    # Step 1: Generate synthetic examples\n",
        "    synthetic_df = generate_all_synthetic_examples(SYNTHETIC_PATH, delay=1.5)\n",
        "\n",
        "    if synthetic_df.empty:\n",
        "        print(\"‚ùå Skipping combination because no synthetic examples were generated.\")\n",
        "    else:\n",
        "        # Step 2: Combine with authentic samples\n",
        "        final_df = combine_with_authentic(AUTHENTIC_PATH, synthetic_df, COMBINED_PATH)\n",
        "        print(\"=\"*70)\n",
        "        print(\"üéâ ALL DONE!\")\n",
        "        print(\"=\"*70)\n",
        "        print()\n",
        "        print(\"Next steps:\")\n",
        "        print(\"1. ‚úÖ Review synthetic examples for quality\")\n",
        "        print(\"2. ‚úÖ Regenerate any that need adjustment\")\n",
        "        print(\"3. ‚úÖ Proceed to Phase 2: Expert Rating\")\n",
        "        print()\n",
        "        print(f\"Your validation set is ready: {COMBINED_PATH}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "ZJTxwd-iunNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c0b85e-cf00-42e7-c9c4-05a4fb20a374"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SYNTHETIC EXAMPLES GENERATION - REFINED VERSION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "GENERATING 23 SYNTHETIC EXAMPLES\n",
            "======================================================================\n",
            "Estimated time: 46 seconds (~1 minutes)\n",
            "\n",
            "[ 1/23] SYNTH_V_01_S1 (Score 1)... ‚úì (139 words)\n",
            "[ 2/23] SYNTH_V_02_S1 (Score 1)... ‚úì (102 words)\n",
            "[ 3/23] SYNTH_V_03_S1 (Score 1)... ‚úì (224 words)\n",
            "[ 4/23] SYNTH_V_04_S2 (Score 2)... ‚úì (184 words)\n",
            "[ 5/23] SYNTH_V_05_S2 (Score 2)... ‚úì (226 words)\n",
            "[ 6/23] SYNTH_V_06_S2 (Score 2)... ‚úì (248 words)\n",
            "[ 7/23] SYNTH_V_07_S2 (Score 2)... ‚úì (461 words)\n",
            "[ 8/23] SYNTH_V_08_S2 (Score 2)... ‚úì (229 words)\n",
            "[ 9/23] SYNTH_V_09_S2 (Score 2)... ‚úì (191 words)\n",
            "[10/23] SYNTH_V_10_S2 (Score 2)... ‚úì (229 words)\n",
            "[11/23] SYNTH_V_11_S3 (Score 3)... ‚úì (244 words)\n",
            "[12/23] SYNTH_V_12_S3 (Score 3)... ‚úì (326 words)\n",
            "[13/23] SYNTH_V_13_S3 (Score 3)... ‚úì (256 words)\n",
            "[14/23] SYNTH_V_14_S3 (Score 3)... ‚úì (232 words)\n",
            "[15/23] SYNTH_V_15_S3 (Score 3)... ‚úì (258 words)\n",
            "[16/23] SYNTH_V_16_S3 (Score 3)... ‚úì (254 words)\n",
            "[17/23] SYNTH_V_17_S3 (Score 3)... ‚úì (293 words)\n",
            "[18/23] SYNTH_V_18_S3 (Score 3)... ‚úì (252 words)\n",
            "[19/23] SYNTH_V_19_S4 (Score 4)... ‚úì (278 words)\n",
            "[20/23] SYNTH_V_20_S4 (Score 4)... ‚úì (234 words)\n",
            "[21/23] SYNTH_V_21_S4 (Score 4)... ‚úì (241 words)\n",
            "[22/23] SYNTH_V_22_S4 (Score 4)... ‚úì (254 words)\n",
            "[23/23] SYNTH_V_23_S5 (Score 5)... ‚úì (241 words)\n",
            "\n",
            "======================================================================\n",
            "‚úÖ GENERATION COMPLETE!\n",
            "======================================================================\n",
            "Generated: 23/23 examples\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_synthetic_23.csv\n",
            "\n",
            "Score distribution:\n",
            "score\n",
            "1    3\n",
            "2    7\n",
            "3    8\n",
            "4    4\n",
            "5    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "======================================================================\n",
            "COMBINING WITH AUTHENTIC SAMPLES\n",
            "======================================================================\n",
            "\n",
            "‚úÖ COMBINED DATASET CREATED!\n",
            "   Authentic samples: 37 (61.7%)\n",
            "   Synthetic samples: 23 (38.3%)\n",
            "   Total samples: 60\n",
            "\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_combined_60.csv\n",
            "\n",
            "Final score distribution:\n",
            "score\n",
            "1     8\n",
            "2    18\n",
            "3    20\n",
            "4    10\n",
            "5     3\n",
            "6     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "======================================================================\n",
            "üéâ ALL DONE!\n",
            "======================================================================\n",
            "\n",
            "Next steps:\n",
            "1. ‚úÖ Review synthetic examples for quality\n",
            "2. ‚úÖ Regenerate any that need adjustment\n",
            "3. ‚úÖ Proceed to Phase 2: Expert Rating\n",
            "\n",
            "Your validation set is ready: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_combined_60.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.read_csv(COMBINED_PATH)\n",
        "\n",
        "print(combined_df.shape)  # should be (60, ...)\n",
        "print(combined_df[\"synthetic_flag\"].value_counts())\n",
        "print(combined_df[\"score\"].value_counts().sort_index())\n",
        "\n",
        "# Look at a few synthetic rows\n",
        "combined_df[combined_df[\"synthetic_flag\"]].head()[[\"essay_id\", \"score\", \"word_count\"]]"
      ],
      "metadata": {
        "id": "UQeNNvMz0rso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "4f43e594-9c11-4cfb-edf2-557c963ba443"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 19)\n",
            "synthetic_flag\n",
            "False    37\n",
            "True     23\n",
            "Name: count, dtype: int64\n",
            "score\n",
            "1     8\n",
            "2    18\n",
            "3    20\n",
            "4    10\n",
            "5     3\n",
            "6     1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         essay_id  score  word_count\n",
              "3   SYNTH_V_09_S2      2         191\n",
              "5   SYNTH_V_18_S3      3         252\n",
              "7   SYNTH_V_12_S3      3         326\n",
              "9   SYNTH_V_21_S4      4         241\n",
              "10  SYNTH_V_10_S2      2         229"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87905404-880b-4d0b-9b8c-c387bfd353de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>score</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SYNTH_V_09_S2</td>\n",
              "      <td>2</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SYNTH_V_18_S3</td>\n",
              "      <td>3</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SYNTH_V_12_S3</td>\n",
              "      <td>3</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SYNTH_V_21_S4</td>\n",
              "      <td>4</td>\n",
              "      <td>241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SYNTH_V_10_S2</td>\n",
              "      <td>2</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87905404-880b-4d0b-9b8c-c387bfd353de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87905404-880b-4d0b-9b8c-c387bfd353de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87905404-880b-4d0b-9b8c-c387bfd353de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3ae2a3c4-889e-44dd-a634-e4c5a88f0389\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ae2a3c4-889e-44dd-a634-e4c5a88f0389')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3ae2a3c4-889e-44dd-a634-e4c5a88f0389 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"combined_df[combined_df[\\\"synthetic_flag\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SYNTH_V_18_S3\",\n          \"SYNTH_V_10_S2\",\n          \"SYNTH_V_12_S3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 191,\n        \"max\": 326,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          252,\n          229,\n          326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic = combined_df[combined_df[\"synthetic_flag\"]]\n",
        "\n",
        "# Check word-count ranges by score\n",
        "synthetic.groupby(\"score\")[\"word_count\"].describe()"
      ],
      "metadata": {
        "id": "QXcUPHqg1M4o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "afb0b901-6a3b-40f4-d518-0196009adbc1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       count        mean        std    min     25%    50%     75%    max\n",
              "score                                                                   \n",
              "1        3.0  155.000000  62.553977  102.0  120.50  139.0  181.50  224.0\n",
              "2        7.0  252.571429  94.669349  184.0  208.50  229.0  238.50  461.0\n",
              "3        8.0  264.375000  30.359454  232.0  250.00  255.0  266.75  326.0\n",
              "4        4.0  251.750000  19.362765  234.0  239.25  247.5  260.00  278.0\n",
              "5        1.0  241.000000        NaN  241.0  241.00  241.0  241.00  241.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36285497-799a-4df5-b19f-1c0ccda50aad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>62.553977</td>\n",
              "      <td>102.0</td>\n",
              "      <td>120.50</td>\n",
              "      <td>139.0</td>\n",
              "      <td>181.50</td>\n",
              "      <td>224.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>252.571429</td>\n",
              "      <td>94.669349</td>\n",
              "      <td>184.0</td>\n",
              "      <td>208.50</td>\n",
              "      <td>229.0</td>\n",
              "      <td>238.50</td>\n",
              "      <td>461.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>264.375000</td>\n",
              "      <td>30.359454</td>\n",
              "      <td>232.0</td>\n",
              "      <td>250.00</td>\n",
              "      <td>255.0</td>\n",
              "      <td>266.75</td>\n",
              "      <td>326.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>251.750000</td>\n",
              "      <td>19.362765</td>\n",
              "      <td>234.0</td>\n",
              "      <td>239.25</td>\n",
              "      <td>247.5</td>\n",
              "      <td>260.00</td>\n",
              "      <td>278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>241.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>241.0</td>\n",
              "      <td>241.00</td>\n",
              "      <td>241.0</td>\n",
              "      <td>241.00</td>\n",
              "      <td>241.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36285497-799a-4df5-b19f-1c0ccda50aad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36285497-799a-4df5-b19f-1c0ccda50aad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36285497-799a-4df5-b19f-1c0ccda50aad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c961f06e-488c-4d3b-b14f-73c6ac0ab7be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c961f06e-488c-4d3b-b14f-73c6ac0ab7be')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c961f06e-488c-4d3b-b14f-73c6ac0ab7be button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"synthetic\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8809720581775866,\n        \"min\": 1.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.0,\n          1.0,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44.347986172441026,\n        \"min\": 155.0,\n        \"max\": 264.375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          252.57142857142858,\n          241.0,\n          264.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.98668459094047,\n        \"min\": 19.36276495407272,\n        \"max\": 94.66934939190041,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          94.66934939190041,\n          19.36276495407272,\n          62.55397669213365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.54741668084083,\n        \"min\": 102.0,\n        \"max\": 241.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          184.0,\n          241.0,\n          232.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53.413364432508835,\n        \"min\": 120.5,\n        \"max\": 250.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          208.5,\n          241.0,\n          250.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.533672275556405,\n        \"min\": 139.0,\n        \"max\": 255.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          229.0,\n          241.0,\n          255.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.5821753315654,\n        \"min\": 181.5,\n        \"max\": 266.75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          238.5,\n          241.0,\n          266.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95.07628516091697,\n        \"min\": 224.0,\n        \"max\": 461.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          461.0,\n          241.0,\n          326.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Calibration Subset Selection\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# SETUP: Mount Google Drive\n",
        "# =============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION: Set your file paths\n",
        "# =============================================================================\n",
        "\n",
        "# UPDATE THESE PATHS to match your Google Drive structure:\n",
        "VALIDATION_DATASET_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_combined_60.csv'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/'\n",
        "\n",
        "# The script will create these files in OUTPUT_DIR:\n",
        "# - calibration_subset.csv\n",
        "# - calibration_practice_summaries.txt\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CALIBRATION SUBSET SELECTION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nReading from: {VALIDATION_DATASET_PATH}\")\n",
        "print(f\"Saving to: {OUTPUT_DIR}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: Load and analyze dataset\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(\"\\n[STEP 1] Loading Dataset...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "df = pd.read_csv(VALIDATION_DATASET_PATH)\n",
        "\n",
        "print(f\"‚úì Loaded {len(df)} summaries\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "\n",
        "print(\"\\n\\nDataset Distribution:\")\n",
        "print(f\"  Authentic (ASAP 2.0): {(df['synthetic_flag'] == False).sum()}\")\n",
        "print(f\"  Synthetic (GPT-4o-Mini): {(df['synthetic_flag'] == True).sum()}\")\n",
        "\n",
        "print(\"\\nScore distribution:\")\n",
        "score_dist = df['score'].value_counts().sort_index()\n",
        "for score, count in score_dist.items():\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"  Score {score}: {count:2d} summaries ({pct:4.1f}%)\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: Define selection strategy\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 2] Selection Strategy\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "selection_plan = {\n",
        "    1: {'target': 2, 'authentic': 1, 'synthetic': 1},\n",
        "    2: {'target': 3, 'authentic': 2, 'synthetic': 1},\n",
        "    3: {'target': 3, 'authentic': 2, 'synthetic': 1},\n",
        "    4: {'target': 2, 'authentic': 1, 'synthetic': 1},\n",
        "    5: {'target': 1, 'authentic': 1, 'synthetic': 0},\n",
        "    6: {'target': 1, 'authentic': 1, 'synthetic': 0}\n",
        "}\n",
        "\n",
        "print(\"\\nWill select:\")\n",
        "for score, plan in selection_plan.items():\n",
        "    print(f\"  Score {score}: {plan['target']} summaries ({plan['authentic']} auth, {plan['synthetic']} synth)\")\n",
        "\n",
        "total_target = sum(plan['target'] for plan in selection_plan.values())\n",
        "print(f\"\\nTotal: {total_target} summaries for calibration\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: Execute selection\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 3] Selecting Summaries\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "calibration_subset = []\n",
        "\n",
        "# Score 1: 1 authentic + 1 synthetic\n",
        "score_1_df = df[df['score'] == 1]\n",
        "cal_1_auth = score_1_df[score_1_df['synthetic_flag'] == False].iloc[0]\n",
        "cal_1_synth = score_1_df[score_1_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_1_auth, cal_1_synth])\n",
        "print(f\"Score 1: Selected {cal_1_auth['essay_id']} (auth), {cal_1_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 2: 2 authentic + 1 synthetic\n",
        "score_2_df = df[df['score'] == 2]\n",
        "cal_2_auth = score_2_df[score_2_df['synthetic_flag'] == False].iloc[0:2]\n",
        "cal_2_synth = score_2_df[score_2_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_2_auth.iloc[0], cal_2_auth.iloc[1], cal_2_synth])\n",
        "print(f\"Score 2: Selected {cal_2_auth.iloc[0]['essay_id']}, {cal_2_auth.iloc[1]['essay_id']} (auth), {cal_2_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 3: 2 authentic + 1 synthetic\n",
        "score_3_df = df[df['score'] == 3]\n",
        "cal_3_auth = score_3_df[score_3_df['synthetic_flag'] == False].iloc[0:2]\n",
        "cal_3_synth = score_3_df[score_3_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_3_auth.iloc[0], cal_3_auth.iloc[1], cal_3_synth])\n",
        "print(f\"Score 3: Selected {cal_3_auth.iloc[0]['essay_id']}, {cal_3_auth.iloc[1]['essay_id']} (auth), {cal_3_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 4: 1 authentic + 1 synthetic\n",
        "score_4_df = df[df['score'] == 4]\n",
        "cal_4_auth = score_4_df[score_4_df['synthetic_flag'] == False].iloc[0]\n",
        "cal_4_synth = score_4_df[score_4_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_4_auth, cal_4_synth])\n",
        "print(f\"Score 4: Selected {cal_4_auth['essay_id']} (auth), {cal_4_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 5: 1 authentic\n",
        "score_5_df = df[df['score'] == 5]\n",
        "cal_5_auth = score_5_df[score_5_df['synthetic_flag'] == False].iloc[0]\n",
        "calibration_subset.append(cal_5_auth)\n",
        "print(f\"Score 5: Selected {cal_5_auth['essay_id']} (auth)\")\n",
        "\n",
        "# Score 6: 1 authentic (only one available)\n",
        "score_6_df = df[df['score'] == 6]\n",
        "cal_6 = score_6_df.iloc[0]\n",
        "calibration_subset.append(cal_6)\n",
        "print(f\"Score 6: Selected {cal_6['essay_id']} (auth)\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: Create calibration DataFrame\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 4] Creating Calibration DataFrame\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "cal_df = pd.DataFrame(calibration_subset)\n",
        "cal_df = cal_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n‚úì Created DataFrame with {len(cal_df)} summaries\")\n",
        "print(f\"\\nScore distribution in calibration set:\")\n",
        "print(cal_df['score'].value_counts().sort_index())\n",
        "print(f\"\\nAuthentic: {(cal_df['synthetic_flag'] == False).sum()}\")\n",
        "print(f\"Synthetic: {(cal_df['synthetic_flag'] == True).sum()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: Display details\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 5] Calibration Subset Details\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"\\n{'#':<3} {'Essay ID':<25} {'Score':<6} {'Source':<8} {'Words':<6} {'Error Pattern':<45}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for idx, row in cal_df.iterrows():\n",
        "    source = \"Synthetic\" if row['synthetic_flag'] else \"Authentic\"\n",
        "    error = row['target_error_pattern'] if pd.notna(row['target_error_pattern']) else \"N/A\"\n",
        "    print(f\"{idx+1:<3} {row['essay_id']:<25} {row['score']:<6} {source:<8} {row['word_count']:<6} {error[:45]:<45}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: Save CSV to Google Drive\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 6] Saving Calibration Subset CSV\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "cal_csv_path = os.path.join(OUTPUT_DIR, 'calibration_subset.csv')\n",
        "cal_df.to_csv(cal_csv_path, index=False)\n",
        "print(f\"‚úì Saved: {cal_csv_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: Create practice summaries document\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 7] Creating Practice Summaries Document\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "output_lines = []\n",
        "output_lines.append(\"=\" * 80)\n",
        "output_lines.append(\"CALIBRATION PRACTICE SET - 12 SUMMARIES\")\n",
        "output_lines.append(\"=\" * 80)\n",
        "output_lines.append(\"\\nInstructions:\")\n",
        "output_lines.append(\"1. Score each summary across all 4 dimensions WITHOUT looking at benchmark scores\")\n",
        "output_lines.append(\"2. Use your rubric and document your reasoning\")\n",
        "output_lines.append(\"3. After scoring all 12, compare with the benchmark scores\")\n",
        "output_lines.append(\"4. Analyze discrepancies to refine your rubric interpretation\")\n",
        "output_lines.append(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "\n",
        "for idx, row in cal_df.iterrows():\n",
        "    practice_num = idx + 1\n",
        "\n",
        "    output_lines.append(f\"\\n{'='*80}\")\n",
        "    output_lines.append(f\"PRACTICE_{practice_num:02d}: {row['essay_id']}\")\n",
        "    output_lines.append(f\"{'='*80}\")\n",
        "    output_lines.append(f\"Source: {'Synthetic' if row['synthetic_flag'] else 'Authentic'}\")\n",
        "    output_lines.append(f\"Word Count: {row['word_count']}\")\n",
        "    if pd.notna(row['target_error_pattern']):\n",
        "        output_lines.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "\n",
        "    output_lines.append(f\"\\n{'-'*80}\")\n",
        "    output_lines.append(\"SUMMARY TEXT:\")\n",
        "    output_lines.append(f\"{'-'*80}\\n\")\n",
        "    output_lines.append(row['full_text'])\n",
        "    output_lines.append(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Save to text file\n",
        "practice_txt_path = os.path.join(OUTPUT_DIR, 'calibration_practice_summaries.txt')\n",
        "with open(practice_txt_path, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(output_lines))\n",
        "\n",
        "print(f\"‚úì Saved: {practice_txt_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: Create Practice IDs reference\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 8] Practice IDs for Calibration Tracker\")\n",
        "print(\"-\" * 80)\n",
        "print(\"\\nCopy these IDs into your Calibration_Tracker.xlsx:\")\n",
        "print()\n",
        "for i, essay_id in enumerate(cal_df['essay_id'], 1):\n",
        "    print(f\"PRACTICE_R1_{i:02d}: {essay_id}\")\n",
        "\n",
        "# Save to a separate reference file\n",
        "practice_ids_path = os.path.join(OUTPUT_DIR, 'calibration_practice_ids.txt')\n",
        "with open(practice_ids_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"Practice IDs for Calibration Tracker\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(\"Use these in your Calibration_Tracker.xlsx:\\n\\n\")\n",
        "    for i, essay_id in enumerate(cal_df['essay_id'], 1):\n",
        "        f.write(f\"PRACTICE_R1_{i:02d}: {essay_id}\\n\")\n",
        "\n",
        "print(f\"\\n‚úì Saved: {practice_ids_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# COMPLETION\n",
        "# =============================================================================\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"CALIBRATION SUBSET SELECTION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚úì Files saved to: {OUTPUT_DIR}\")\n",
        "print(f\"  ‚Ä¢ calibration_subset.csv (metadata)\")\n",
        "print(f\"  ‚Ä¢ calibration_practice_summaries.txt (full texts)\")\n",
        "print(f\"  ‚Ä¢ calibration_practice_ids.txt (IDs for tracker)\")\n",
        "\n",
        "print(f\"\\n‚úì Selected {len(cal_df)} summaries:\")\n",
        "print(f\"  ‚Ä¢ All 6 score levels covered\")\n",
        "print(f\"  ‚Ä¢ {(cal_df['synthetic_flag'] == False).sum()} authentic, {(cal_df['synthetic_flag'] == True).sum()} synthetic\")\n",
        "print(f\"  ‚Ä¢ Word count range: {cal_df['word_count'].min()}-{cal_df['word_count'].max()}\")\n",
        "\n",
        "print(\"\\nüìã Next steps:\")\n",
        "print(\"  1. Download the three files from your Google Drive\")\n",
        "print(\"  2. Review the practice summaries document\")\n",
        "print(\"  3. Begin Phase 1 of calibration (Rubric Study)\")\n",
        "print(\"  4. Use the practice IDs to update your Calibration_Tracker.xlsx\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feQW4BYuS4E6",
        "outputId": "f8818265-bb41-4190-c973-b358ed3c0de9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "================================================================================\n",
            "CALIBRATION SUBSET SELECTION\n",
            "================================================================================\n",
            "\n",
            "Reading from: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/data/dataset/validation_set_combined_60.csv\n",
            "Saving to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase2_Calibration/\n",
            "\n",
            "[STEP 1] Loading Dataset...\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Loaded 60 summaries\n",
            "\n",
            "Columns: ['essay_id', 'score', 'full_text', 'assignment', 'prompt_name', 'economically_disadvantaged', 'student_disability_status', 'ell_status', 'race_ethnicity', 'gender', 'source_text_1', 'source_text_2', 'source_text_3', 'source_text_4', 'synthetic_flag', 'target_error_pattern', 'generation_date', 'generation_model', 'word_count']\n",
            "\n",
            "\n",
            "Dataset Distribution:\n",
            "  Authentic (ASAP 2.0): 37\n",
            "  Synthetic (GPT-4o-Mini): 23\n",
            "\n",
            "Score distribution:\n",
            "  Score 1:  8 summaries (13.3%)\n",
            "  Score 2: 18 summaries (30.0%)\n",
            "  Score 3: 20 summaries (33.3%)\n",
            "  Score 4: 10 summaries (16.7%)\n",
            "  Score 5:  3 summaries ( 5.0%)\n",
            "  Score 6:  1 summaries ( 1.7%)\n",
            "\n",
            "\n",
            "[STEP 2] Selection Strategy\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Will select:\n",
            "  Score 1: 2 summaries (1 auth, 1 synth)\n",
            "  Score 2: 3 summaries (2 auth, 1 synth)\n",
            "  Score 3: 3 summaries (2 auth, 1 synth)\n",
            "  Score 4: 2 summaries (1 auth, 1 synth)\n",
            "  Score 5: 1 summaries (1 auth, 0 synth)\n",
            "  Score 6: 1 summaries (1 auth, 0 synth)\n",
            "\n",
            "Total: 12 summaries for calibration\n",
            "\n",
            "\n",
            "[STEP 3] Selecting Summaries\n",
            "--------------------------------------------------------------------------------\n",
            "Score 1: Selected AAAVUP14319000017665 (auth), SYNTH_V_01_S1 (synth)\n",
            "Score 2: Selected AAAVUP14319000153727, AAAVUP14319000099170 (auth), SYNTH_V_09_S2 (synth)\n",
            "Score 3: Selected AAAVUP14319000141935, AAAVUP14319000151934 (auth), SYNTH_V_18_S3 (synth)\n",
            "Score 4: Selected AAAVUP14319000017185 (auth), SYNTH_V_21_S4 (synth)\n",
            "Score 5: Selected AAAVUP14319000033223 (auth)\n",
            "Score 6: Selected AAAVUP14319000070539 (auth)\n",
            "\n",
            "\n",
            "[STEP 4] Creating Calibration DataFrame\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úì Created DataFrame with 12 summaries\n",
            "\n",
            "Score distribution in calibration set:\n",
            "score\n",
            "1    2\n",
            "2    3\n",
            "3    3\n",
            "4    2\n",
            "5    1\n",
            "6    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Authentic: 8\n",
            "Synthetic: 4\n",
            "\n",
            "\n",
            "[STEP 5] Calibration Subset Details\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "#   Essay ID                  Score  Source   Words  Error Pattern                                \n",
            "--------------------------------------------------------------------------------\n",
            "1   AAAVUP14319000017665      1      Authentic 387    Authentic student work                       \n",
            "2   SYNTH_V_01_S1             1      Synthetic 139    Severe incompleteness + fabrication          \n",
            "3   AAAVUP14319000153727      2      Authentic 286    Authentic student work                       \n",
            "4   AAAVUP14319000099170      2      Authentic 158    Authentic student work                       \n",
            "5   SYNTH_V_09_S2             2      Synthetic 191    Shallow coverage - lists facts without connec\n",
            "6   AAAVUP14319000141935      3      Authentic 263    Authentic student work                       \n",
            "7   AAAVUP14319000151934      3      Authentic 499    Authentic student work                       \n",
            "8   SYNTH_V_18_S3             3      Synthetic 252    Good summary with minor coherence gaps       \n",
            "9   AAAVUP14319000017185      4      Authentic 513    Authentic student work                       \n",
            "10  SYNTH_V_21_S4             4      Synthetic 241    Strong summary, minor accuracy detail        \n",
            "11  AAAVUP14319000033223      5      Authentic 732    Authentic student work                       \n",
            "12  AAAVUP14319000070539      6      Authentic 753    Authentic student work                       \n",
            "\n",
            "\n",
            "[STEP 6] Saving Calibration Subset CSV\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase2_Calibration/calibration_subset.csv\n",
            "\n",
            "\n",
            "[STEP 7] Creating Practice Summaries Document\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase2_Calibration/calibration_practice_summaries.txt\n",
            "\n",
            "\n",
            "[STEP 8] Practice IDs for Calibration Tracker\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Copy these IDs into your Calibration_Tracker.xlsx:\n",
            "\n",
            "PRACTICE_R1_01: AAAVUP14319000017665\n",
            "PRACTICE_R1_02: SYNTH_V_01_S1\n",
            "PRACTICE_R1_03: AAAVUP14319000153727\n",
            "PRACTICE_R1_04: AAAVUP14319000099170\n",
            "PRACTICE_R1_05: SYNTH_V_09_S2\n",
            "PRACTICE_R1_06: AAAVUP14319000141935\n",
            "PRACTICE_R1_07: AAAVUP14319000151934\n",
            "PRACTICE_R1_08: SYNTH_V_18_S3\n",
            "PRACTICE_R1_09: AAAVUP14319000017185\n",
            "PRACTICE_R1_10: SYNTH_V_21_S4\n",
            "PRACTICE_R1_11: AAAVUP14319000033223\n",
            "PRACTICE_R1_12: AAAVUP14319000070539\n",
            "\n",
            "‚úì Saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase2_Calibration/calibration_practice_ids.txt\n",
            "\n",
            "\n",
            "================================================================================\n",
            "CALIBRATION SUBSET SELECTION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "‚úì Files saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase2_Calibration/\n",
            "  ‚Ä¢ calibration_subset.csv (metadata)\n",
            "  ‚Ä¢ calibration_practice_summaries.txt (full texts)\n",
            "  ‚Ä¢ calibration_practice_ids.txt (IDs for tracker)\n",
            "\n",
            "‚úì Selected 12 summaries:\n",
            "  ‚Ä¢ All 6 score levels covered\n",
            "  ‚Ä¢ 8 authentic, 4 synthetic\n",
            "  ‚Ä¢ Word count range: 139-753\n",
            "\n",
            "üìã Next steps:\n",
            "  1. Download the three files from your Google Drive\n",
            "  2. Review the practice summaries document\n",
            "  3. Begin Phase 1 of calibration (Rubric Study)\n",
            "  4. Use the practice IDs to update your Calibration_Tracker.xlsx\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generate Calibration Benchmark Scores Answer Key\n",
        "Reads calibration_subset.csv and creates formatted answer key file\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "CALIBRATION_SUBSET_PATH = \"/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/calibration_subset.csv\"  # Adjust path as needed\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/CALIBRATION_BENCHMARK_SCORES.txt\"\n",
        "\n",
        "def create_benchmark_scores_file(input_csv, output_txt):\n",
        "    \"\"\"\n",
        "    Create formatted benchmark scores file from calibration subset CSV.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    input_csv : str\n",
        "        Path to calibration_subset.csv\n",
        "    output_txt : str\n",
        "        Path for output benchmark scores file\n",
        "    \"\"\"\n",
        "\n",
        "    # Read calibration subset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Define practice IDs and their roles\n",
        "    exemplars = {\n",
        "        'PRACTICE_01': 'Not used for blind practice - reference only',\n",
        "        'PRACTICE_02': 'EXEMPLAR - analyzed in detail in EXEMPLAR_ANALYSIS_GUIDE.md',\n",
        "        'PRACTICE_07': 'EXEMPLAR - analyzed in detail in EXEMPLAR_ANALYSIS_GUIDE.md',\n",
        "        'PRACTICE_11': 'EXEMPLAR - analyzed in detail in EXEMPLAR_ANALYSIS_GUIDE.md'\n",
        "    }\n",
        "\n",
        "    round_1 = ['PRACTICE_03', 'PRACTICE_04', 'PRACTICE_05', 'PRACTICE_06']\n",
        "    round_2 = ['PRACTICE_08', 'PRACTICE_09', 'PRACTICE_10', 'PRACTICE_12']\n",
        "\n",
        "    # Create practice_id column if it doesn't exist\n",
        "    if 'practice_id' not in df.columns:\n",
        "        # Create practice IDs based on row order\n",
        "        df['practice_id'] = [f'PRACTICE_{str(i+1).zfill(2)}' for i in range(len(df))]\n",
        "\n",
        "    # Build the output content\n",
        "    content = []\n",
        "\n",
        "    # Header\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"CALIBRATION PRACTICE SUMMARIES - BENCHMARK SCORES (ANSWER KEY)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"DO NOT LOOK AT THIS FILE UNTIL YOU HAVE SCORED ALL 9 PRACTICE SUMMARIES BLIND!\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"Instructions for Use:\")\n",
        "    content.append(\"1. Score all 9 practice summaries (PRACTICE_03 through PRACTICE_06, and\")\n",
        "    content.append(\"   PRACTICE_08 through PRACTICE_12) WITHOUT looking at this file\")\n",
        "    content.append(\"2. Record your scores in Calibration_Tracker.xlsx\")\n",
        "    content.append(\"3. AFTER completing all 9, open this file to compare your scores\")\n",
        "    content.append(\"4. Calculate agreement metrics and analyze discrepancies\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Exemplar summaries section\n",
        "    content.append(\"EXEMPLAR SUMMARIES (Study These First - Scores Already Known)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    for practice_id, note in exemplars.items():\n",
        "        row = df[df['practice_id'] == practice_id].iloc[0]\n",
        "        content.append(f\"{practice_id}: {row['essay_id']}\")\n",
        "        content.append(f\"Benchmark Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Note: {note}\")\n",
        "        content.append(\"\")\n",
        "\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Practice Round 1\n",
        "    content.append(\"PRACTICE ROUND 1 - BLIND SCORING (Complete First)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    for practice_id in round_1:\n",
        "        row = df[df['practice_id'] == practice_id].iloc[0]\n",
        "        content.append(f\"{practice_id}: {row['essay_id']}\")\n",
        "        content.append(f\"Benchmark Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Word Count: {row['word_count']}\")\n",
        "        if row['synthetic_flag'] == 1 and pd.notna(row['target_error_pattern']):\n",
        "            content.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "        content.append(\"\")\n",
        "\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Practice Round 2\n",
        "    content.append(\"PRACTICE ROUND 2 - BLIND SCORING (Complete Second)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    for practice_id in round_2:\n",
        "        row = df[df['practice_id'] == practice_id].iloc[0]\n",
        "        content.append(f\"{practice_id}: {row['essay_id']}\")\n",
        "        content.append(f\"Benchmark Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Word Count: {row['word_count']}\")\n",
        "        if row['synthetic_flag'] == 1 and pd.notna(row['target_error_pattern']):\n",
        "            content.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "        content.append(\"\")\n",
        "\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Score distribution\n",
        "    content.append(\"SCORE DISTRIBUTION IN PRACTICE SET\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    score_counts = df['score'].value_counts().sort_index()\n",
        "    for score, count in score_counts.items():\n",
        "        practice_ids = df[df['score'] == score]['practice_id'].tolist()\n",
        "        ids_str = ', '.join(practice_ids)\n",
        "\n",
        "        # Identify exemplars\n",
        "        exemplar_ids = [pid for pid in practice_ids if pid in exemplars]\n",
        "        if exemplar_ids:\n",
        "            ids_str += f\" ({', '.join([f'{pid} - exemplar' for pid in exemplar_ids])})\"\n",
        "\n",
        "        content.append(f\"Score {score}: {count} {'summary' if count == 1 else 'summaries'} ({ids_str})\")\n",
        "\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Agreement metrics section\n",
        "    content.append(\"AGREEMENT METRICS TO CALCULATE\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"After comparing your scores to these benchmarks:\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"1. EXACT AGREEMENT: How many summaries did you score exactly the same?\")\n",
        "    content.append(\"   Target: ‚â• 60% (at least 6 out of 9)\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"2. ADJACENT AGREEMENT: How many were within ¬±1 point?\")\n",
        "    content.append(\"   Target: > 85% (at least 8 out of 9)\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"3. MEAN ABSOLUTE ERROR (MAE): Average distance from benchmark\")\n",
        "    content.append(\"   Target: < 0.5 points per dimension\")\n",
        "    content.append(\"   \")\n",
        "    content.append(\"   Formula: Sum of |your score - benchmark| √∑ number of summaries\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"4. PATTERNS IN DISCREPANCIES:\")\n",
        "    content.append(\"   - Do you tend to score higher or lower than benchmarks?\")\n",
        "    content.append(\"   - Are discrepancies concentrated in specific dimensions?\")\n",
        "    content.append(\"   - Are errors larger for certain score levels?\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Next steps\n",
        "    content.append(\"NEXT STEPS AFTER COMPARISON\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"1. Calculate your agreement metrics\")\n",
        "    content.append(\"2. Identify patterns in discrepancies\")\n",
        "    content.append(\"3. Create decision rules for borderline cases\")\n",
        "    content.append(\"4. Review rubric areas where you struggled\")\n",
        "    content.append(\"5. Proceed to Practice Round 2 with refined approach\")\n",
        "    content.append(\"6. After Round 2, assess readiness for full validation scoring\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "\n",
        "    # Write to file\n",
        "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(content))\n",
        "\n",
        "    print(f\"‚úì Benchmark scores file created: {output_txt}\")\n",
        "    print(f\"  Total summaries: {len(df)}\")\n",
        "    print(f\"  Exemplars: {len(exemplars)}\")\n",
        "    print(f\"  Practice Round 1: {len(round_1)}\")\n",
        "    print(f\"  Practice Round 2: {len(round_2)}\")\n",
        "    print(f\"\\nScore distribution:\")\n",
        "    for score, count in score_counts.items():\n",
        "        print(f\"  Score {score}: {count}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the benchmark scores file\n",
        "    create_benchmark_scores_file(CALIBRATION_SUBSET_PATH, OUTPUT_PATH)\n",
        "\n",
        "    print(\"\\n‚úì Generation complete!\")\n",
        "    print(f\"\\nReminder: DO NOT open {OUTPUT_PATH} until after blind scoring!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCC-EuslhC0D",
        "outputId": "2ed5054e-4ab9-4ebd-ccd4-1833d7fdf447"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Benchmark scores file created: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/CALIBRATION_BENCHMARK_SCORES.txt\n",
            "  Total summaries: 12\n",
            "  Exemplars: 4\n",
            "  Practice Round 1: 4\n",
            "  Practice Round 2: 4\n",
            "\n",
            "Score distribution:\n",
            "  Score 1: 2\n",
            "  Score 2: 3\n",
            "  Score 3: 3\n",
            "  Score 4: 2\n",
            "  Score 5: 1\n",
            "  Score 6: 1\n",
            "\n",
            "‚úì Generation complete!\n",
            "\n",
            "Reminder: DO NOT open /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/CALIBRATION_BENCHMARK_SCORES.txt until after blind scoring!\n"
          ]
        }
      ]
    }
  ]
}