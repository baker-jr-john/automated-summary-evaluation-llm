{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "16rzCEir-3WyU2xJobpiuSnjGvjfBtkDB",
      "authorship_tag": "ABX9TyMT9tYaKqiE8YnADmfESsOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baker-jr-john/automated-summary-evaluation-llm/blob/main/automated_summary_evaluation_llm_rubric_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P_OlYgvXG2jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26218d9-ffce-4bdf-de1c-86239b60ea34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Columns: ['essay_id', 'score', 'full_text', 'assignment', 'prompt_name', 'economically_disadvantaged', 'student_disability_status', 'ell_status', 'race_ethnicity', 'gender', 'source_text_1', 'source_text_2', 'source_text_3', 'source_text_4']\n",
            "\n",
            "Shape: (24728, 14)\n",
            "\n",
            "First few rows:\n",
            "               essay_id  score  \\\n",
            "0  AAAVUP14319000159574      4   \n",
            "1  AAAVUP14319000159542      2   \n",
            "2  AAAVUP14319000159461      3   \n",
            "3  AAAVUP14319000159420      2   \n",
            "4  AAAVUP14319000159419      2   \n",
            "\n",
            "                                           full_text  \\\n",
            "0  The author suggests that studying Venus is wor...   \n",
            "1  NASA is fighting to be alble to to go to Venus...   \n",
            "2  \"The Evening Star\", is one of the brightest po...   \n",
            "3  The author supports this idea because from rea...   \n",
            "4  How the author supports this idea is that he s...   \n",
            "\n",
            "                                          assignment      prompt_name  \\\n",
            "0  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "1  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "2  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "3  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "4  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
            "\n",
            "       economically_disadvantaged            student_disability_status  \\\n",
            "0      Economically disadvantaged      Identified as having disability   \n",
            "1  Not economically disadvantaged  Not identified as having disability   \n",
            "2      Economically disadvantaged      Identified as having disability   \n",
            "3      Economically disadvantaged  Not identified as having disability   \n",
            "4      Economically disadvantaged  Not identified as having disability   \n",
            "\n",
            "  ell_status          race_ethnicity gender  \\\n",
            "0         No  Black/African American      F   \n",
            "1         No         Hispanic/Latino      F   \n",
            "2         No                   White      M   \n",
            "3        Yes         Hispanic/Latino      F   \n",
            "4        Yes         Hispanic/Latino      M   \n",
            "\n",
            "                                       source_text_1 source_text_2  \\\n",
            "0  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "1  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "2  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "3  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "4  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
            "\n",
            "  source_text_3 source_text_4  \n",
            "0           NaN           NaN  \n",
            "1           NaN           NaN  \n",
            "2           NaN           NaN  \n",
            "3           NaN           NaN  \n",
            "4           NaN           NaN  \n",
            "\n",
            "Unique prompts:\n",
            "prompt_name\n",
            "Driverless cars                     6170\n",
            "Facial action coding system         4883\n",
            "Exploring Venus                     4480\n",
            "The Face on Mars                    3015\n",
            "\"A Cowboy Who Rode the Waves\"       2175\n",
            "Does the electoral college work?    2046\n",
            "Car-free cities                     1959\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Score distribution:\n",
            "score\n",
            "1    1751\n",
            "2    6847\n",
            "3    9021\n",
            "4    5553\n",
            "5    1356\n",
            "6     200\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Load the dataset - use comma separator (default for CSV)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                 encoding='ISO-8859-1')\n",
        "\n",
        "# Explore the structure\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"\\nShape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check what types of assignments/prompts exist\n",
        "print(\"\\nUnique prompts:\")\n",
        "print(df['prompt_name'].value_counts())\n",
        "\n",
        "# Look at score distribution\n",
        "print(\"\\nScore distribution:\")\n",
        "print(df['score'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the actual assignment prompts to understand task types\n",
        "print(\"=\" * 80)\n",
        "for prompt in df['prompt_name'].unique():\n",
        "    subset = df[df['prompt_name'] == prompt]\n",
        "    print(f\"\\n{prompt} ({len(subset)} responses)\")\n",
        "    print(f\"Score range: {subset['score'].min()}-{subset['score'].max()}\")\n",
        "    print(\"\\nAssignment:\")\n",
        "    print(subset['assignment'].iloc[0][:300] + \"...\")  # First 300 chars\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "JVwaIb36Fmr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f856da2e-7e26-47a2-c3e4-52324813c407"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "\n",
            "Exploring Venus (4480 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "In \"The Challenge of Exploring Venus,\" the author suggests studying Venus is a worthy pursuit despite the dangers it presents. Using details from the article, write an essay evaluating how well the author supports this idea. Be sure to include: a claim that evaluates how well the author supports the...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Facial action coding system (4883 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "In the article \"Making Mona Lisa Smile,\" the author describes how a new technology called the Facial Action Coding System enables computers to identify human emotions. Using details from the article, write an essay arguing whether the use of this technology to read the emotional expressions of stude...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "The Face on Mars (3015 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "You have read the article 'Unmasking the Face on Mars.' Imagine you are a scientist at NASA discussing the Face with someone who thinks it was created by aliens. Using information in the article, write an argumentative essay to convince someone that the Face is just a natural landform.Be sure to inc...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\"A Cowboy Who Rode the Waves\" (2175 responses)\n",
            "Score range: 1-5\n",
            "\n",
            "Assignment:\n",
            "You have just read the article, 'A Cowboy Who Rode the Waves.' Luke's participation in the Seagoing Cowboys program allowed him to experience adventures and visit many unique places. Using information from the article, write an argument from Luke's point of view convincing others to participate in t...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Driverless cars (6170 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "In the article √¢¬Ä¬úDriverless Cars are Coming,√¢¬Ä¬ù the author presents both positive and negative aspects of driverless cars. Using details from the article, create an argument for or against the development of these cars.  Be sure to include: your position on driverless cars; appropriate details from...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Does the electoral college work? (2046 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Car-free cities (1959 responses)\n",
            "Score range: 1-6\n",
            "\n",
            "Assignment:\n",
            "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise a...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for Exploring Venus responses\n",
        "venus_df = df[df['prompt_name'] == 'Exploring Venus'].copy()\n",
        "\n",
        "print(f\"Total Venus responses: {len(venus_df)}\")\n",
        "print(f\"\\nScore distribution:\")\n",
        "print(venus_df['score'].value_counts().sort_index())\n",
        "\n",
        "# Look at the source text\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SOURCE TEXT:\")\n",
        "print(\"=\"*80)\n",
        "print(venus_df['source_text_1'].iloc[0])\n",
        "\n",
        "# Examine sample responses across score levels\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAMPLE RESPONSES BY SCORE LEVEL:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for score in sorted(venus_df['score'].unique()):\n",
        "    print(f\"\\n--- SCORE {score} EXAMPLE ---\")\n",
        "    sample = venus_df[venus_df['score'] == score].iloc[0]\n",
        "    print(sample['full_text'][:400] + \"...\")"
      ],
      "metadata": {
        "id": "BrHaKRsxGigk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df713720-1ec7-47f0-ce47-e157feb6375a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Venus responses: 4480\n",
            "\n",
            "Score distribution:\n",
            "score\n",
            "1     567\n",
            "2    1419\n",
            "3    1469\n",
            "4     808\n",
            "5     175\n",
            "6      42\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n",
            "SOURCE TEXT:\n",
            "================================================================================\n",
            "The Challenge of Exploring Venus\n",
            "Venus, sometimes called the √¢¬Ä¬úEvening Star,√¢¬Ä¬ù is one of the brightest points of light in the night sky, making it simple for even and amateur stargazer to spot. However, this nickname is misleading since Venus is actually a planet. While Venus is simple to see from the distant but safe vantage point of Earth, it has proved a very challenging place to examine more closely. \n",
            "Often referred to as Earth's √¢¬Ä¬útwin,√¢¬Ä¬ù Venus is the closest planet to Earth in terms of density and size, and occasionally the closest in distance too. Earth, Venus, and Mars, our other planetary neighbor, orbit the sun at different speeds. These differences in speed mean that sometimes we are closer to Mars and other times to Venus. Because Venus is sometimes right around the corner - in space terms - humans have spent numerous spacecraft to land on this cloud-draped world. Each previous mission was unmanned, and for good reason, since no spacecraft survived the landing for more than a few hours. Maybe this issue explains why not a single spaceship has touched down of Venus in more than three decades. Numberous factors contribute to Venus's reputation as a challenging planet for humans to study, despite its proximity to us. \n",
            "A thick atmosphere of almost 97 percent carbon dioxide blankets Venus. Even more challenging are the clouds of highly corrosive sulfuric acid in Venus's atmosphere. On the planet's surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet. These conditions are far more extreme than anything humans encounter on Earth; such an environment would crush even a submarine accustomed to diving to the deepest parts of our oceans and would liquefy many metals. Also notable, Venus has the hottest surface temperature of any planet in our solar system, even though Mercury is closer to our sun. Beyond high presure and heat, Venusian geology and weather present additional impediments like erupting volcanoes, powerful earthquakes, and frequent lightning strikes to probes seeking to land on its surface. \n",
            "If our sister is so inhospitable, why are scientists even discussing further visits to its surface? Astronomers are fascinated by Venus beccause it may well once have been the most Earth-like planet in our solar system. Long ago, Venus was probably covered largely with oceans and could have supported various forms of life, just like Earth. Today, Venus still has some features that are analogous to those on Earth. The planet has a surface of rocky sediment and includes familiar features such as valleys, mountains, and craters. Furthermore, recall that Venus can sometimes be our nearest option for a planetary visit, a crucial consideration given the long time frames of space travel. The value of returning to Venus seems indisputable, but what are the options for making such a mission both safe and scientifically productive?\n",
            "The National Aeronautics and Space Administration (NASA) has one particularly compelling idea for sending humans to study Venus. NASA's possible solution to the hostile conditions on the surface of Venus would allow scientists to float above the fray. Imagine a blimp-like vehicle hovering 30 or so miles above the roiling Venusian landscape. Just as our jet airplanes travel at a higher altitude to fly over many storms, a vehicle hovering over Venus would avoid the unfriendly ground conditions by staying up and out of their way. At thirty-plus miles above the surface, temperatures would still be toasty at around 170 degrees Farenheit, but the air pressure would be close to that of sea level on Earth. Solar power would be plentiful, and radiation would not exceed Earth levels. Not easy conditions, but survivable for humans.\n",
            "However, peering at Venus from a ship orbiting or hovering safely far above the planet can provide only limited insight on ground conditions rendering standard forms of photography and videography ineffective. More importantly, researchers cannot take samples of rock, gas, or anything else, from a distance. Therefore, scientists seeking to conduct a thorough mission to understand Venus would need to get up close and personal despite the risks. Or maybe we should think of them as challenges. Many researchers are working on innovattions that would allow our machines to last long enough to contribute meaningfully to our knowledge of Venus. \n",
            "NASA is working on other approaches to studying Venus. For example, some simplified electronics made of silicon carbide have been tested in a chamber simuulating the chaos of Venus's surface and have laster for three weeks in such conditions. Another project is looking back to an old technology called mechanical computers. These devices were first envisioned in the 1800s and played an important role int he 1940s during World War II. The thought of computers existing in those days may sound shocking, but these devices make calculations by using gears and levers and do not require electronics at all. Modern commputers are enormously powerful, flexible, and quick, but tend to be more delicate when it comes to extreme physical conditions. Just imagine exposing a cell phone or tablet to acid or heat capable of melting tin. By comparison, systems that use mechanical parts can be made mroe resistant to pressure, heat, and other forces. \n",
            "Striving to meet the challenge presented by Venus has value, not only because of the insight to be gained on the planet itself, but also because human curiousity will likely lead us into many equally intimidating endeavors. Our travels on Earth and beyond should not be limited by dangers and doubts but should be expanded to meet the very edges of imagination and innovation.\n",
            "\n",
            "================================================================================\n",
            "SAMPLE RESPONSES BY SCORE LEVEL:\n",
            "================================================================================\n",
            "\n",
            "--- SCORE 1 EXAMPLE ---\n",
            "In the story of √Ç¬®The Challenge of Exploring Venus√Ç¬® Venus is one of the brightest point of light in the night sky, It√Ç¬¥s also the second planet from our sun. From earth people can see Venus from a safe distance. The Earth has a planet that is closer to it and it√Ç¬¥s called Venus. Earth and Veus are often referred as twins. Venus has blanets of thick atmosphere of 97 percent carbon dioxide. The mor...\n",
            "\n",
            "--- SCORE 2 EXAMPLE ---\n",
            "NASA is fighting to be alble to to go to Venus . They have been researching diffrent methods on how to sustaine life on the planet . In the text it says that \"Our travels on earth and beyond should not be limited by dangers but should be expanded ..\"(8) Yes we are trying to figer out our planet earth still but there may be diffrent ways we can help explore the ocean and lower in the earths core .\n",
            "...\n",
            "\n",
            "--- SCORE 3 EXAMPLE ---\n",
            "\"The Evening Star\", is one of the brightest points of the light on the sky at night. Venus is a planet, Also Venus is the second planet\n",
            "\n",
            "from the sun. Venus is a simple to see from the distant but safe vantage point on Earth. It proved that a very challeging place to examine more closely on Earth. It is reffered to Earths twin. Venus is also the closeset planet to Earth and has density and size.\n",
            "\n",
            "...\n",
            "\n",
            "--- SCORE 4 EXAMPLE ---\n",
            "The author suggests that studying Venus is worthy enough even though it is very dangerous. The author mentioned that on the planet's surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet . His solution to survive this weather that is dangerous to us humans is to allow them to float above the fray. A \"bl...\n",
            "\n",
            "--- SCORE 5 EXAMPLE ---\n",
            "In the passage, \"The Challenge of Exploring Venus,\" the author supports that studying Venus is a worthy pursuit despite the dangers it presents. The author starts with facts about Venus to just bring general facts the the public in the passage. The author does not support his idea in the passage well. The author points out more dangers than he points out the reasons that pursuing Venus is a benefi...\n",
            "\n",
            "--- SCORE 6 EXAMPLE ---\n",
            "The author's claim of studying Venus is a worthy pursuit because Venus is closely related to Earth, Venus has a enviroment that is similar to Earth, and scientists want to explore more of what Venus has to offer.\n",
            "\n",
            "The first claim of why the author supports scientists studying Venus is that Venus is closely related to Earth. In the passage, it states,\" Often referred to as Earth's twin, Venus is th...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Calculate proportional samples (36 total based on original 6-point distribution)\n",
        "# Proportions: 1=13%, 2=32%, 3=33%, 4=18%, 5=4%, 6=1%\n",
        "samples_needed = {\n",
        "    1: 5,   # ~13% (567/4480)\n",
        "    2: 11,  # ~32% (1,419/4480)\n",
        "    3: 12,  # ~33% (1,469/4480)\n",
        "    4: 6,   # ~18% (808/4480)\n",
        "    5: 2,   # ~4% (175/4480)\n",
        "    6: 0    # ~1% (42/4480) - too few to sample reliably, we'll grab these separately\n",
        "}\n",
        "\n",
        "# For score 6, let's just include all available or sample very carefully\n",
        "# Since there are only 42 total, we could include 1-2 in the validation set\n",
        "\n",
        "sampled_rows = []\n",
        "for score, n_samples in samples_needed.items():\n",
        "    if n_samples > 0:\n",
        "        score_subset = venus_df[venus_df['score'] == score]\n",
        "        if len(score_subset) >= n_samples:\n",
        "            sample = score_subset.sample(n=n_samples, random_state=42)\n",
        "            sampled_rows.append(sample)\n",
        "\n",
        "# For score 6, sample 1 if we want to include it\n",
        "score_6_subset = venus_df[venus_df['score'] == 6]\n",
        "if len(score_6_subset) > 0:\n",
        "    score_6_sample = score_6_subset.sample(n=1, random_state=42)\n",
        "    sampled_rows.append(score_6_sample)\n",
        "\n",
        "venus_validation_sample = pd.concat(sampled_rows)\n",
        "\n",
        "print(f\"\\nSampled {len(venus_validation_sample)} Venus responses for validation\")\n",
        "print(\"\\n6-point score distribution in sample:\")\n",
        "print(venus_validation_sample['score'].value_counts().sort_index())\n",
        "print(\"\\nPercentages:\")\n",
        "print(venus_validation_sample['score'].value_counts(normalize=True).sort_index() * 100)\n",
        "\n",
        "# Save validation sample\n",
        "venus_validation_sample.to_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_venus_36.csv', index=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved validation sample (6-point scale)!\")"
      ],
      "metadata": {
        "id": "5Kx5_6GEHlfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91af5177-e0d0-4659-c8d5-81f5152467e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sampled 37 Venus responses for validation\n",
            "\n",
            "6-point score distribution in sample:\n",
            "score\n",
            "1     5\n",
            "2    11\n",
            "3    12\n",
            "4     6\n",
            "5     2\n",
            "6     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentages:\n",
            "score\n",
            "1    13.513514\n",
            "2    29.729730\n",
            "3    32.432432\n",
            "4    16.216216\n",
            "5     5.405405\n",
            "6     2.702703\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "‚úÖ Saved validation sample (6-point scale)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# QUICK TEST: Generate 3 Synthetic Examples\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive, userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Load Venus source text\n",
        "df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                 encoding='ISO-8859-1')\n",
        "venus_df = df[df['prompt_name'] == 'Exploring Venus']\n",
        "VENUS_SOURCE = venus_df['source_text_1'].iloc[0]\n",
        "VENUS_ASSIGNMENT = venus_df['assignment'].iloc[0]\n",
        "\n",
        "# Rubric\n",
        "RUBRIC = \"\"\"\n",
        "COMPLETENESS (1-5): Coverage of main ideas and supporting details\n",
        "ACCURACY (1-5): Factual correctness and faithful representation\n",
        "COHERENCE (1-5): Organization, transitions, logical flow\n",
        "CONCISENESS (1-5): Appropriate length without repetition\n",
        "\"\"\"\n",
        "\n",
        "def generate_example(essay_id, score, error_type, instructions, word_target):\n",
        "    prompt = f\"\"\"You are simulating a grade 7-8 middle school student writing an evaluative essay.\n",
        "\n",
        "ASSIGNMENT: {VENUS_ASSIGNMENT}\n",
        "\n",
        "SOURCE TEXT: {VENUS_SOURCE}\n",
        "\n",
        "RUBRIC: {RUBRIC}\n",
        "\n",
        "TASK: Write a student response earning score {score}/6 with these characteristics:\n",
        "{instructions}\n",
        "\n",
        "Target length: {word_target} words\n",
        "Use authentic middle school vocabulary and style.\n",
        "Write only the student essay (no meta-commentary):\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You simulate authentic middle school writing for research.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.9,\n",
        "            max_tokens=800\n",
        "        )\n",
        "\n",
        "        text = response.choices[0].message.content.strip()\n",
        "\n",
        "        return {\n",
        "            'essay_id': essay_id,\n",
        "            'score': score,\n",
        "            'full_text': text,\n",
        "            'synthetic_flag': True,\n",
        "            'target_error_pattern': error_type,\n",
        "            'word_count': len(text.split()),\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'assignment': VENUS_ASSIGNMENT,\n",
        "            'prompt_name': 'Exploring Venus',\n",
        "            'source_text_1': VENUS_SOURCE\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# TEST: Generate 3 examples\n",
        "configs = [\n",
        "    {'essay_id': 'SYNTH_V_01_S1', 'score': 1, 'error_type': 'Severe incompleteness + fabrication',\n",
        "     'word_target': '100-150',\n",
        "     'instructions': 'Cover only 1-2 superficial details. Include 2-3 fabricated facts. Show fundamental misunderstanding. Random organization.'},\n",
        "\n",
        "    {'essay_id': 'SYNTH_V_04_S2', 'score': 2, 'error_type': 'Completeness gap',\n",
        "     'word_target': '150-200',\n",
        "     'instructions': 'Identify main claim correctly but provide only 1-2 vague examples. Omit specific evidence (temperatures, NASA solutions). Very superficial.'},\n",
        "\n",
        "    {'essay_id': 'SYNTH_V_11_S3', 'score': 3, 'error_type': 'Good content, weak coherence',\n",
        "     'word_target': '220-250',\n",
        "     'instructions': 'Cover all main ideas with adequate detail. Use awkward transitions. Random ordering. Choppy flow. Good content, poor organization.'},\n",
        "]\n",
        "\n",
        "results = []\n",
        "for i, cfg in enumerate(configs, 1):\n",
        "    print(f\"[{i}/3] Generating {cfg['essay_id']}...\", end=\" \")\n",
        "    result = generate_example(**cfg)\n",
        "    if result:\n",
        "        results.append(result)\n",
        "        print(f\"‚úì ({result['word_count']} words)\")\n",
        "        print(f\"Preview: {result['full_text'][:200]}...\\n\")\n",
        "    time.sleep(1)\n",
        "\n",
        "# Save test results\n",
        "test_df = pd.DataFrame(results)\n",
        "test_path = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/test_synthetic_3.csv'\n",
        "test_df.to_csv(test_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Generated {len(results)} test examples\")\n",
        "print(f\"üìÅ Saved to: {test_path}\")\n",
        "print(\"\\nüëÄ Review these examples. If they look good, proceed to full generation!\")"
      ],
      "metadata": {
        "id": "qhg3B2EA7w6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d66e50c-876e-4e71-ea01-12967a5a963e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[1/3] Generating SYNTH_V_01_S1... ‚úì (130 words)\n",
            "Preview: In \"The Challenge of Exploring Venus,\" the author talks about studying Venus, but I think they don't do a good job explaining why it's worth it. They mention that Venus has volcanoes and can be really...\n",
            "\n",
            "[2/3] Generating SYNTH_V_04_S2... ‚úì (161 words)\n",
            "Preview: In \"The Challenge of Exploring Venus,\" the author argues that studying Venus is worth it even though it‚Äôs a really dangerous place. I think the author does an okay job of explaining this idea, but not...\n",
            "\n",
            "[3/3] Generating SYNTH_V_11_S3... ‚úì (235 words)\n",
            "Preview: In \"The Challenge of Exploring Venus,\" the author argues that studying Venus is a valuable goal, even though it is dangerous. While the article shares great information about Venus, the author could h...\n",
            "\n",
            "‚úÖ Generated 3 test examples\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/test_synthetic_3.csv\n",
            "\n",
            "üëÄ Review these examples. If they look good, proceed to full generation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# REGENERATE 2 EXAMPLES WITH REFINED PROMPTS\n",
        "# ========================================\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Load Venus source text (if not already loaded)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                 encoding='ISO-8859-1')\n",
        "venus_df = df[df['prompt_name'] == 'Exploring Venus']\n",
        "VENUS_SOURCE = venus_df['source_text_1'].iloc[0]\n",
        "VENUS_ASSIGNMENT = venus_df['assignment'].iloc[0]\n",
        "\n",
        "# Rubric\n",
        "RUBRIC = \"\"\"\n",
        "COMPLETENESS (1-5): Coverage of main ideas and supporting details\n",
        "ACCURACY (1-5): Factual correctness and faithful representation\n",
        "COHERENCE (1-5): Organization, transitions, logical flow\n",
        "CONCISENESS (1-5): Appropriate length without repetition\n",
        "\"\"\"\n",
        "\n",
        "# Generation function\n",
        "def generate_example(essay_id, score, error_type, instructions, word_target):\n",
        "    prompt = f\"\"\"You are simulating a grade 7-8 middle school student writing an evaluative essay.\n",
        "\n",
        "ASSIGNMENT: {VENUS_ASSIGNMENT}\n",
        "\n",
        "SOURCE TEXT: {VENUS_SOURCE}\n",
        "\n",
        "RUBRIC: {RUBRIC}\n",
        "\n",
        "TASK: Write a student response earning score {score}/6 with these characteristics:\n",
        "{instructions}\n",
        "\n",
        "Target length: {word_target} words\n",
        "Use authentic middle school vocabulary and style.\n",
        "Write only the student essay (no meta-commentary):\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You simulate authentic middle school writing for research.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.9,\n",
        "            max_tokens=800\n",
        "        )\n",
        "\n",
        "        text = response.choices[0].message.content.strip()\n",
        "\n",
        "        return {\n",
        "            'essay_id': essay_id,\n",
        "            'score': score,\n",
        "            'full_text': text,\n",
        "            'synthetic_flag': True,\n",
        "            'target_error_pattern': error_type,\n",
        "            'word_count': len(text.split()),\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'assignment': VENUS_ASSIGNMENT,\n",
        "            'prompt_name': 'Exploring Venus',\n",
        "            'source_text_1': VENUS_SOURCE\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# ========================================\n",
        "# REFINED CONFIGURATIONS (THE KEY CHANGES)\n",
        "# ========================================\n",
        "\n",
        "refined_configs = [\n",
        "    # SCORE 1 - REVISED for more chaos\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_01_S1_REVISED',\n",
        "        'score': 1,\n",
        "        'error_type': 'Severe incompleteness + fabrication',\n",
        "        'word_target': '100-150',\n",
        "        'instructions': \"\"\"Cover only 1-2 superficial details like \"Venus is bright\" or \"it's hot.\"\n",
        "Include 2-3 fabricated facts (e.g., say \"hotter than the sun\" or \"NASA already went there\").\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump between totally unrelated ideas with NO logical connections\n",
        "- NO clear introduction-body-conclusion structure\n",
        "- Let ideas trail off or suddenly change direction mid-thought\n",
        "- Use only simple transitions: \"Also,\" \"And,\" or just start new sentences randomly\n",
        "- Make at least 2-3 sentences that don't connect to anything around them\n",
        "- Reader should feel confused trying to follow your point\n",
        "\n",
        "Example of scattered style you should use:\n",
        "\"Venus is really hot I think. Also there's blimps or something? The article talks about dangers but I can't remember. And they should explore Mars instead because it's better. Venus has acid maybe. I heard NASA already landed there but it broke. Also space is cool.\"\n",
        "\n",
        "Show you fundamentally misunderstood the assignment. Make it feel random and unfocused.\"\"\"\n",
        "    },\n",
        "\n",
        "    # SCORE 3 - REVISED for choppier flow\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_11_S3_REVISED',\n",
        "        'score': 3,\n",
        "        'error_type': 'Good content, weak coherence',\n",
        "        'word_target': '220-250',\n",
        "        'instructions': \"\"\"Cover ALL main ideas with GOOD specific details:\n",
        "- Dangers: 800¬∞F temperature, sulfuric acid, 97% CO2 atmosphere, 90x pressure\n",
        "- Solutions: NASA's blimp at 30 miles altitude, mechanical computers, silicon carbide\n",
        "- Value: Venus may have had oceans, Earth's twin, scientific curiosity\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing,\" \"So,\" \"Plus\"\n",
        "- NEVER use sophisticated ones: \"Furthermore,\" \"Additionally,\" \"Moreover,\" \"In conclusion\"\n",
        "- Present good ideas but in somewhat random order - jump between topics\n",
        "- Make each paragraph feel disconnected from the previous one\n",
        "\n",
        "Example of choppy style you should use:\n",
        "\"The author talks about Venus being super dangerous. It's like 800 degrees with sulfuric acid everywhere and 97% carbon dioxide. Also NASA has this idea about using blimps to float above Venus at like 30 miles up. And the temperature would still be hot but humans could survive. Plus Venus might have had oceans a long time ago so that's why scientists care. Another thing is they're making mechanical computers that can handle the extreme heat and pressure.\"\n",
        "\n",
        "Reader should think: \"This student clearly understood the article and has good details, but the organization and flow are rough. It feels choppy.\"\n",
        "\n",
        "DO NOT write a polished conclusion that ties everything together - make it feel more abrupt.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# ========================================\n",
        "# GENERATE THE 2 REVISED EXAMPLES\n",
        "# ========================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GENERATING 2 REVISED EXAMPLES WITH REFINED PROMPTS\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "\n",
        "revised_results = []\n",
        "for i, cfg in enumerate(refined_configs, 1):\n",
        "    print(f\"[{i}/2] Generating {cfg['essay_id']}...\")\n",
        "    print(f\"Target: {cfg['error_type']}\")\n",
        "    print()\n",
        "\n",
        "    result = generate_example(**cfg)\n",
        "\n",
        "    if result:\n",
        "        revised_results.append(result)\n",
        "        print(f\"‚úì Generated! ({result['word_count']} words)\\n\")\n",
        "        print(f\"FULL TEXT:\")\n",
        "        print(\"-\"*60)\n",
        "        print(result['full_text'])\n",
        "        print(\"-\"*60)\n",
        "        print()\n",
        "\n",
        "    time.sleep(2)  # Rate limiting\n",
        "\n",
        "# ========================================\n",
        "# SAVE REVISED EXAMPLES\n",
        "# ========================================\n",
        "\n",
        "if revised_results:\n",
        "    revised_df = pd.DataFrame(revised_results)\n",
        "    revised_path = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/test_synthetic_REVISED.csv'\n",
        "    revised_df.to_csv(revised_path, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ REGENERATION COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üìÅ Saved to: {revised_path}\")\n",
        "    print()\n",
        "    print(\"üìä COMPARISON:\")\n",
        "    print(f\"  Original Score 1: 129 words, somewhat coherent\")\n",
        "    print(f\"  Revised Score 1:  {revised_results[0]['word_count']} words\")\n",
        "    print()\n",
        "    print(f\"  Original Score 3: 241 words, too smooth\")\n",
        "    print(f\"  Revised Score 3:  {revised_results[1]['word_count']} words\")\n",
        "    print()\n",
        "    print(\"üîç REVIEW THE TEXT ABOVE\")\n",
        "    print(\"   Check if Score 1 now feels scattered/chaotic\")\n",
        "    print(\"   Check if Score 3 now feels choppy but has good content\")\n",
        "    print()\n",
        "    print(\"‚úÖ If satisfied ‚Üí Proceed to STEP 2\")\n",
        "    print(\"‚ùå If not quite right ‚Üí Adjust instructions and regenerate\")"
      ],
      "metadata": {
        "id": "sFOWrXRhi7az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3063ce78-a335-40b3-bdc2-7797fc6099a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "============================================================\n",
            "GENERATING 2 REVISED EXAMPLES WITH REFINED PROMPTS\n",
            "============================================================\n",
            "\n",
            "[1/2] Generating SYNTH_V_01_S1_REVISED...\n",
            "Target: Severe incompleteness + fabrication\n",
            "\n",
            "‚úì Generated! (139 words)\n",
            "\n",
            "FULL TEXT:\n",
            "------------------------------------------------------------\n",
            "Venus is really hot, like, hotter than the sun, I think. The article says it has clouds, which are not nice at all. NASA already went there, but the spaceship broke, so that's bad. Also, people say Venus is bright in the sky, but that doesn‚Äôt mean it‚Äôs safe. And they should explore Mars instead because it‚Äôs better for studying life maybe. Venus has acid and volcanoes, which seems dangerous, but it kind of sounds exciting too like a video game. There‚Äôs blimps or something that could fly over it to keep people safe, but I don‚Äôt get how that works. Also, the atmosphere is weird and has carbon, I think. The author talks about innovations, but why don‚Äôt they just forget it? Space is cool but Venus sounds too risky. So, yeah, that‚Äôs why studying Venus is confusing.\n",
            "------------------------------------------------------------\n",
            "\n",
            "[2/2] Generating SYNTH_V_11_S3_REVISED...\n",
            "Target: Good content, weak coherence\n",
            "\n",
            "‚úì Generated! (240 words)\n",
            "\n",
            "FULL TEXT:\n",
            "------------------------------------------------------------\n",
            "In the article \"The Challenge of Exploring Venus,\" the author shows that studying Venus is worth it, even though it‚Äôs super dangerous. The author talks about Venus being super dangerous. It‚Äôs like 800 degrees with sulfuric acid everywhere and 97% carbon dioxide. The pressure is 90 times more than on Earth, which is crazy. This makes it hard for humans to actually study Venus up close. \n",
            "\n",
            "And NASA has this idea about using blimps to float above Venus at like 30 miles up. This way, they can avoid the really harsh conditions on the surface. The temperature would still be hot but humans could survive. Plus, Venus might have had oceans a long time ago, so that‚Äôs why scientists care. They think Venus was once a lot like Earth, which makes it interesting. \n",
            "\n",
            "Another thing is they‚Äôre making mechanical computers that can handle the extreme heat and pressure. The article says these computers are different because they don‚Äôt need electronics, so they can survive better in those conditions. Also, they tested silicon carbide materials and found they could last for weeks on the surface. \n",
            "\n",
            "Overall, the author explains reasons why studying Venus is risky, but it can help us understand more about our solar system. Even with all the dangers, the possibility of past oceans and Earth-like conditions makes Venus worth exploring. The author‚Äôs points show how much humans can learn, but there‚Äôs still a lot of work to do.\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚úÖ REGENERATION COMPLETE!\n",
            "============================================================\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/test_synthetic_REVISED.csv\n",
            "\n",
            "üìä COMPARISON:\n",
            "  Original Score 1: 129 words, somewhat coherent\n",
            "  Revised Score 1:  139 words\n",
            "\n",
            "  Original Score 3: 241 words, too smooth\n",
            "  Revised Score 3:  240 words\n",
            "\n",
            "üîç REVIEW THE TEXT ABOVE\n",
            "   Check if Score 1 now feels scattered/chaotic\n",
            "   Check if Score 3 now feels choppy but has good content\n",
            "\n",
            "‚úÖ If satisfied ‚Üí Proceed to STEP 2\n",
            "‚ùå If not quite right ‚Üí Adjust instructions and regenerate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "COMPLETE SYNTHETIC EXAMPLES GENERATOR - REFINED VERSION\n",
        "Generates 23 synthetic Venus summaries with improved authenticity\n",
        "- Score 1: Enhanced chaotic, scattered organization\n",
        "- Score 3: Enhanced choppy flow with good content\n",
        "- Scores 2, 4, 5: Unchanged (already working well)\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ===========================================\n",
        "# CONFIGURATION\n",
        "# ===========================================\n",
        "\n",
        "# Set your OpenAI API key\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# File paths\n",
        "AUTHENTIC_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_venus_36.csv'\n",
        "SYNTHETIC_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_synthetic_23.csv'\n",
        "COMBINED_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv'\n",
        "\n",
        "# ===========================================\n",
        "# LOAD VENUS SOURCE TEXT\n",
        "# ===========================================\n",
        "\n",
        "def load_venus_source():\n",
        "    \"\"\"Load the Venus article text from the ASAP dataset\"\"\"\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/ASAP2_train_sourcetexts.csv',\n",
        "                     encoding='ISO-8859-1')\n",
        "    venus_df = df[df['prompt_name'] == 'Exploring Venus']\n",
        "    source_text = venus_df['source_text_1'].iloc[0]\n",
        "    assignment = venus_df['assignment'].iloc[0]\n",
        "    return source_text, assignment\n",
        "\n",
        "VENUS_SOURCE, VENUS_ASSIGNMENT = load_venus_source()\n",
        "\n",
        "# ===========================================\n",
        "# RUBRIC\n",
        "# ===========================================\n",
        "\n",
        "RUBRIC = \"\"\"\n",
        "RUBRIC FOR VENUS SUMMARY EVALUATION (1-5 scale per dimension):\n",
        "\n",
        "COMPLETENESS (1-5):\n",
        "5: Comprehensive coverage of all main ideas with strong supporting details\n",
        "4: Covers main ideas with good supporting details, minor gaps acceptable\n",
        "3: Covers basic main ideas but missing some key supporting details\n",
        "2: Partial coverage with significant gaps\n",
        "1: Minimal coverage, major ideas missing\n",
        "\n",
        "ACCURACY (1-5):\n",
        "5: All information factually correct\n",
        "4: Mostly accurate with only minor imprecisions\n",
        "3: Generally accurate but with some notable errors\n",
        "2: Multiple factual errors or significant misrepresentations\n",
        "1: Major factual errors, invented details, fundamental misunderstandings\n",
        "\n",
        "COHERENCE (1-5):\n",
        "5: Excellent organization with smooth transitions and clear logical flow\n",
        "4: Well-organized with generally good transitions\n",
        "3: Basic organization but with awkward transitions or logical gaps\n",
        "2: Poor organization, weak transitions, difficult to follow\n",
        "1: Incoherent, random organization, no clear structure\n",
        "\n",
        "CONCISENESS (1-5):\n",
        "5: Appropriately concise (200-250 words), no unnecessary repetition\n",
        "4: Reasonably concise (250-280 words), minimal redundancy\n",
        "3: Somewhat verbose (280-320 words) or with noticeable repetition\n",
        "2: Too long (320-400 words) with significant repetition\n",
        "1: Extremely brief (<150 words) or excessively long (>400 words)\n",
        "\"\"\"\n",
        "\n",
        "# ===========================================\n",
        "# GENERATION FUNCTIONS\n",
        "# ===========================================\n",
        "\n",
        "def create_generation_prompt(score, specific_instructions, word_count_guidance):\n",
        "    \"\"\"Create prompt for generating a synthetic example\"\"\"\n",
        "    return f\"\"\"You are simulating an authentic middle school student (grades 7-8) writing an evaluative essay about whether the author of an article successfully supports their argument. This is for educational research to test an automated assessment system.\n",
        "\n",
        "ASSIGNMENT:\n",
        "{VENUS_ASSIGNMENT}\n",
        "\n",
        "SOURCE TEXT:\n",
        "{VENUS_SOURCE}\n",
        "\n",
        "RUBRIC:\n",
        "{RUBRIC}\n",
        "\n",
        "YOUR TASK:\n",
        "Write a student response that would realistically earn a score of {score} on the 6-point scale based on the rubric above.\n",
        "\n",
        "SPECIFIC REQUIREMENTS FOR THIS SAMPLE:\n",
        "{specific_instructions}\n",
        "\n",
        "WRITING GUIDELINES:\n",
        "- Use vocabulary and sentence structure typical of grades 7-8\n",
        "- Target length: {word_count_guidance} words\n",
        "- Include some natural middle school writing patterns (minor grammar quirks, occasional informal phrasing)\n",
        "- Make it feel authentic - not overly polished or obviously AI-generated\n",
        "- Focus on the CONTENT errors specified above (don't make it artificially bad with excessive spelling/grammar errors)\n",
        "- Stay focused on the Venus exploration topic\n",
        "- Remember: this is evaluating HOW WELL THE AUTHOR SUPPORTS THE IDEA, not just summarizing\n",
        "\n",
        "Write only the student essay response (no meta-commentary):\"\"\"\n",
        "\n",
        "def generate_synthetic_example(example_config, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"Generate a single synthetic example using GPT-4o-Mini\"\"\"\n",
        "\n",
        "    prompt = create_generation_prompt(\n",
        "        score=example_config['score'],\n",
        "        specific_instructions=example_config['instructions'],\n",
        "        word_count_guidance=example_config['word_count']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # ‚úÖ Use Chat Completions via the client\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"You are an expert at simulating authentic middle school \"\n",
        "                        \"student writing for educational research purposes.\"\n",
        "                    )\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                },\n",
        "            ],\n",
        "            temperature=0.9,\n",
        "            max_tokens=800,\n",
        "        )\n",
        "\n",
        "        generated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        return {\n",
        "            'essay_id': example_config['essay_id'],\n",
        "            'score': example_config['score'],\n",
        "            'full_text': generated_text,\n",
        "            'assignment': VENUS_ASSIGNMENT,\n",
        "            'prompt_name': 'Exploring Venus',\n",
        "            'source_text_1': VENUS_SOURCE,\n",
        "            'source_text_2': None,\n",
        "            'source_text_3': None,\n",
        "            'source_text_4': None,\n",
        "            'economically_disadvantaged': 'Synthetic',\n",
        "            'student_disability_status': 'Synthetic',\n",
        "            'ell_status': 'Synthetic',\n",
        "            'race_ethnicity': 'Synthetic',\n",
        "            'gender': 'Synthetic',\n",
        "            'synthetic_flag': True,\n",
        "            'target_error_pattern': example_config['target_error'],\n",
        "            'generation_date': datetime.now().isoformat(),\n",
        "            'generation_model': model,\n",
        "            'word_count': len(generated_text.split())\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating {example_config['essay_id']}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ===========================================\n",
        "# ALL 23 SYNTHETIC EXAMPLE CONFIGURATIONS\n",
        "# ===========================================\n",
        "\n",
        "SYNTHETIC_EXAMPLES = [\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 1 EXAMPLES (3 total) - REFINED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_01_S1',\n",
        "        'score': 1,\n",
        "        'target_error': 'Severe incompleteness + fabrication',\n",
        "        'word_count': '100-150',\n",
        "        'instructions': \"\"\"Cover only 1-2 superficial details like \"Venus is bright\" or \"it's hot.\"\n",
        "Include 2-3 fabricated facts (e.g., say \"hotter than the sun\" or \"NASA already went there\").\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump between totally unrelated ideas with NO logical connections\n",
        "- NO clear introduction-body-conclusion structure\n",
        "- Let ideas trail off or suddenly change direction mid-thought\n",
        "- Use only simple transitions: \"Also,\" \"And,\" or just start new sentences randomly\n",
        "- Make at least 2-3 sentences that don't connect to anything around them\n",
        "- Reader should feel confused trying to follow your point\n",
        "\n",
        "Example scattered style: \"Venus is really hot I think. Also there's blimps or something? The article talks about dangers but I can't remember. And they should explore Mars instead. Venus has acid maybe.\"\n",
        "\n",
        "Show you fundamentally misunderstood the assignment. Make it feel random and unfocused.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_02_S1',\n",
        "        'score': 1,\n",
        "        'target_error': 'Extreme brevity + major misunderstandings',\n",
        "        'word_count': '80-120',\n",
        "        'instructions': \"\"\"Write only 3-5 sentences total (extremely brief).\n",
        "Fundamentally misrepresent the article's main argument (say scientists have already successfully explored Venus when the article is about future plans and challenges).\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump between ideas with no connections\n",
        "- NO structure at all\n",
        "- Treat Venus exploration as if it's already accomplished rather than a future challenge\n",
        "- Miss the evaluative component entirely - don't assess whether the author supported their claim well\n",
        "- Use simple transitions only: \"Also,\" \"And,\" or none\n",
        "- Let thoughts trail off incompletely\n",
        "\n",
        "Show you didn't understand what the article was actually about. Make it feel very confused.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_03_S1',\n",
        "        'score': 1,\n",
        "        'target_error': 'Off-topic rambling + factual confusion',\n",
        "        'word_count': '150-200',\n",
        "        'instructions': \"\"\"Spend most of the essay on tangential topics (other planets, space exploration in general, why space is cool).\n",
        "Confuse Venus with Mars or Mercury in several places.\n",
        "Include information about planets that wasn't in the article at all.\n",
        "\n",
        "CRITICAL - Make it SCATTERED and CHAOTIC:\n",
        "- Jump wildly between unrelated topics: Venus ‚Üí other planets ‚Üí space careers ‚Üí back to Venus ‚Üí random facts\n",
        "- NO clear focus on the assigned task\n",
        "- Incoherent connections between ideas\n",
        "- Simple or no transitions\n",
        "- Several sentences that feel completely disconnected\n",
        "- Never clearly address whether the author supported their argument\n",
        "\n",
        "Show the student didn't focus on the assigned task and got distracted by tangents.\"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 2 EXAMPLES (7 total) - UNCHANGED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_04_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Completeness gap - missing critical supporting details',\n",
        "        'word_count': '150-200',\n",
        "        'instructions': \"\"\"Correctly identify the main claim (studying Venus is worthy despite dangers).\n",
        "Mention that the author discusses dangers and solutions.\n",
        "BUT only provide 1-2 very vague examples (e.g., \"there are dangers\" without specifying what).\n",
        "Omit key evidence like specific temperatures, NASA's blimp solution, mechanical computers, etc.\n",
        "Show basic understanding but very superficial engagement with the text.\n",
        "Address the evaluation aspect but without sufficient detail to be convincing.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_05_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Accuracy issues - multiple misrepresentations',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Capture the basic structure (dangers ‚Üí solutions ‚Üí why it's worth it).\n",
        "Include several factual errors: wrong temperature (say 600¬∞F instead of 800¬∞F), wrong atmospheric pressure, wrong altitude for NASA's blimp.\n",
        "Misattribute information (e.g., say Mercury is Earth's twin, or confuse which planet has the hottest surface).\n",
        "Mix up timeframes (say missions were recent when they were decades ago).\n",
        "Show the student read the article but remembered details incorrectly.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_06_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Coherence problems - poor organization',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Include relevant content from the article but present it in random order.\n",
        "Jump from dangers to solutions back to dangers to why Venus is interesting with no logical flow.\n",
        "Use very weak or missing transitions (\"Also...\" or \"And another thing...\").\n",
        "Make it hard to follow the argument even though the information is present.\n",
        "Repeat the same point in different places rather than grouping related ideas.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_07_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Conciseness problems - excessive length with repetition',\n",
        "        'word_count': '400-450',\n",
        "        'instructions': \"\"\"Include accurate information about Venus.\n",
        "Repeat the same points 3-4 times using slightly different wording each time.\n",
        "Say things like \"Venus is dangerous because of the heat. The heat on Venus is extreme. The temperatures on Venus are very hot.\"\n",
        "Include unnecessary elaboration on minor details.\n",
        "Make it feel like padding to meet a length requirement.\n",
        "Could easily be cut to 200 words without losing content.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_08_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Quote-heavy with minimal synthesis',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Rely heavily on direct phrases from the article (don't use actual quotation marks, but use near-quotes).\n",
        "String together borrowed phrases with minimal original summarization.\n",
        "Reads like a patchwork: \"The article says [near quote]. It also mentions [near quote]. The author states [near quote].\"\n",
        "Very little original synthesis or paraphrasing.\n",
        "Shows the student didn't process the information, just copied it.\n",
        "Weak evaluation of whether the author's support is effective.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_09_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Shallow coverage - lists facts without connections',\n",
        "        'word_count': '160-200',\n",
        "        'instructions': \"\"\"Write in a bullet-point style or list-like structure even without actual bullets.\n",
        "\"First, Venus is hot. Second, there is acid. Third, NASA has an idea.\"\n",
        "List facts from the article without connecting them or showing relationships.\n",
        "No clear evaluation of the author's argument - just recitation.\n",
        "Miss the analytical component entirely.\n",
        "Each sentence feels disconnected from the previous one.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_10_S2',\n",
        "        'score': 2,\n",
        "        'target_error': 'Personal opinion intrusion',\n",
        "        'word_count': '180-220',\n",
        "        'instructions': \"\"\"Start summarizing the article but then shift into personal opinions.\n",
        "Use phrases like \"I think we should explore Venus because...\" or \"I believe the author is right because I've always been interested in space...\"\n",
        "Include 2-3 paragraphs about the student's own views on space exploration.\n",
        "Lose objectivity required for summary/evaluation.\n",
        "Confuse personal response with evaluation of the author's support.\n",
        "Mix \"the author supports this\" with \"I agree because...\" \"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 3 EXAMPLES (8 total) - REFINED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_11_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good completeness, weak coherence',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Cover ALL main ideas with GOOD specific details:\n",
        "- Dangers: 800¬∞F temperature, sulfuric acid, 97% CO2 atmosphere, 90x pressure\n",
        "- Solutions: NASA's blimp at 30 miles altitude, mechanical computers, silicon carbide\n",
        "- Value: Venus may have had oceans, Earth's twin, scientific curiosity\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing,\" \"So,\" \"Plus\"\n",
        "- NEVER use: \"Furthermore,\" \"Additionally,\" \"Moreover,\" \"In conclusion\"\n",
        "- Present good ideas in somewhat random order - jump between topics\n",
        "- Make each paragraph feel disconnected from the previous one\n",
        "\n",
        "Example choppy style: \"The author talks about Venus being super dangerous. It's like 800 degrees with sulfuric acid. Also NASA has this idea about blimps. And the temperature would be hot but survivable. Plus Venus might have had oceans.\"\n",
        "\n",
        "Reader should think: \"Good content but rough organization.\" DO NOT write polished conclusion.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_12_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good accuracy/completeness, conciseness issues',\n",
        "        'word_count': '320-350',\n",
        "        'instructions': \"\"\"Cover all main ideas with accurate, thorough detail.\n",
        "Include all key facts with correct information.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution AND TOO LONG:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing,\" \"So,\" \"Plus\"\n",
        "- Be moderately too long (320-350 words)\n",
        "- Include some unnecessary elaboration or minor tangential details\n",
        "- Some repetition of ideas\n",
        "- Could be tightened significantly without losing content\n",
        "- Good substance but needs editing\n",
        "- Somewhat random organization\n",
        "\n",
        "Make it feel like the student knows the material well but wrote too much with choppy flow.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_13_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good structure, minor accuracy lapses',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write with decent organization and appropriate length.\n",
        "Include good coverage of main ideas.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS minor errors:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"So,\" \"Plus\"\n",
        "- Include 2-3 minor factual errors (slightly wrong numbers)\n",
        "- Example: say the blimp would be 20 miles up instead of 30, or say 80% carbon dioxide instead of 97%\n",
        "- Errors are small enough that overall understanding is clear\n",
        "- Somewhat choppy flow with weak transitions\n",
        "\n",
        "Otherwise solid summary with adequate evaluation.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_14_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Adequate but mechanical',\n",
        "        'word_count': '200-230',\n",
        "        'instructions': \"\"\"Hit all required elements in a formulaic way.\n",
        "\"The author supports this idea in three ways. First,... Second,... Third,...\"\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution AND mechanical:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"First,\" \"Second,\" \"Third\"\n",
        "- Very five-paragraph-essay structure that feels paint-by-numbers\n",
        "- Overly simplistic sentence structure throughout (mostly simple sentences, few complex ones)\n",
        "- Feels formulaic but technically complete\n",
        "- Adequate but uninspired\n",
        "- Choppy transitions between sections\n",
        "\n",
        "Make it feel like following a template rather than natural writing.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_15_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good content, weak introduction/conclusion',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write strong middle paragraphs with good detail about dangers, solutions, and value.\n",
        "Include specific facts and evidence.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS weak framing:\n",
        "- Use ONLY weak transitions in body: \"Also,\" \"And,\" \"Plus,\" \"So\"\n",
        "- Unclear or missing claim statement in introduction\n",
        "- Introduction jumps straight into details without setting up the evaluation\n",
        "- Abrupt ending or incomplete conclusion that doesn't tie ideas together\n",
        "- The body is strong (score 4 content level) but framing is weak and choppy\n",
        "\n",
        "Make the middle good but the beginning and end feel rough.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_16_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Imbalanced coverage',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write excellent, detailed coverage of the dangers (sulfuric acid, heat, pressure, etc.).\n",
        "Then only 2-3 sentences total on NASA's solutions (very superficial).\n",
        "Barely mention why Venus is scientifically valuable.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution AND imbalanced:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Another thing\"\n",
        "- Show engagement with some sections but uneven attention\n",
        "- Good depth in dangers, inadequate in solutions/value\n",
        "- Choppy flow throughout\n",
        "- Somewhat random organization\n",
        "\n",
        "Make it obvious the student focused on one section and rushed through others.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_17_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Nearly good but with redundancy',\n",
        "        'word_count': '260-290',\n",
        "        'instructions': \"\"\"Write with accurate information and decent structure.\n",
        "Include good evaluation of the author's support.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS redundancy:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"Plus,\" \"So\"\n",
        "- Repeat 2-3 points unnecessarily\n",
        "- Example: mention the extreme heat in paragraph 2, then mention it again in paragraph 3 in similar words\n",
        "- Some ideas stated twice without adding new information\n",
        "- Choppy transitions throughout\n",
        "- Could be excellent if tightened and smoothed\n",
        "\n",
        "Make it feel like good understanding but needs editing for flow and conciseness.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_18_S3',\n",
        "        'score': 3,\n",
        "        'target_error': 'Good summary with minor coherence gaps',\n",
        "        'word_count': '220-250',\n",
        "        'instructions': \"\"\"Write comprehensive and accurate coverage.\n",
        "Include good specific details.\n",
        "\n",
        "CRITICAL - Good content but CHOPPY execution PLUS coherence hiccups:\n",
        "- Use ONLY weak transitions: \"Also,\" \"And,\" \"So,\" \"Plus\"\n",
        "- Make one paragraph or section feel disconnected from the rest\n",
        "- Include slightly confusing pronoun references (unclear antecedents)\n",
        "- One transition that doesn't quite work\n",
        "- Reader might need to reread one part to understand the connection\n",
        "- Overall good but with noticeable choppiness\n",
        "\n",
        "Make it feel like the content is there but organization could be smoother.\"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 4 EXAMPLES (4 total) - UNCHANGED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_19_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Excellent overall, slightly too lengthy',\n",
        "        'word_count': '290-310',\n",
        "        'instructions': \"\"\"Write a clear, explicit evaluation of how well the author supports the argument.\n",
        "Include comprehensive coverage of dangers (specific examples), solutions (blimp, mechanical computers), and scientific value.\n",
        "Make it accurate throughout with good detail.\n",
        "Organize well with smooth transitions.\n",
        "BUT make it slightly longer than ideal (290-310 words).\n",
        "Could be tightened by 40-60 words without losing substance.\n",
        "Very strong work with only minor conciseness issue.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_20_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Very good but with minor conciseness issue',\n",
        "        'word_count': '250-270',\n",
        "        'instructions': \"\"\"Write with excellent structure, accuracy, and completeness.\n",
        "Include strong evaluation of the author's argument.\n",
        "Make it clear and coherent throughout.\n",
        "BUT include 1-2 sentences that could be tightened.\n",
        "One slightly redundant point or phrase.\n",
        "Example: might say both \"very hot\" and \"extremely high temperatures\" in close proximity.\n",
        "Nearly perfect with just minor tightening needed.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_21_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Strong summary, minor accuracy detail',\n",
        "        'word_count': '230-260',\n",
        "        'instructions': \"\"\"Write with excellent organization, completeness, and conciseness.\n",
        "Include clear evaluation with strong supporting evidence.\n",
        "Use smooth, sophisticated writing.\n",
        "BUT include one small factual error that doesn't undermine the overall argument.\n",
        "Example: say 85 times atmospheric pressure instead of 90, or 750¬∞F instead of 800¬∞F.\n",
        "Error is minor enough that understanding remains strong.\n",
        "Otherwise near-perfect.\"\"\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_22_S4',\n",
        "        'score': 4,\n",
        "        'target_error': 'Near-excellent but slightly mechanical',\n",
        "        'word_count': '240-260',\n",
        "        'instructions': \"\"\"Hit all rubric criteria very well.\n",
        "Make it accurate, complete, organized, and reasonably concise.\n",
        "Include clear evaluation with good evidence.\n",
        "BUT lack the sophisticated synthesis and insightful connections of score 5-6.\n",
        "Be slightly formulaic in approach.\n",
        "Very competent and thorough but doesn't have the \"spark\" of exceptional writing.\n",
        "Very good but not quite excellent.\"\"\"\n",
        "    },\n",
        "\n",
        "    # ========================================\n",
        "    # SCORE 5 EXAMPLES (1 total) - UNCHANGED\n",
        "    # ========================================\n",
        "\n",
        "    {\n",
        "        'essay_id': 'SYNTH_V_23_S5',\n",
        "        'score': 5,\n",
        "        'target_error': 'Excellent summary with very minor flaw',\n",
        "        'word_count': '230-250',\n",
        "        'instructions': \"\"\"Write a clear, insightful evaluation of how the author builds their argument.\n",
        "Include comprehensive coverage of all key evidence (dangers, NASA solutions, scientific value, mechanical computers, past missions).\n",
        "Make all information accurate and well-synthesized.\n",
        "Use excellent organization with smooth, sophisticated transitions.\n",
        "Be appropriately concise (230-250 words) with no redundancy.\n",
        "Show deep understanding and analytical thinking.\n",
        "BUT include one VERY minor issue (e.g., two ideas that could be connected more explicitly, or one transition that's good but could be slightly smoother).\n",
        "The flaw should be extremely subtle - this is nearly perfect work.\n",
        "Should feel like strong high school or early college writing.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# ===========================================\n",
        "# MAIN GENERATION FUNCTION\n",
        "# ===========================================\n",
        "\n",
        "def generate_all_synthetic_examples(save_path, delay=1.5):\n",
        "    \"\"\"Generate all 23 synthetic examples and save to CSV\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"GENERATING {len(SYNTHETIC_EXAMPLES)} SYNTHETIC EXAMPLES\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\n",
        "        f\"Estimated time: {len(SYNTHETIC_EXAMPLES) * 2:.0f} seconds \"\n",
        "        f\"(~{len(SYNTHETIC_EXAMPLES) * 2 / 60:.0f} minutes)\"\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, example_config in enumerate(SYNTHETIC_EXAMPLES, 1):\n",
        "        print(\n",
        "            f\"[{i:2d}/{len(SYNTHETIC_EXAMPLES)}] \"\n",
        "            f\"{example_config['essay_id']} (Score {example_config['score']})...\",\n",
        "            end=\" \",\n",
        "        )\n",
        "\n",
        "        # ‚úÖ actually generate one example\n",
        "        result = generate_synthetic_example(example_config)\n",
        "\n",
        "        if result is not None:\n",
        "            results.append(result)\n",
        "            word_count = result[\"word_count\"]\n",
        "            print(f\"‚úì ({word_count} words)\")\n",
        "        else:\n",
        "            print(\"‚úó FAILED\")\n",
        "\n",
        "        # Rate limiting\n",
        "        if i < len(SYNTHETIC_EXAMPLES):\n",
        "            time.sleep(delay)\n",
        "\n",
        "    # If all generations failed, bail out gracefully\n",
        "    if not results:\n",
        "        print(\n",
        "            \"\\nNo synthetic examples were generated. \"\n",
        "            \"Check the error messages above (likely an API or config issue).\"\n",
        "        )\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Create DataFrame\n",
        "    synthetic_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save to CSV\n",
        "    synthetic_df.to_csv(save_path, index=False)\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 70)\n",
        "    print(\"‚úÖ GENERATION COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Generated: {len(results)}/{len(SYNTHETIC_EXAMPLES)} examples\")\n",
        "    print(f\"üìÅ Saved to: {save_path}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Score distribution:\")\n",
        "    print(synthetic_df[\"score\"].value_counts().sort_index())\n",
        "    print()\n",
        "\n",
        "    return synthetic_df\n",
        "\n",
        "# ===========================================\n",
        "# COMBINE WITH AUTHENTIC SAMPLES\n",
        "# ===========================================\n",
        "\n",
        "def combine_with_authentic(authentic_path, synthetic_df, output_path):\n",
        "    \"\"\"Combine authentic and synthetic samples into final validation set\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"COMBINING WITH AUTHENTIC SAMPLES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load authentic samples\n",
        "    authentic_df = pd.read_csv(authentic_path)\n",
        "\n",
        "    # Add metadata columns to authentic samples\n",
        "    authentic_df['synthetic_flag'] = False\n",
        "    authentic_df['target_error_pattern'] = 'Authentic student work'\n",
        "    authentic_df['generation_date'] = None\n",
        "    authentic_df['generation_model'] = None\n",
        "    authentic_df['word_count'] = authentic_df['full_text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "    # Combine\n",
        "    combined_df = pd.concat([authentic_df, synthetic_df], ignore_index=True)\n",
        "\n",
        "    # Shuffle to mix authentic and synthetic\n",
        "    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Save\n",
        "    combined_df.to_csv(output_path, index=False)\n",
        "\n",
        "    print()\n",
        "    print(\"‚úÖ COMBINED DATASET CREATED!\")\n",
        "    print(f\"   Authentic samples: {len(authentic_df)} ({len(authentic_df)/len(combined_df)*100:.1f}%)\")\n",
        "    print(f\"   Synthetic samples: {len(synthetic_df)} ({len(synthetic_df)/len(combined_df)*100:.1f}%)\")\n",
        "    print(f\"   Total samples: {len(combined_df)}\")\n",
        "    print()\n",
        "    print(f\"üìÅ Saved to: {output_path}\")\n",
        "    print()\n",
        "    print(\"Final score distribution:\")\n",
        "    print(combined_df['score'].value_counts().sort_index())\n",
        "    print()\n",
        "\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "hyufyNRfm2tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930e3323-516c-48ef-afaf-76493b5c914c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# QUICK SANITY CHECK (RUNS WHEN YOU EXECUTE THIS CELL)\n",
        "# ===========================================\n",
        "\n",
        "print(\"Running quick sanity check with one synthetic example...\")\n",
        "test_config = SYNTHETIC_EXAMPLES[0]\n",
        "test_sample = generate_synthetic_example(test_config)\n",
        "\n",
        "print(\"Result is None?\", test_sample is None)\n",
        "if test_sample:\n",
        "    print(\"Sample word_count:\", test_sample[\"word_count\"])\n",
        "    print(test_sample[\"full_text\"][:400], \"...\")\n",
        "    # Optional: stop here while debugging\n",
        "    # import sys\n",
        "    # sys.exit(\"Stopping after sanity check.\")"
      ],
      "metadata": {
        "id": "D9RHW7IxupJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364cbf63-692c-4397-9b29-5fd924cd5be2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running quick sanity check with one synthetic example...\n",
            "Result is None? False\n",
            "Sample word_count: 156\n",
            "Venus is super bright and hot. Like, hotter than the sun I think. Also, it has a lot of clouds and acid which is really cool and dangerous. The author talks about NASA wanting to send a blimp to Venus, but I don‚Äôt get why they want to go when they already sent a spaceship there once. I mean, it was probably really hard but they should just explore Mars instead. And the article says it has volcanoe ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# RUN COMPLETE GENERATION\n",
        "# ===========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SYNTHETIC EXAMPLES GENERATION - REFINED VERSION\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "\n",
        "    # Step 1: Generate synthetic examples\n",
        "    synthetic_df = generate_all_synthetic_examples(SYNTHETIC_PATH, delay=1.5)\n",
        "\n",
        "    if synthetic_df.empty:\n",
        "        print(\"‚ùå Skipping combination because no synthetic examples were generated.\")\n",
        "    else:\n",
        "        # Step 2: Combine with authentic samples\n",
        "        final_df = combine_with_authentic(AUTHENTIC_PATH, synthetic_df, COMBINED_PATH)\n",
        "        print(\"=\"*70)\n",
        "        print(\"üéâ ALL DONE!\")\n",
        "        print(\"=\"*70)\n",
        "        print()\n",
        "        print(\"Next steps:\")\n",
        "        print(\"1. ‚úÖ Review synthetic examples for quality\")\n",
        "        print(\"2. ‚úÖ Regenerate any that need adjustment\")\n",
        "        print(\"3. ‚úÖ Proceed to Phase 2: Expert Rating\")\n",
        "        print()\n",
        "        print(f\"Your validation set is ready: {COMBINED_PATH}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "ZJTxwd-iunNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce6a3e0-4141-485d-97bb-11e65f1fc8e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SYNTHETIC EXAMPLES GENERATION - REFINED VERSION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "GENERATING 23 SYNTHETIC EXAMPLES\n",
            "======================================================================\n",
            "Estimated time: 46 seconds (~1 minutes)\n",
            "\n",
            "[ 1/23] SYNTH_V_01_S1 (Score 1)... ‚úì (144 words)\n",
            "[ 2/23] SYNTH_V_02_S1 (Score 1)... ‚úì (99 words)\n",
            "[ 3/23] SYNTH_V_03_S1 (Score 1)... ‚úì (248 words)\n",
            "[ 4/23] SYNTH_V_04_S2 (Score 2)... ‚úì (196 words)\n",
            "[ 5/23] SYNTH_V_05_S2 (Score 2)... ‚úì (222 words)\n",
            "[ 6/23] SYNTH_V_06_S2 (Score 2)... ‚úì (242 words)\n",
            "[ 7/23] SYNTH_V_07_S2 (Score 2)... ‚úì (488 words)\n",
            "[ 8/23] SYNTH_V_08_S2 (Score 2)... ‚úì (216 words)\n",
            "[ 9/23] SYNTH_V_09_S2 (Score 2)... ‚úì (197 words)\n",
            "[10/23] SYNTH_V_10_S2 (Score 2)... ‚úì (219 words)\n",
            "[11/23] SYNTH_V_11_S3 (Score 3)... ‚úì (248 words)\n",
            "[12/23] SYNTH_V_12_S3 (Score 3)... ‚úì (341 words)\n",
            "[13/23] SYNTH_V_13_S3 (Score 3)... ‚úì (249 words)\n",
            "[14/23] SYNTH_V_14_S3 (Score 3)... ‚úì (242 words)\n",
            "[15/23] SYNTH_V_15_S3 (Score 3)... ‚úì (238 words)\n",
            "[16/23] SYNTH_V_16_S3 (Score 3)... ‚úì (272 words)\n",
            "[17/23] SYNTH_V_17_S3 (Score 3)... ‚úì (283 words)\n",
            "[18/23] SYNTH_V_18_S3 (Score 3)... ‚úì (257 words)\n",
            "[19/23] SYNTH_V_19_S4 (Score 4)... ‚úì (278 words)\n",
            "[20/23] SYNTH_V_20_S4 (Score 4)... ‚úì (242 words)\n",
            "[21/23] SYNTH_V_21_S4 (Score 4)... ‚úì (267 words)\n",
            "[22/23] SYNTH_V_22_S4 (Score 4)... ‚úì (238 words)\n",
            "[23/23] SYNTH_V_23_S5 (Score 5)... ‚úì (238 words)\n",
            "\n",
            "======================================================================\n",
            "‚úÖ GENERATION COMPLETE!\n",
            "======================================================================\n",
            "Generated: 23/23 examples\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_synthetic_23.csv\n",
            "\n",
            "Score distribution:\n",
            "score\n",
            "1    3\n",
            "2    7\n",
            "3    8\n",
            "4    4\n",
            "5    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "======================================================================\n",
            "COMBINING WITH AUTHENTIC SAMPLES\n",
            "======================================================================\n",
            "\n",
            "‚úÖ COMBINED DATASET CREATED!\n",
            "   Authentic samples: 37 (61.7%)\n",
            "   Synthetic samples: 23 (38.3%)\n",
            "   Total samples: 60\n",
            "\n",
            "üìÅ Saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv\n",
            "\n",
            "Final score distribution:\n",
            "score\n",
            "1     8\n",
            "2    18\n",
            "3    20\n",
            "4    10\n",
            "5     3\n",
            "6     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "======================================================================\n",
            "üéâ ALL DONE!\n",
            "======================================================================\n",
            "\n",
            "Next steps:\n",
            "1. ‚úÖ Review synthetic examples for quality\n",
            "2. ‚úÖ Regenerate any that need adjustment\n",
            "3. ‚úÖ Proceed to Phase 2: Expert Rating\n",
            "\n",
            "Your validation set is ready: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.read_csv(COMBINED_PATH)\n",
        "\n",
        "print(combined_df.shape)  # should be (60, ...)\n",
        "print(combined_df[\"synthetic_flag\"].value_counts())\n",
        "print(combined_df[\"score\"].value_counts().sort_index())\n",
        "\n",
        "# Look at a few synthetic rows\n",
        "combined_df[combined_df[\"synthetic_flag\"]].head()[[\"essay_id\", \"score\", \"word_count\"]]"
      ],
      "metadata": {
        "id": "UQeNNvMz0rso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "dd9331d9-6a18-42cc-972b-43168fb74432"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 19)\n",
            "synthetic_flag\n",
            "False    37\n",
            "True     23\n",
            "Name: count, dtype: int64\n",
            "score\n",
            "1     8\n",
            "2    18\n",
            "3    20\n",
            "4    10\n",
            "5     3\n",
            "6     1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         essay_id  score  word_count\n",
              "3   SYNTH_V_09_S2      2         197\n",
              "5   SYNTH_V_18_S3      3         257\n",
              "7   SYNTH_V_12_S3      3         341\n",
              "9   SYNTH_V_21_S4      4         267\n",
              "10  SYNTH_V_10_S2      2         219"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34e7a307-8569-406f-ba00-ac9d9e871b69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>score</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SYNTH_V_09_S2</td>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SYNTH_V_18_S3</td>\n",
              "      <td>3</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SYNTH_V_12_S3</td>\n",
              "      <td>3</td>\n",
              "      <td>341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SYNTH_V_21_S4</td>\n",
              "      <td>4</td>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SYNTH_V_10_S2</td>\n",
              "      <td>2</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34e7a307-8569-406f-ba00-ac9d9e871b69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34e7a307-8569-406f-ba00-ac9d9e871b69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34e7a307-8569-406f-ba00-ac9d9e871b69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2591870e-cb8a-4f52-be1e-79388f82cf45\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2591870e-cb8a-4f52-be1e-79388f82cf45')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2591870e-cb8a-4f52-be1e-79388f82cf45 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"combined_df[combined_df[\\\"synthetic_flag\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SYNTH_V_18_S3\",\n          \"SYNTH_V_10_S2\",\n          \"SYNTH_V_12_S3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55,\n        \"min\": 197,\n        \"max\": 341,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          257,\n          219,\n          341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic = combined_df[combined_df[\"synthetic_flag\"]]\n",
        "\n",
        "# Check word-count ranges by score\n",
        "synthetic.groupby(\"score\")[\"word_count\"].describe()"
      ],
      "metadata": {
        "id": "QXcUPHqg1M4o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b35c0786-c70d-4ea3-887c-8139c8909e98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       count        mean         std    min    25%    50%     75%    max\n",
              "score                                                                   \n",
              "1        3.0  163.666667   76.422074   99.0  121.5  144.0  196.00  248.0\n",
              "2        7.0  254.285714  104.247645  196.0  206.5  219.0  232.00  488.0\n",
              "3        8.0  266.250000   33.813564  238.0  246.5  253.0  274.75  341.0\n",
              "4        4.0  256.250000   19.362765  238.0  241.0  254.5  269.75  278.0\n",
              "5        1.0  238.000000         NaN  238.0  238.0  238.0  238.00  238.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbcd5006-7481-4209-8d09-f9b936b20323\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>163.666667</td>\n",
              "      <td>76.422074</td>\n",
              "      <td>99.0</td>\n",
              "      <td>121.5</td>\n",
              "      <td>144.0</td>\n",
              "      <td>196.00</td>\n",
              "      <td>248.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>254.285714</td>\n",
              "      <td>104.247645</td>\n",
              "      <td>196.0</td>\n",
              "      <td>206.5</td>\n",
              "      <td>219.0</td>\n",
              "      <td>232.00</td>\n",
              "      <td>488.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>266.250000</td>\n",
              "      <td>33.813564</td>\n",
              "      <td>238.0</td>\n",
              "      <td>246.5</td>\n",
              "      <td>253.0</td>\n",
              "      <td>274.75</td>\n",
              "      <td>341.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>256.250000</td>\n",
              "      <td>19.362765</td>\n",
              "      <td>238.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>254.5</td>\n",
              "      <td>269.75</td>\n",
              "      <td>278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>238.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>238.00</td>\n",
              "      <td>238.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbcd5006-7481-4209-8d09-f9b936b20323')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbcd5006-7481-4209-8d09-f9b936b20323 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbcd5006-7481-4209-8d09-f9b936b20323');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6233d587-f93b-4455-b791-2343add715a2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6233d587-f93b-4455-b791-2343add715a2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6233d587-f93b-4455-b791-2343add715a2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"synthetic\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8809720581775866,\n        \"min\": 1.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.0,\n          1.0,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.51844298955157,\n        \"min\": 163.66666666666666,\n        \"max\": 266.25,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          254.28571428571428,\n          238.0,\n          266.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38.96658850631574,\n        \"min\": 19.36276495407272,\n        \"max\": 104.2476447147437,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          104.2476447147437,\n          19.36276495407272,\n          76.42207360006226\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.27603172074286,\n        \"min\": 99.0,\n        \"max\": 238.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          99.0,\n          196.0,\n          238.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.247727223296515,\n        \"min\": 121.5,\n        \"max\": 246.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          206.5,\n          238.0,\n          246.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.73237365368213,\n        \"min\": 144.0,\n        \"max\": 254.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          219.0,\n          238.0,\n          253.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.916198865153095,\n        \"min\": 196.0,\n        \"max\": 274.75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          232.0,\n          238.0,\n          274.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102.867876424081,\n        \"min\": 238.0,\n        \"max\": 488.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          488.0,\n          238.0,\n          341.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Calibration Subset Selection\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# SETUP: Mount Google Drive\n",
        "# =============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION: Set your file paths\n",
        "# =============================================================================\n",
        "\n",
        "# UPDATE THESE PATHS to match your Google Drive structure:\n",
        "VALIDATION_DATASET_PATH = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/'\n",
        "\n",
        "# The script will create these files in OUTPUT_DIR:\n",
        "# - calibration_subset.csv\n",
        "# - calibration_practice_summaries.txt\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CALIBRATION SUBSET SELECTION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nReading from: {VALIDATION_DATASET_PATH}\")\n",
        "print(f\"Saving to: {OUTPUT_DIR}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: Load and analyze dataset\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(\"\\n[STEP 1] Loading Dataset...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "df = pd.read_csv(VALIDATION_DATASET_PATH)\n",
        "\n",
        "print(f\"‚úì Loaded {len(df)} summaries\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "\n",
        "print(\"\\n\\nDataset Distribution:\")\n",
        "print(f\"  Authentic (ASAP 2.0): {(df['synthetic_flag'] == False).sum()}\")\n",
        "print(f\"  Synthetic (GPT-4o-Mini): {(df['synthetic_flag'] == True).sum()}\")\n",
        "\n",
        "print(\"\\nScore distribution:\")\n",
        "score_dist = df['score'].value_counts().sort_index()\n",
        "for score, count in score_dist.items():\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"  Score {score}: {count:2d} summaries ({pct:4.1f}%)\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: Define selection strategy\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 2] Selection Strategy\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "selection_plan = {\n",
        "    1: {'target': 2, 'authentic': 1, 'synthetic': 1},\n",
        "    2: {'target': 3, 'authentic': 2, 'synthetic': 1},\n",
        "    3: {'target': 3, 'authentic': 2, 'synthetic': 1},\n",
        "    4: {'target': 2, 'authentic': 1, 'synthetic': 1},\n",
        "    5: {'target': 1, 'authentic': 1, 'synthetic': 0},\n",
        "    6: {'target': 1, 'authentic': 1, 'synthetic': 0}\n",
        "}\n",
        "\n",
        "print(\"\\nWill select:\")\n",
        "for score, plan in selection_plan.items():\n",
        "    print(f\"  Score {score}: {plan['target']} summaries ({plan['authentic']} auth, {plan['synthetic']} synth)\")\n",
        "\n",
        "total_target = sum(plan['target'] for plan in selection_plan.values())\n",
        "print(f\"\\nTotal: {total_target} summaries for calibration\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: Execute selection\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 3] Selecting Summaries\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "calibration_subset = []\n",
        "\n",
        "# Score 1: 1 authentic + 1 synthetic\n",
        "score_1_df = df[df['score'] == 1]\n",
        "cal_1_auth = score_1_df[score_1_df['synthetic_flag'] == False].iloc[0]\n",
        "cal_1_synth = score_1_df[score_1_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_1_auth, cal_1_synth])\n",
        "print(f\"Score 1: Selected {cal_1_auth['essay_id']} (auth), {cal_1_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 2: 2 authentic + 1 synthetic\n",
        "score_2_df = df[df['score'] == 2]\n",
        "cal_2_auth = score_2_df[score_2_df['synthetic_flag'] == False].iloc[0:2]\n",
        "cal_2_synth = score_2_df[score_2_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_2_auth.iloc[0], cal_2_auth.iloc[1], cal_2_synth])\n",
        "print(f\"Score 2: Selected {cal_2_auth.iloc[0]['essay_id']}, {cal_2_auth.iloc[1]['essay_id']} (auth), {cal_2_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 3: 2 authentic + 1 synthetic\n",
        "score_3_df = df[df['score'] == 3]\n",
        "cal_3_auth = score_3_df[score_3_df['synthetic_flag'] == False].iloc[0:2]\n",
        "cal_3_synth = score_3_df[score_3_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_3_auth.iloc[0], cal_3_auth.iloc[1], cal_3_synth])\n",
        "print(f\"Score 3: Selected {cal_3_auth.iloc[0]['essay_id']}, {cal_3_auth.iloc[1]['essay_id']} (auth), {cal_3_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 4: 1 authentic + 1 synthetic\n",
        "score_4_df = df[df['score'] == 4]\n",
        "cal_4_auth = score_4_df[score_4_df['synthetic_flag'] == False].iloc[0]\n",
        "cal_4_synth = score_4_df[score_4_df['synthetic_flag'] == True].iloc[0]\n",
        "calibration_subset.extend([cal_4_auth, cal_4_synth])\n",
        "print(f\"Score 4: Selected {cal_4_auth['essay_id']} (auth), {cal_4_synth['essay_id']} (synth)\")\n",
        "\n",
        "# Score 5: 1 authentic\n",
        "score_5_df = df[df['score'] == 5]\n",
        "cal_5_auth = score_5_df[score_5_df['synthetic_flag'] == False].iloc[0]\n",
        "calibration_subset.append(cal_5_auth)\n",
        "print(f\"Score 5: Selected {cal_5_auth['essay_id']} (auth)\")\n",
        "\n",
        "# Score 6: 1 authentic (only one available)\n",
        "score_6_df = df[df['score'] == 6]\n",
        "cal_6 = score_6_df.iloc[0]\n",
        "calibration_subset.append(cal_6)\n",
        "print(f\"Score 6: Selected {cal_6['essay_id']} (auth)\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: Create calibration DataFrame\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 4] Creating Calibration DataFrame\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "cal_df = pd.DataFrame(calibration_subset)\n",
        "cal_df = cal_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n‚úì Created DataFrame with {len(cal_df)} summaries\")\n",
        "print(f\"\\nScore distribution in calibration set:\")\n",
        "print(cal_df['score'].value_counts().sort_index())\n",
        "print(f\"\\nAuthentic: {(cal_df['synthetic_flag'] == False).sum()}\")\n",
        "print(f\"Synthetic: {(cal_df['synthetic_flag'] == True).sum()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: Display details\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 5] Calibration Subset Details\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"\\n{'#':<3} {'Essay ID':<25} {'Score':<6} {'Source':<8} {'Words':<6} {'Error Pattern':<45}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for idx, row in cal_df.iterrows():\n",
        "    source = \"Synthetic\" if row['synthetic_flag'] else \"Authentic\"\n",
        "    error = row['target_error_pattern'] if pd.notna(row['target_error_pattern']) else \"N/A\"\n",
        "    print(f\"{idx+1:<3} {row['essay_id']:<25} {row['score']:<6} {source:<8} {row['word_count']:<6} {error[:45]:<45}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: Save CSV to Google Drive\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 6] Saving Calibration Subset CSV\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "cal_csv_path = os.path.join(OUTPUT_DIR, 'calibration_subset.csv')\n",
        "cal_df.to_csv(cal_csv_path, index=False)\n",
        "print(f\"‚úì Saved: {cal_csv_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: Create practice summaries document\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 7] Creating Practice Summaries Document\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "output_lines = []\n",
        "output_lines.append(\"=\" * 80)\n",
        "output_lines.append(\"CALIBRATION PRACTICE SET - 12 SUMMARIES\")\n",
        "output_lines.append(\"=\" * 80)\n",
        "output_lines.append(\"\\nInstructions:\")\n",
        "output_lines.append(\"1. Score each summary across all 4 dimensions WITHOUT looking at benchmark scores\")\n",
        "output_lines.append(\"2. Use your rubric and document your reasoning\")\n",
        "output_lines.append(\"3. After scoring all 12, compare with the benchmark scores\")\n",
        "output_lines.append(\"4. Analyze discrepancies to refine your rubric interpretation\")\n",
        "output_lines.append(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "\n",
        "for idx, row in cal_df.iterrows():\n",
        "    practice_num = idx + 1\n",
        "\n",
        "    output_lines.append(f\"\\n{'='*80}\")\n",
        "    output_lines.append(f\"PRACTICE_{practice_num:02d}: {row['essay_id']}\")\n",
        "    output_lines.append(f\"{'='*80}\")\n",
        "    output_lines.append(f\"Source: {'Synthetic' if row['synthetic_flag'] else 'Authentic'}\")\n",
        "    output_lines.append(f\"Word Count: {row['word_count']}\")\n",
        "    if pd.notna(row['target_error_pattern']):\n",
        "        output_lines.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "\n",
        "    output_lines.append(f\"\\n{'-'*80}\")\n",
        "    output_lines.append(\"SUMMARY TEXT:\")\n",
        "    output_lines.append(f\"{'-'*80}\\n\")\n",
        "    output_lines.append(row['full_text'])\n",
        "    output_lines.append(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Save to text file\n",
        "practice_txt_path = os.path.join(OUTPUT_DIR, 'calibration_practice_summaries.txt')\n",
        "with open(practice_txt_path, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(output_lines))\n",
        "\n",
        "print(f\"‚úì Saved: {practice_txt_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: Create Practice IDs reference\n",
        "# =============================================================================\n",
        "print(\"\\n\\n[STEP 8] Practice IDs for Calibration Tracker\")\n",
        "print(\"-\" * 80)\n",
        "print(\"\\nCopy these IDs into your Calibration_Tracker.xlsx:\")\n",
        "print()\n",
        "for i, essay_id in enumerate(cal_df['essay_id'], 1):\n",
        "    print(f\"PRACTICE_R1_{i:02d}: {essay_id}\")\n",
        "\n",
        "# Save to a separate reference file\n",
        "practice_ids_path = os.path.join(OUTPUT_DIR, 'calibration_practice_ids.txt')\n",
        "with open(practice_ids_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"Practice IDs for Calibration Tracker\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(\"Use these in your Calibration_Tracker.xlsx:\\n\\n\")\n",
        "    for i, essay_id in enumerate(cal_df['essay_id'], 1):\n",
        "        f.write(f\"PRACTICE_R1_{i:02d}: {essay_id}\\n\")\n",
        "\n",
        "print(f\"\\n‚úì Saved: {practice_ids_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# COMPLETION\n",
        "# =============================================================================\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"CALIBRATION SUBSET SELECTION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚úì Files saved to: {OUTPUT_DIR}\")\n",
        "print(f\"  ‚Ä¢ calibration_subset.csv (metadata)\")\n",
        "print(f\"  ‚Ä¢ calibration_practice_summaries.txt (full texts)\")\n",
        "print(f\"  ‚Ä¢ calibration_practice_ids.txt (IDs for tracker)\")\n",
        "\n",
        "print(f\"\\n‚úì Selected {len(cal_df)} summaries:\")\n",
        "print(f\"  ‚Ä¢ All 6 score levels covered\")\n",
        "print(f\"  ‚Ä¢ {(cal_df['synthetic_flag'] == False).sum()} authentic, {(cal_df['synthetic_flag'] == True).sum()} synthetic\")\n",
        "print(f\"  ‚Ä¢ Word count range: {cal_df['word_count'].min()}-{cal_df['word_count'].max()}\")\n",
        "\n",
        "print(\"\\nüìã Next steps:\")\n",
        "print(\"  1. Download the three files from your Google Drive\")\n",
        "print(\"  2. Review the practice summaries document\")\n",
        "print(\"  3. Begin Phase 1 of calibration (Rubric Study)\")\n",
        "print(\"  4. Use the practice IDs to update your Calibration_Tracker.xlsx\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feQW4BYuS4E6",
        "outputId": "da0b411a-1c94-464b-db9c-9c0c98ca7c7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "================================================================================\n",
            "CALIBRATION SUBSET SELECTION\n",
            "================================================================================\n",
            "\n",
            "Reading from: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv\n",
            "Saving to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/\n",
            "\n",
            "[STEP 1] Loading Dataset...\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Loaded 60 summaries\n",
            "\n",
            "Columns: ['essay_id', 'score', 'full_text', 'assignment', 'prompt_name', 'economically_disadvantaged', 'student_disability_status', 'ell_status', 'race_ethnicity', 'gender', 'source_text_1', 'source_text_2', 'source_text_3', 'source_text_4', 'synthetic_flag', 'target_error_pattern', 'generation_date', 'generation_model', 'word_count']\n",
            "\n",
            "\n",
            "Dataset Distribution:\n",
            "  Authentic (ASAP 2.0): 37\n",
            "  Synthetic (GPT-4o-Mini): 23\n",
            "\n",
            "Score distribution:\n",
            "  Score 1:  8 summaries (13.3%)\n",
            "  Score 2: 18 summaries (30.0%)\n",
            "  Score 3: 20 summaries (33.3%)\n",
            "  Score 4: 10 summaries (16.7%)\n",
            "  Score 5:  3 summaries ( 5.0%)\n",
            "  Score 6:  1 summaries ( 1.7%)\n",
            "\n",
            "\n",
            "[STEP 2] Selection Strategy\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Will select:\n",
            "  Score 1: 2 summaries (1 auth, 1 synth)\n",
            "  Score 2: 3 summaries (2 auth, 1 synth)\n",
            "  Score 3: 3 summaries (2 auth, 1 synth)\n",
            "  Score 4: 2 summaries (1 auth, 1 synth)\n",
            "  Score 5: 1 summaries (1 auth, 0 synth)\n",
            "  Score 6: 1 summaries (1 auth, 0 synth)\n",
            "\n",
            "Total: 12 summaries for calibration\n",
            "\n",
            "\n",
            "[STEP 3] Selecting Summaries\n",
            "--------------------------------------------------------------------------------\n",
            "Score 1: Selected AAAVUP14319000017665 (auth), SYNTH_V_01_S1 (synth)\n",
            "Score 2: Selected AAAVUP14319000153727, AAAVUP14319000099170 (auth), SYNTH_V_09_S2 (synth)\n",
            "Score 3: Selected AAAVUP14319000141935, AAAVUP14319000151934 (auth), SYNTH_V_18_S3 (synth)\n",
            "Score 4: Selected AAAVUP14319000017185 (auth), SYNTH_V_21_S4 (synth)\n",
            "Score 5: Selected AAAVUP14319000033223 (auth)\n",
            "Score 6: Selected AAAVUP14319000070539 (auth)\n",
            "\n",
            "\n",
            "[STEP 4] Creating Calibration DataFrame\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úì Created DataFrame with 12 summaries\n",
            "\n",
            "Score distribution in calibration set:\n",
            "score\n",
            "1    2\n",
            "2    3\n",
            "3    3\n",
            "4    2\n",
            "5    1\n",
            "6    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Authentic: 8\n",
            "Synthetic: 4\n",
            "\n",
            "\n",
            "[STEP 5] Calibration Subset Details\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "#   Essay ID                  Score  Source   Words  Error Pattern                                \n",
            "--------------------------------------------------------------------------------\n",
            "1   AAAVUP14319000017665      1      Authentic 387    Authentic student work                       \n",
            "2   SYNTH_V_01_S1             1      Synthetic 144    Severe incompleteness + fabrication          \n",
            "3   AAAVUP14319000153727      2      Authentic 286    Authentic student work                       \n",
            "4   AAAVUP14319000099170      2      Authentic 158    Authentic student work                       \n",
            "5   SYNTH_V_09_S2             2      Synthetic 197    Shallow coverage - lists facts without connec\n",
            "6   AAAVUP14319000141935      3      Authentic 263    Authentic student work                       \n",
            "7   AAAVUP14319000151934      3      Authentic 499    Authentic student work                       \n",
            "8   SYNTH_V_18_S3             3      Synthetic 257    Good summary with minor coherence gaps       \n",
            "9   AAAVUP14319000017185      4      Authentic 513    Authentic student work                       \n",
            "10  SYNTH_V_21_S4             4      Synthetic 267    Strong summary, minor accuracy detail        \n",
            "11  AAAVUP14319000033223      5      Authentic 732    Authentic student work                       \n",
            "12  AAAVUP14319000070539      6      Authentic 753    Authentic student work                       \n",
            "\n",
            "\n",
            "[STEP 6] Saving Calibration Subset CSV\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/calibration_subset.csv\n",
            "\n",
            "\n",
            "[STEP 7] Creating Practice Summaries Document\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì Saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/calibration_practice_summaries.txt\n",
            "\n",
            "\n",
            "[STEP 8] Practice IDs for Calibration Tracker\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Copy these IDs into your Calibration_Tracker.xlsx:\n",
            "\n",
            "PRACTICE_R1_01: AAAVUP14319000017665\n",
            "PRACTICE_R1_02: SYNTH_V_01_S1\n",
            "PRACTICE_R1_03: AAAVUP14319000153727\n",
            "PRACTICE_R1_04: AAAVUP14319000099170\n",
            "PRACTICE_R1_05: SYNTH_V_09_S2\n",
            "PRACTICE_R1_06: AAAVUP14319000141935\n",
            "PRACTICE_R1_07: AAAVUP14319000151934\n",
            "PRACTICE_R1_08: SYNTH_V_18_S3\n",
            "PRACTICE_R1_09: AAAVUP14319000017185\n",
            "PRACTICE_R1_10: SYNTH_V_21_S4\n",
            "PRACTICE_R1_11: AAAVUP14319000033223\n",
            "PRACTICE_R1_12: AAAVUP14319000070539\n",
            "\n",
            "‚úì Saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/calibration_practice_ids.txt\n",
            "\n",
            "\n",
            "================================================================================\n",
            "CALIBRATION SUBSET SELECTION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "‚úì Files saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/\n",
            "  ‚Ä¢ calibration_subset.csv (metadata)\n",
            "  ‚Ä¢ calibration_practice_summaries.txt (full texts)\n",
            "  ‚Ä¢ calibration_practice_ids.txt (IDs for tracker)\n",
            "\n",
            "‚úì Selected 12 summaries:\n",
            "  ‚Ä¢ All 6 score levels covered\n",
            "  ‚Ä¢ 8 authentic, 4 synthetic\n",
            "  ‚Ä¢ Word count range: 144-753\n",
            "\n",
            "üìã Next steps:\n",
            "  1. Download the three files from your Google Drive\n",
            "  2. Review the practice summaries document\n",
            "  3. Begin Phase 1 of calibration (Rubric Study)\n",
            "  4. Use the practice IDs to update your Calibration_Tracker.xlsx\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generate Calibration Benchmark Scores Answer Key\n",
        "Reads calibration_subset.csv and creates formatted answer key file\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "CALIBRATION_SUBSET_PATH = \"/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/calibration_subset.csv\"  # Adjust path as needed\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/CALIBRATION_BENCHMARK_SCORES.txt\"\n",
        "\n",
        "def create_benchmark_scores_file(input_csv, output_txt):\n",
        "    \"\"\"\n",
        "    Create formatted benchmark scores file from calibration subset CSV.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    input_csv : str\n",
        "        Path to calibration_subset.csv\n",
        "    output_txt : str\n",
        "        Path for output benchmark scores file\n",
        "    \"\"\"\n",
        "\n",
        "    # Read calibration subset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Define practice IDs and their roles\n",
        "    exemplars = {\n",
        "        'PRACTICE_01': 'Not used for blind practice - reference only',\n",
        "        'PRACTICE_02': 'EXEMPLAR - analyzed in detail in EXEMPLAR_ANALYSIS_GUIDE.md',\n",
        "        'PRACTICE_07': 'EXEMPLAR - analyzed in detail in EXEMPLAR_ANALYSIS_GUIDE.md',\n",
        "        'PRACTICE_11': 'EXEMPLAR - analyzed in detail in EXEMPLAR_ANALYSIS_GUIDE.md'\n",
        "    }\n",
        "\n",
        "    round_1 = ['PRACTICE_03', 'PRACTICE_04', 'PRACTICE_05', 'PRACTICE_06']\n",
        "    round_2 = ['PRACTICE_08', 'PRACTICE_09', 'PRACTICE_10', 'PRACTICE_12']\n",
        "\n",
        "    # Create practice_id column if it doesn't exist\n",
        "    if 'practice_id' not in df.columns:\n",
        "        # Create practice IDs based on row order\n",
        "        df['practice_id'] = [f'PRACTICE_{str(i+1).zfill(2)}' for i in range(len(df))]\n",
        "\n",
        "    # Build the output content\n",
        "    content = []\n",
        "\n",
        "    # Header\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"CALIBRATION PRACTICE SUMMARIES - BENCHMARK SCORES (ANSWER KEY)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"DO NOT LOOK AT THIS FILE UNTIL YOU HAVE SCORED ALL 9 PRACTICE SUMMARIES BLIND!\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"Instructions for Use:\")\n",
        "    content.append(\"1. Score all 9 practice summaries (PRACTICE_03 through PRACTICE_06, and\")\n",
        "    content.append(\"   PRACTICE_08 through PRACTICE_12) WITHOUT looking at this file\")\n",
        "    content.append(\"2. Record your scores in Calibration_Tracker.xlsx\")\n",
        "    content.append(\"3. AFTER completing all 9, open this file to compare your scores\")\n",
        "    content.append(\"4. Calculate agreement metrics and analyze discrepancies\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Exemplar summaries section\n",
        "    content.append(\"EXEMPLAR SUMMARIES (Study These First - Scores Already Known)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    for practice_id, note in exemplars.items():\n",
        "        row = df[df['practice_id'] == practice_id].iloc[0]\n",
        "        content.append(f\"{practice_id}: {row['essay_id']}\")\n",
        "        content.append(f\"Benchmark Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Note: {note}\")\n",
        "        content.append(\"\")\n",
        "\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Practice Round 1\n",
        "    content.append(\"PRACTICE ROUND 1 - BLIND SCORING (Complete First)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    for practice_id in round_1:\n",
        "        row = df[df['practice_id'] == practice_id].iloc[0]\n",
        "        content.append(f\"{practice_id}: {row['essay_id']}\")\n",
        "        content.append(f\"Benchmark Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Word Count: {row['word_count']}\")\n",
        "        if row['synthetic_flag'] == 1 and pd.notna(row['target_error_pattern']):\n",
        "            content.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "        content.append(\"\")\n",
        "\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Practice Round 2\n",
        "    content.append(\"PRACTICE ROUND 2 - BLIND SCORING (Complete Second)\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    for practice_id in round_2:\n",
        "        row = df[df['practice_id'] == practice_id].iloc[0]\n",
        "        content.append(f\"{practice_id}: {row['essay_id']}\")\n",
        "        content.append(f\"Benchmark Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Word Count: {row['word_count']}\")\n",
        "        if row['synthetic_flag'] == 1 and pd.notna(row['target_error_pattern']):\n",
        "            content.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "        content.append(\"\")\n",
        "\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Score distribution\n",
        "    content.append(\"SCORE DISTRIBUTION IN PRACTICE SET\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    score_counts = df['score'].value_counts().sort_index()\n",
        "    for score, count in score_counts.items():\n",
        "        practice_ids = df[df['score'] == score]['practice_id'].tolist()\n",
        "        ids_str = ', '.join(practice_ids)\n",
        "\n",
        "        # Identify exemplars\n",
        "        exemplar_ids = [pid for pid in practice_ids if pid in exemplars]\n",
        "        if exemplar_ids:\n",
        "            ids_str += f\" ({', '.join([f'{pid} - exemplar' for pid in exemplar_ids])})\"\n",
        "\n",
        "        content.append(f\"Score {score}: {count} {'summary' if count == 1 else 'summaries'} ({ids_str})\")\n",
        "\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Agreement metrics section\n",
        "    content.append(\"AGREEMENT METRICS TO CALCULATE\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"After comparing your scores to these benchmarks:\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"1. EXACT AGREEMENT: How many summaries did you score exactly the same?\")\n",
        "    content.append(\"   Target: ‚â• 60% (at least 6 out of 9)\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"2. ADJACENT AGREEMENT: How many were within ¬±1 point?\")\n",
        "    content.append(\"   Target: > 85% (at least 8 out of 9)\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"3. MEAN ABSOLUTE ERROR (MAE): Average distance from benchmark\")\n",
        "    content.append(\"   Target: < 0.5 points per dimension\")\n",
        "    content.append(\"   \")\n",
        "    content.append(\"   Formula: Sum of |your score - benchmark| √∑ number of summaries\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"4. PATTERNS IN DISCREPANCIES:\")\n",
        "    content.append(\"   - Do you tend to score higher or lower than benchmarks?\")\n",
        "    content.append(\"   - Are discrepancies concentrated in specific dimensions?\")\n",
        "    content.append(\"   - Are errors larger for certain score levels?\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Next steps\n",
        "    content.append(\"NEXT STEPS AFTER COMPARISON\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"1. Calculate your agreement metrics\")\n",
        "    content.append(\"2. Identify patterns in discrepancies\")\n",
        "    content.append(\"3. Create decision rules for borderline cases\")\n",
        "    content.append(\"4. Review rubric areas where you struggled\")\n",
        "    content.append(\"5. Proceed to Practice Round 2 with refined approach\")\n",
        "    content.append(\"6. After Round 2, assess readiness for full validation scoring\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "\n",
        "    # Write to file\n",
        "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(content))\n",
        "\n",
        "    print(f\"‚úì Benchmark scores file created: {output_txt}\")\n",
        "    print(f\"  Total summaries: {len(df)}\")\n",
        "    print(f\"  Exemplars: {len(exemplars)}\")\n",
        "    print(f\"  Practice Round 1: {len(round_1)}\")\n",
        "    print(f\"  Practice Round 2: {len(round_2)}\")\n",
        "    print(f\"\\nScore distribution:\")\n",
        "    for score, count in score_counts.items():\n",
        "        print(f\"  Score {score}: {count}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the benchmark scores file\n",
        "    create_benchmark_scores_file(CALIBRATION_SUBSET_PATH, OUTPUT_PATH)\n",
        "\n",
        "    print(\"\\n‚úì Generation complete!\")\n",
        "    print(f\"\\nReminder: DO NOT open {OUTPUT_PATH} until after blind scoring!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCC-EuslhC0D",
        "outputId": "9eb775ef-d091-4c97-f52e-9e0a37cebbc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Benchmark scores file created: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/CALIBRATION_BENCHMARK_SCORES.txt\n",
            "  Total summaries: 12\n",
            "  Exemplars: 4\n",
            "  Practice Round 1: 4\n",
            "  Practice Round 2: 4\n",
            "\n",
            "Score distribution:\n",
            "  Score 1: 2\n",
            "  Score 2: 3\n",
            "  Score 3: 3\n",
            "  Score 4: 2\n",
            "  Score 5: 1\n",
            "  Score 6: 1\n",
            "\n",
            "‚úì Generation complete!\n",
            "\n",
            "Reminder: DO NOT open /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/Phase2_Calibration/CALIBRATION_BENCHMARK_SCORES.txt until after blind scoring!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "25-Summary Validation Subset Selector\n",
        "Stratified sampling from 60-summary validation set for accelerated timeline\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION - Adjust these paths for your Google Drive setup\n",
        "# ============================================================================\n",
        "\n",
        "# Path to your validation_set_combined_60.csv in Google Drive\n",
        "VALIDATION_DATASET_PATH = \"/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv\"\n",
        "\n",
        "# Output directory in Google Drive\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/data\"\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Target distribution for 25 summaries (proportional to original 60)\n",
        "TARGET_DISTRIBUTION = {\n",
        "    1: 3,   # From 8 available\n",
        "    2: 8,   # From 18 available\n",
        "    3: 8,   # From 20 available\n",
        "    4: 4,   # From 10 available\n",
        "    5: 1,   # From 3 available\n",
        "    6: 1    # From 1 available\n",
        "}\n",
        "# Total = 25 summaries\n",
        "\n",
        "# ============================================================================\n",
        "\n",
        "def select_validation_subset(input_csv, target_dist, random_seed=42):\n",
        "    \"\"\"\n",
        "    Select stratified 25-summary subset from 60-summary validation set.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    input_csv : str\n",
        "        Path to validation_set_combined_60.csv\n",
        "    target_dist : dict\n",
        "        Target number of summaries per score level\n",
        "    random_seed : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        Selected subset of 25 summaries\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"FAST-TRACK VALIDATION SUBSET SELECTION\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "\n",
        "    # Read full validation dataset\n",
        "    print(f\"Reading validation dataset...\")\n",
        "    print(f\"  Path: {input_csv}\")\n",
        "    df = pd.read_csv(input_csv)\n",
        "    print(f\"‚úì Loaded {len(df)} summaries\")\n",
        "    print()\n",
        "\n",
        "    # Set random seed\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # Display current distribution\n",
        "    print(\"Current score distribution (60 summaries):\")\n",
        "    score_dist = df['score'].value_counts().sort_index()\n",
        "    for score, count in score_dist.items():\n",
        "        auth_count = len(df[(df['score'] == score) & (df['synthetic_flag'] == 0)])\n",
        "        synth_count = len(df[(df['score'] == score) & (df['synthetic_flag'] == 1)])\n",
        "        print(f\"  Score {score}: {count} total ({auth_count} authentic, {synth_count} synthetic)\")\n",
        "    print()\n",
        "\n",
        "    # Stratified sampling by score\n",
        "    print(\"Target distribution (25 summaries):\")\n",
        "    for score, target in target_dist.items():\n",
        "        print(f\"  Score {score}: {target} summaries\")\n",
        "    print()\n",
        "\n",
        "    print(\"Selecting summaries...\")\n",
        "    selected_dfs = []\n",
        "\n",
        "    for score, target_count in target_dist.items():\n",
        "        # Get all summaries with this score\n",
        "        score_df = df[df['score'] == score].copy()\n",
        "\n",
        "        if len(score_df) < target_count:\n",
        "            print(f\"  ‚ö† Warning: Only {len(score_df)} summaries available for score {score} (need {target_count})\")\n",
        "            selected = score_df\n",
        "        else:\n",
        "            # Randomly sample target_count summaries\n",
        "            selected = score_df.sample(n=target_count, random_state=random_seed)\n",
        "\n",
        "        selected_dfs.append(selected)\n",
        "\n",
        "        auth_selected = len(selected[selected['synthetic_flag'] == 0])\n",
        "        synth_selected = len(selected[selected['synthetic_flag'] == 1])\n",
        "        print(f\"  ‚úì Score {score}: Selected {len(selected)} ({auth_selected} authentic, {synth_selected} synthetic)\")\n",
        "\n",
        "    # Combine all selected summaries\n",
        "    subset_df = pd.concat(selected_dfs, ignore_index=True)\n",
        "\n",
        "    # Shuffle the final subset\n",
        "    subset_df = subset_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "\n",
        "    # Add validation_id for tracking\n",
        "    subset_df['validation_id'] = [f'VAL_{str(i+1).zfill(2)}' for i in range(len(subset_df))]\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 80)\n",
        "    print(\"SELECTION COMPLETE\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Total selected: {len(subset_df)} summaries\")\n",
        "    print()\n",
        "\n",
        "    # Final distribution summary\n",
        "    print(\"Final subset distribution:\")\n",
        "    for score in sorted(subset_df['score'].unique()):\n",
        "        count = len(subset_df[subset_df['score'] == score])\n",
        "        auth_count = len(subset_df[(subset_df['score'] == score) & (subset_df['synthetic_flag'] == 0)])\n",
        "        synth_count = len(subset_df[(subset_df['score'] == score) & (subset_df['synthetic_flag'] == 1)])\n",
        "        print(f\"  Score {score}: {count} ({auth_count} authentic, {synth_count} synthetic)\")\n",
        "\n",
        "    total_auth = len(subset_df[subset_df['synthetic_flag'] == 0])\n",
        "    total_synth = len(subset_df[subset_df['synthetic_flag'] == 1])\n",
        "    print()\n",
        "    print(f\"Overall: {total_auth} authentic ({total_auth/len(subset_df)*100:.1f}%), \"\n",
        "          f\"{total_synth} synthetic ({total_synth/len(subset_df)*100:.1f}%)\")\n",
        "\n",
        "    return subset_df\n",
        "\n",
        "\n",
        "def create_scoring_text_file(subset_df, output_txt):\n",
        "    \"\"\"\n",
        "    Create formatted text file for manual scoring.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    subset_df : pd.DataFrame\n",
        "        Selected validation subset\n",
        "    output_txt : str\n",
        "        Path for output text file\n",
        "    \"\"\"\n",
        "\n",
        "    content = []\n",
        "\n",
        "    # Header\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"FAST-TRACK VALIDATION SET - 25 SUMMARIES FOR SCORING\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"Instructions:\")\n",
        "    content.append(\"1. Score each summary across all 4 dimensions using your calibrated approach\")\n",
        "    content.append(\"2. Record scores in your scoring template spreadsheet\")\n",
        "    content.append(\"3. Document brief rationale for borderline cases\")\n",
        "    content.append(\"4. These scores will be your ground truth for LLM validation\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"Timeline: Complete all 25 by end of day Monday, December 2\")\n",
        "    content.append(\"Estimated time: 6-8 hours (15-20 min per summary)\")\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "\n",
        "    # Each summary\n",
        "    for idx, row in subset_df.iterrows():\n",
        "        content.append(\"\")\n",
        "        content.append(\"=\" * 80)\n",
        "        content.append(f\"{row['validation_id']}: {row['essay_id']}\")\n",
        "        content.append(\"=\" * 80)\n",
        "        content.append(f\"Original Score: {row['score']}\")\n",
        "        content.append(f\"Source: {'Authentic' if row['synthetic_flag'] == 0 else 'Synthetic'}\")\n",
        "        content.append(f\"Word Count: {row['word_count']}\")\n",
        "        if row['synthetic_flag'] == 1 and pd.notna(row.get('target_error_pattern')):\n",
        "            content.append(f\"Error Pattern: {row['target_error_pattern']}\")\n",
        "        content.append(\"\")\n",
        "        content.append(\"-\" * 80)\n",
        "        content.append(\"SUMMARY TEXT:\")\n",
        "        content.append(\"-\" * 80)\n",
        "        content.append(\"\")\n",
        "        content.append(row['full_text'])\n",
        "        content.append(\"\")\n",
        "        content.append(\"-\" * 80)\n",
        "        content.append(\"YOUR SCORES (Complete after reading):\")\n",
        "        content.append(\"-\" * 80)\n",
        "        content.append(\"Completeness (1-5): _____\")\n",
        "        content.append(\"Accuracy (1-5): _____\")\n",
        "        content.append(\"Coherence (1-5): _____\")\n",
        "        content.append(\"Conciseness (1-5): _____\")\n",
        "        content.append(\"\")\n",
        "        content.append(\"Brief rationale/notes:\")\n",
        "        content.append(\"\")\n",
        "        content.append(\"\")\n",
        "        content.append(\"=\" * 80)\n",
        "        content.append(\"\")\n",
        "\n",
        "    # Footer\n",
        "    content.append(\"\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"END OF VALIDATION SET\")\n",
        "    content.append(\"=\" * 80)\n",
        "    content.append(\"\")\n",
        "    content.append(\"Next steps after scoring:\")\n",
        "    content.append(\"1. Transfer scores to spreadsheet\")\n",
        "    content.append(\"2. Begin LLM prompt design (Tuesday)\")\n",
        "    content.append(\"3. Test initial prompt on 5 summaries (Tuesday)\")\n",
        "    content.append(\"4. Prepare progress update presentation (Wednesday)\")\n",
        "\n",
        "    # Write to file\n",
        "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(content))\n",
        "\n",
        "    print(f\"‚úì Scoring text file created\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "    print()\n",
        "\n",
        "    # Define output paths\n",
        "    output_csv = os.path.join(OUTPUT_DIR, \"validation_subset_25.csv\")\n",
        "    output_txt = os.path.join(OUTPUT_DIR, \"validation_subset_25_for_scoring.txt\")\n",
        "\n",
        "    # Select subset\n",
        "    subset_df = select_validation_subset(\n",
        "        VALIDATION_DATASET_PATH,\n",
        "        TARGET_DISTRIBUTION,\n",
        "        RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    # Save CSV\n",
        "    print(f\"\\nSaving subset CSV...\")\n",
        "    subset_df.to_csv(output_csv, index=False)\n",
        "    print(f\"‚úì CSV saved: {output_csv}\")\n",
        "    print(f\"  {len(subset_df)} summaries\")\n",
        "\n",
        "    # Create scoring text file\n",
        "    print(f\"\\nCreating scoring text file...\")\n",
        "    create_scoring_text_file(subset_df, output_txt)\n",
        "    print(f\"‚úì Text file saved: {output_txt}\")\n",
        "\n",
        "    # Summary statistics\n",
        "    print()\n",
        "    print(\"=\" * 80)\n",
        "    print(\"FILES CREATED IN GOOGLE DRIVE\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"1. validation_subset_25.csv - Subset data for analysis\")\n",
        "    print(f\"2. validation_subset_25_for_scoring.txt - Formatted for manual scoring\")\n",
        "    print()\n",
        "    print(f\"Location: {OUTPUT_DIR}\")\n",
        "    print()\n",
        "    print(\"=\" * 80)\n",
        "    print(\"NEXT STEPS - FAST-TRACK SCHEDULE\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "    print(\"üìÖ MONDAY DEC 1 (Tomorrow):\")\n",
        "    print(\"   ‚Ä¢ Score all 25 summaries (6-8 hours)\")\n",
        "    print(\"   ‚Ä¢ Use your calibrated approach from practice rounds\")\n",
        "    print(\"   ‚Ä¢ Document scores in spreadsheet as you go\")\n",
        "    print()\n",
        "    print(\"üìÖ TUESDAY DEC 2:\")\n",
        "    print(\"   ‚Ä¢ Design base LLM evaluation prompt\")\n",
        "    print(\"   ‚Ä¢ Set up Llama 3.1 8B in Colab\")\n",
        "    print(\"   ‚Ä¢ Test on 5 summaries\")\n",
        "    print(\"   ‚Ä¢ Calculate initial agreement metrics\")\n",
        "    print()\n",
        "    print(\"üìÖ WEDNESDAY DEC 3:\")\n",
        "    print(\"   ‚Ä¢ Prepare progress update presentation\")\n",
        "    print(\"   ‚Ä¢ Iterate on prompt based on results\")\n",
        "    print(\"   ‚Ä¢ DELIVERABLE: Progress update\")\n",
        "    print()\n",
        "    print(\"üéØ You're on track for the December 10 demo!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob1Rt8laGGgl",
        "outputId": "13bbd1b8-4bc3-4760-d7b6-a886c3f3e1a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Output directory: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/data\n",
            "\n",
            "================================================================================\n",
            "FAST-TRACK VALIDATION SUBSET SELECTION\n",
            "================================================================================\n",
            "\n",
            "Reading validation dataset...\n",
            "  Path: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_1/data/dataset/validation_set_combined_60.csv\n",
            "‚úì Loaded 60 summaries\n",
            "\n",
            "Current score distribution (60 summaries):\n",
            "  Score 1: 8 total (5 authentic, 3 synthetic)\n",
            "  Score 2: 18 total (11 authentic, 7 synthetic)\n",
            "  Score 3: 20 total (12 authentic, 8 synthetic)\n",
            "  Score 4: 10 total (6 authentic, 4 synthetic)\n",
            "  Score 5: 3 total (2 authentic, 1 synthetic)\n",
            "  Score 6: 1 total (1 authentic, 0 synthetic)\n",
            "\n",
            "Target distribution (25 summaries):\n",
            "  Score 1: 3 summaries\n",
            "  Score 2: 8 summaries\n",
            "  Score 3: 8 summaries\n",
            "  Score 4: 4 summaries\n",
            "  Score 5: 1 summaries\n",
            "  Score 6: 1 summaries\n",
            "\n",
            "Selecting summaries...\n",
            "  ‚úì Score 1: Selected 3 (3 authentic, 0 synthetic)\n",
            "  ‚úì Score 2: Selected 8 (4 authentic, 4 synthetic)\n",
            "  ‚úì Score 3: Selected 8 (3 authentic, 5 synthetic)\n",
            "  ‚úì Score 4: Selected 4 (3 authentic, 1 synthetic)\n",
            "  ‚úì Score 5: Selected 1 (1 authentic, 0 synthetic)\n",
            "  ‚úì Score 6: Selected 1 (1 authentic, 0 synthetic)\n",
            "\n",
            "================================================================================\n",
            "SELECTION COMPLETE\n",
            "================================================================================\n",
            "Total selected: 25 summaries\n",
            "\n",
            "Final subset distribution:\n",
            "  Score 1: 3 (3 authentic, 0 synthetic)\n",
            "  Score 2: 8 (4 authentic, 4 synthetic)\n",
            "  Score 3: 8 (3 authentic, 5 synthetic)\n",
            "  Score 4: 4 (3 authentic, 1 synthetic)\n",
            "  Score 5: 1 (1 authentic, 0 synthetic)\n",
            "  Score 6: 1 (1 authentic, 0 synthetic)\n",
            "\n",
            "Overall: 15 authentic (60.0%), 10 synthetic (40.0%)\n",
            "\n",
            "Saving subset CSV...\n",
            "‚úì CSV saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/data/validation_subset_25.csv\n",
            "  25 summaries\n",
            "\n",
            "Creating scoring text file...\n",
            "‚úì Scoring text file created\n",
            "‚úì Text file saved: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/data/validation_subset_25_for_scoring.txt\n",
            "\n",
            "================================================================================\n",
            "FILES CREATED IN GOOGLE DRIVE\n",
            "================================================================================\n",
            "1. validation_subset_25.csv - Subset data for analysis\n",
            "2. validation_subset_25_for_scoring.txt - Formatted for manual scoring\n",
            "\n",
            "Location: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/Phase_2/data\n",
            "\n",
            "================================================================================\n",
            "NEXT STEPS - FAST-TRACK SCHEDULE\n",
            "================================================================================\n",
            "\n",
            "üìÖ MONDAY DEC 2 (Tomorrow):\n",
            "   ‚Ä¢ Score all 25 summaries (6-8 hours)\n",
            "   ‚Ä¢ Use your calibrated approach from practice rounds\n",
            "   ‚Ä¢ Document scores in spreadsheet as you go\n",
            "\n",
            "üìÖ TUESDAY DEC 3:\n",
            "   ‚Ä¢ Design base LLM evaluation prompt\n",
            "   ‚Ä¢ Set up Llama 3.1 8B in Colab\n",
            "   ‚Ä¢ Test on 5 summaries\n",
            "   ‚Ä¢ Calculate initial agreement metrics\n",
            "\n",
            "üìÖ WEDNESDAY DEC 4:\n",
            "   ‚Ä¢ Prepare progress update presentation\n",
            "   ‚Ä¢ Iterate on prompt based on results\n",
            "   ‚Ä¢ DELIVERABLE: Progress update\n",
            "\n",
            "üéØ You're on track for the December 10 demo!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Installing required packages...\")\n",
        "!pip install -q transformers accelerate bitsandbytes huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gCZT4fLyeUW",
        "outputId": "e5600062-6866-4d98-bf6d-6be86409655a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úì Authenticated with Hugging Face (via Secrets)\")\n",
        "except Exception:\n",
        "    print(\"Secret not found. Please enter your Hugging Face token manually:\")\n",
        "    login()\n",
        "    print(\"‚úì Authenticated with Hugging Face (manual entry)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPJbR3NR9PU0",
        "outputId": "f0cbadbb-d88d-43cc-a87e-8edc8c534a78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Authenticated with Hugging Face (via Secrets)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "print(\"Loading Llama 3.1 8B-Instruct...\")\n",
        "print(\"(This takes 2-5 minutes on first run)\")\n",
        "\n",
        "MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# Configure 4-bit quantization to fit in Colab GPU memory\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "print(\"‚úì Model loaded successfully!\")\n",
        "print(f\"  Model device: {model.device}\")"
      ],
      "metadata": {
        "id": "byQvPiZpBBz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_TEXT = \"\"\"THE CHALLENGE OF EXPLORING VENUS\n",
        "\n",
        "Venus, sometimes called the \"Evening Star,\" is one of the brightest points of light in the night sky, making it simple for even an amateur stargazer to spot. However, this nickname is misleading since Venus is actually a planet. While Venus is simple to see from the distant but safe vantage point of Earth, it has proved a very challenging place to examine more closely.\n",
        "\n",
        "Often referred to as Earth's \"twin,\" Venus is the closest planet to Earth in terms of density and size, and occasionally the closest in distance too. Earth and Venus, along with Mars, our other planetary neighbor, orbit the sun at different speeds. These differences in speed mean that sometimes we are closer to Mars and other times to Venus. Because Venus is sometimes right around the corner‚Äîin space terms‚Äîhumans have sent numerous spacecraft to land on this cloud-draped world. Each previous mission was unmanned, and for good reason, since no spacecraft survived the landing for more than a few hours. Maybe this issue explains why not a single spaceship has touched down on Venus in more than three decades. Numerous factors contribute to Venus's reputation as a challenging planet for humans to study, despite its proximity to us.\n",
        "\n",
        "A thick atmosphere of almost 97 percent carbon dioxide blankets Venus. Even more challenging are the clouds of highly corrosive sulfuric acid in Venus's atmosphere. On the planet's surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet. These conditions are far more extreme than anything humans encounter on Earth; such an environment would crush even a submarine accustomed to diving to the deepest parts of our oceans and would liquefy many metals. Also notable, Venus has the hottest surface temperature of any planet in our solar system, even though Mercury is closer to our sun. Beyond high pressure and heat, Venusian geology and weather present additional impediments like erupting volcanoes, powerful earthquakes, and frequent lightning strikes to probes seeking to land on its surface.\n",
        "\n",
        "If our sister is so inhospitable, why are scientists even discussing further visits to its surface? Astronomers are fascinated by Venus because it may well once have been the most Earth-like planet in our solar system. Long ago, Venus was probably covered largely with oceans and could have supported various forms of life, just like Earth. Today, Venus still has some features that are analogous to those on Earth. The planet has a surface of rocky sediment and includes familiar features such as valleys, mountains, and craters. Furthermore, recall that Venus can sometimes be our nearest option for a planetary visit, a crucial consideration given the long time frames of space travel. The value of returning to Venus seems indisputable, but what are the options for making such a mission both safe and scientifically productive?\n",
        "\n",
        "The National Aeronautics and Space Administration (NASA) has one particularly compelling idea for sending humans to study Venus. NASA's possible solution to the hostile conditions on the surface of Venus would allow scientists to float above the fray. Imagine a blimp-like vehicle hovering 30 or so miles above the roiling Venusian landscape. Just as our jet airplanes travel at a higher altitude to fly over many storms, a vehicle hovering over Venus would avoid the unfriendly ground conditions by staying up and out of the way. At thirty-plus miles above the surface, temperatures would still be toasty at around 170 degrees Fahrenheit, but the air pressure would be close to that of sea level on Earth. Solar power would be plentiful, and radiation would not exceed Earth‚Äôs levels. Not easy conditions, but survivable for humans.\n",
        "\n",
        "However, peering at Venus from a ship orbiting or hovering safely far above the planet can provide only limited insight into ground conditions, rendering standard forms of photography and videography ineffective. More importantly, researchers cannot take samples of rock, gas, or anything else from a distance. Therefore, scientists seeking to conduct a thorough mission to understand Venus would need to get up close and personal despite the risks. Or maybe we should think of them as challenges. Many researchers are working on innovations that would allow our machines to last long enough to contribute meaningfully to our knowledge of Venus.\n",
        "\n",
        "NASA is working on other approaches to studying Venus. For example, some simplified electronics made of silicon carbide have been tested in a chamber simulating the chaos of Venus's surface and have lasted for three weeks in such conditions. Another project is looking back at an old technology called mechanical computers. These devices were first envisioned in the 1800s and played an important role in the 1940s during World War II. The thought of computers existing in those days may sound shocking, but these devices made calculations by using gears and levers and did not require electronics at all. Modern computers are enormously powerful, flexible, and quick, but tend to be more delicate when it comes to extreme physical conditions. Just imagine exposing a cell phone or tablet to acid or heat capable of melting tin. By comparison, systems that use mechanical parts can be made more resistant to pressure, heat, and other forces.\n",
        "\n",
        "Striving to meet the challenge presented by Venus has value, not only because of the insight to be gained on the planet itself, but also because human curiosity will likely lead us into many equally intimidating endeavors. Our travels on Earth and beyond should not be limited by dangers and doubts but should be expanded to meet the very edges of imagination and innovation.\"\"\"\n",
        "\n",
        "print(f\"Source text loaded: {len(SOURCE_TEXT)} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcRGoOTCB6y8",
        "outputId": "38d88797-e7a1-43fd-f763-20856f6d7248"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source text loaded: 5778 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUBRIC = \"\"\"\n",
        "## SUMMARY EVALUATION RUBRIC (Grades 6-8)\n",
        "\n",
        "### Task Context\n",
        "Students read \"The Challenge of Exploring Venus\" and wrote a response to this prompt:\n",
        "\"Write an essay evaluating how well the author supports the claim that studying Venus is a worthy pursuit despite the dangers. Use evidence from the text to support your evaluation.\"\n",
        "\n",
        "This is a HYBRID task requiring students to:\n",
        "1. Identify the author's claim and supporting evidence\n",
        "2. Evaluate how effectively the author builds the argument\n",
        "3. Support their evaluation with specific textual evidence\n",
        "\n",
        "### Scoring Dimensions\n",
        "\n",
        "**COMPLETENESS (1-5)**: Coverage of the author's main supporting points\n",
        "- 5: Identifies ALL major supporting points (extreme conditions, scientific value, NASA solutions, alternative technologies) with specific evidence\n",
        "- 4: Identifies MOST major points with evidence; one minor omission\n",
        "- 3: Identifies SEVERAL points but misses at least one crucial aspect\n",
        "- 2: Identifies only a FEW points; missing multiple important concepts\n",
        "- 1: Fails to identify main points or provides only vague statements\n",
        "\n",
        "**ACCURACY (1-5)**: Factual correctness of claims about the text\n",
        "- 5: All information factually correct; precise language; no distortions\n",
        "- 4: Generally accurate with only minor imprecisions that don't alter meaning (awkward paraphrasing with correct meaning = 4, not 3)\n",
        "- 3: Contains accurate points but also noticeable errors or oversimplifications\n",
        "- 2: Multiple significant factual errors or misrepresentations (note: quoting or paraphrasing the source text is not a factual error)\n",
        "- 1: Information contradicts source or includes fabricated details\n",
        "\n",
        "**COHERENCE (1-5)**: Logical organization and flow\n",
        "- 5: Ideas flow logically; effective transitions; each sentence builds on previous\n",
        "- 4: Clearly organized; transitions mostly effective; minor rough spots\n",
        "- 3: Basic organization but inconsistent flow; transitions missing in places\n",
        "- 2: Organization unclear; ideas jump between topics; few transitions\n",
        "- 1: No discernible organization; disconnected fragments\n",
        "\n",
        "**CONCISENESS (1-5)**: Efficiency of expression\n",
        "- 5: Every sentence essential; no repetition; focused on main ideas\n",
        "- 4: Mostly efficient; only minor wordiness or brief repetition\n",
        "- 3: Noticeable wordiness; some repetition; includes irrelevant information\n",
        "- 2: Significant wordiness; frequent repetition; could be cut substantially\n",
        "- 1: Excessively wordy; ideas repeated multiple times; essential content buried\n",
        "\"\"\"\n",
        "\n",
        "print(\"Rubric loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwBqTyUUC4pu",
        "outputId": "7aa23255-8d41-4ca5-edd2-2d5b3e8220ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rubric loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_evaluation_prompt(student_summary):\n",
        "    \"\"\"Create the full CoT evaluation prompt for a student summary.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"You are an experienced middle school English Language Arts teacher evaluating a student's response to a reading comprehension task. The student read an article about Venus exploration and wrote an evaluative essay.\n",
        "\n",
        "## SOURCE TEXT\n",
        "{SOURCE_TEXT}\n",
        "\n",
        "## STUDENT TASK\n",
        "The student was asked: \"Write an essay evaluating how well the author supports the claim that studying Venus is a worthy pursuit despite the dangers. Use evidence from the text to support your evaluation.\"\n",
        "\n",
        "## STUDENT RESPONSE\n",
        "{student_summary}\n",
        "\n",
        "## EVALUATION RUBRIC\n",
        "{RUBRIC}\n",
        "\n",
        "## YOUR TASK\n",
        "Evaluate this student response using Chain-of-Thought reasoning. For each dimension:\n",
        "\n",
        "1. First, identify specific evidence from the student's response\n",
        "2. Then, compare against the rubric criteria\n",
        "3. Finally, assign a score (1-5) with brief justification\n",
        "\n",
        "**Think step-by-step before providing scores.**\n",
        "\n",
        "### Step 1: Analyze COMPLETENESS\n",
        "What main supporting points from the article does the student identify or discuss?\n",
        "- Extreme conditions on Venus (heat, pressure, sulfuric acid, etc.)?\n",
        "- Scientific value (Earth-like past, similar features, proximity)?\n",
        "- NASA's blimp/hovering solution?\n",
        "- Alternative technologies (silicon carbide, mechanical computers)?\n",
        "Identify what's present and what's missing.\n",
        "\n",
        "### Step 2: Analyze ACCURACY\n",
        "Check each factual claim the student makes against the source text:\n",
        "- Are temperatures, pressures, and other numbers correct?\n",
        "- Are the solutions described accurately?\n",
        "- Is the author's argument represented faithfully?\n",
        "\n",
        "### Step 3: Analyze COHERENCE\n",
        "Examine the organization and flow:\n",
        "- Is there a clear introduction and conclusion?\n",
        "- Do paragraphs/sentences connect logically?\n",
        "- Are transitions used effectively?\n",
        "\n",
        "### Step 4: Analyze CONCISENESS\n",
        "Check for efficiency:\n",
        "- Is there unnecessary repetition?\n",
        "- Are there irrelevant tangents?\n",
        "- Could the response be shortened without losing meaning?\n",
        "\n",
        "## PROVIDE YOUR EVALUATION\n",
        "\n",
        "After your analysis, provide scores in this EXACT format:\n",
        "\n",
        "COMPLETENESS: [score 1-5]\n",
        "Justification: [1-2 sentences]\n",
        "\n",
        "ACCURACY: [score 1-5]\n",
        "Justification: [1-2 sentences]\n",
        "\n",
        "COHERENCE: [score 1-5]\n",
        "Justification: [1-2 sentences]\n",
        "\n",
        "CONCISENESS: [score 1-5]\n",
        "Justification: [1-2 sentences]\n",
        "\n",
        "OVERALL FEEDBACK: [2-3 sentences of constructive feedback for the student]\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "OmXaGnI7GZUT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_simple_prompt(student_summary):\n",
        "    \"\"\"A simpler, more direct prompt without extensive CoT scaffolding.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"You are a middle school English teacher grading a student essay.\n",
        "\n",
        "ARTICLE SUMMARY: The source article discusses why Venus is difficult to explore (extreme heat, pressure, sulfuric acid) but argues it's worth studying because Venus may have once been Earth-like, has similar features today, and is sometimes our closest neighbor. NASA proposes hovering vehicles at 30 miles altitude where conditions are survivable. Scientists are also developing heat-resistant electronics and mechanical computers.\n",
        "\n",
        "STUDENT TASK: Evaluate how well the author supports the claim that studying Venus is worthwhile despite the dangers.\n",
        "\n",
        "STUDENT RESPONSE:\n",
        "{student_summary}\n",
        "\n",
        "SCORING RUBRIC (1-5 scale):\n",
        "- COMPLETENESS: Does it cover the main supporting points?\n",
        "- ACCURACY: Are the facts correct?\n",
        "- COHERENCE: Is it well-organized with good flow?\n",
        "- CONCISENESS: Is it focused without unnecessary repetition?\n",
        "\n",
        "Provide scores in this format:\n",
        "COMPLETENESS: [1-5]\n",
        "ACCURACY: [1-5]\n",
        "COHERENCE: [1-5]\n",
        "CONCISENESS: [1-5]\n",
        "BRIEF FEEDBACK: [1-2 sentences]\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "OVdLrcmAGmZh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_evaluation(prompt, max_new_tokens=800, temperature=0.1):\n",
        "    \"\"\"Generate model response for an evaluation prompt.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert middle school English teacher who evaluates student writing using rubrics.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    # Format for Llama 3.1 Instruct\n",
        "    input_text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Build generation kwargs conditionally\n",
        "    generate_kwargs = {\n",
        "        \"max_new_tokens\": max_new_tokens,\n",
        "        \"pad_token_id\": tokenizer.eos_token_id,\n",
        "    }\n",
        "\n",
        "    if temperature > 0:\n",
        "        generate_kwargs[\"do_sample\"] = True\n",
        "        generate_kwargs[\"temperature\"] = temperature\n",
        "        generate_kwargs[\"top_p\"] = 0.9\n",
        "    else:\n",
        "        generate_kwargs[\"do_sample\"] = False\n",
        "        # --- FIX: Explicitly unset these to silence the warning ---\n",
        "        generate_kwargs[\"temperature\"] = None\n",
        "        generate_kwargs[\"top_p\"] = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, **generate_kwargs)\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract just the assistant's response\n",
        "    if \"<|assistant|>\" in response:\n",
        "        response = response.split(\"<|assistant|>\")[-1].strip()\n",
        "    elif \"assistant\" in response.lower():\n",
        "        parts = response.split(\"COMPLETENESS:\")\n",
        "        if len(parts) > 1:\n",
        "            response = \"COMPLETENESS:\" + parts[-1]\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "OKrlbtIBHVrK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_scores(response_text):\n",
        "    \"\"\"Extract numerical scores from the model's response.\"\"\"\n",
        "    scores = {}\n",
        "\n",
        "    # Pattern: DIMENSION: [score] or DIMENSION: score\n",
        "    patterns = {\n",
        "        'completeness': r'COMPLETENESS:\\s*\\[?(\\d)\\]?',\n",
        "        'accuracy': r'ACCURACY:\\s*\\[?(\\d)\\]?',\n",
        "        'coherence': r'COHERENCE:\\s*\\[?(\\d)\\]?',\n",
        "        'conciseness': r'CONCISENESS:\\s*\\[?(\\d)\\]?'\n",
        "    }\n",
        "\n",
        "    for dim, pattern in patterns.items():\n",
        "        match = re.search(pattern, response_text, re.IGNORECASE)\n",
        "        if match:\n",
        "            scores[dim] = int(match.group(1))\n",
        "        else:\n",
        "            scores[dim] = None\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "drwYURNsH0I-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SUMMARIES = {\n",
        "    \"VAL_02\": \"\"\"Do you guys think that venus is dangers? Well for our part venus need to get up close and personal despite the risk or maybe they should think of them as challenges. Astronmers are fascinated by venus because it may once have been the most earth-like planet in our solar system. Even more challenging are the clouds of highly corrosive sulfuric acid in venus's atmosphere. Venus is simple to see from the distant but safe vantage point of earth, it had proved a very challenging place to examine more closely. Venus would need to get uo close and personal despite the risk and maybe should think of them as challenges.\n",
        "\n",
        "Astronomers are fascinated by venus because it may well once have been the most earth-like planet in the solar system because people from long time had to covered the oceans to support carious forms of life to them just how earth is from us today. Also because the value of the returning of the venus seem to be a little difficult but there was other option to make a mission to be safe and productive to both of them for the astronomers to be by venus and know the planets in the solar system.\n",
        "\n",
        "Even more challenging are the clouds of highly corrosvie sulfuric acid in venus's atmosphere because they think that the challenging for venus might not be working for them but now they do work because the conditions are now more extreme then any human encounter out there and all of the environment can crush of a submarine. But then venus has the hottest surface temperature to any of the planet in the solar system that their is even when mercury is close to the sun venus can still be hot for the system being beside another planet.\n",
        "\n",
        "Venus is simple to see from the distant but safe vantage point of earth, it has proved a very challenging place to examine more closely. Venus can be the closest planet to earth even in terms of size and density. Also each of the previous mission can have an unmanned and for a reason no sacecraft has been survived for the time of landing for more than hours or even minutes. Venus had more than three decades, but venus reputation for a challenge planet is for humans to work on and study for and to despite the proximity to it.\n",
        "\n",
        "This is what I think the author suggests to the study of venus because venus would need to get up close and personal despite the risk and maybe should think of them for a challenge, because astronomers are fascinated by venus because it may once have been the most earth-like planet in the solar system, even more challenging are the clouds of highly corrosive sulfuric acid in venus's atmosphere, and venus is simple to see from the distant but can be safe vantage point in earth and has proved a very challenging place to examine more closely to it.\"\"\",\n",
        "\n",
        "    \"VAL_04\": \"\"\"The author excellently supports the idea that even though it is dangerous, Venus is worth exploring. You can tell the author supports the idea of further exploration of Venus because of their use of details. The author explains Venus, why it is so dangerous, and why we should continue exploring it to support the idea that Venus is a challenge that we should not give up on.\n",
        "\n",
        "One of the reasons the authors point comes across so well is how in depth they explain Venus so that the reader can be more knowlegable about the topic before the author begins to explain why we should continue to explore it. The author gives as much detail as a book about planets so that the reader knows that the author is well versed in the topic and is not having an opinion without factual evidence to support it. In paragraph 2, it says \"Often referred to as Earth's \"twin\", Venus is the closest planet to Earth in terms of density and size, and occasionally the closest in distance too. Earth, Venus, and Mars, our other planetary neighbor, orbit the sun at different speeds.\". Throughout this paragraph, the author gives information about Venus so you can understand in depth how and why it is explored, and most importantly, why it is so dangerous.\n",
        "\n",
        "The danger of Venus is why it is mostly unknown, and why humans want to study it more. Even unmanned missions do not survive Venus's burning temperatures and intense pressure for more than a couple hours, making it very challenging to study. The author uses data like in the quote \" A thick atmosphere of amost 97 percent carbon dioxide blankets Venus. Even more challenging are the clouds of highly corrosive sulfuric acid in Venus's atmosphere.\"(paragraph 3), to show how dangerous it is and why Venus is mostly unexplored. The author shows that the danger is not keeping NASA away, but it is drawing them closer. The author states that \"Astronomers are facinated by Venus because it may well once have been the most Earth-like planet in our solar system.\" (paragraph 4). To the author, natural human curiousity is another reason why we should continue pursuing Venus, and how we are going to continue to explore Venus, even if it is dangerous.\n",
        "\n",
        "The author uses examples of ideas from real scientists to support the statement that we should not give up on the idea of knowing more about Venus. NASA is still trying to figure out a way to have people explore Venus deeper. The author uses NASA's solutions to the conditions of Venus to explain why we should never stop exploring space. NASA is coming up with solutions to Venus, but they might prove ineffective, so pursuing Veus is still a worthy idea. They are trying to come up with a way to float above the harms of Venus, so they can still study it close, but be unaffected by the harmful temperatures and pressures of the surface. The author offers a rebuttal to this idea, saying \"peering at Venus from a ship orbiting or hovering safely far above the planet can provide only limited insight on ground conditions because most forms of light cannot penetrate the dense atmosphere, rendering standard forms of photography and videography ineffective. More importantly, researchers cannot take samples of rock, gas, or anything else, from a distance.\" (paragraph 6). This information the author presents makes the reader understand that Venus is insanely difficult to explore when even NASA can not present useful ideas for intense exploration. But even when every idea is shut down, the author makes it clear that we should not give up the fight for exploration.\n",
        "\n",
        "Venus is still an unhabitable planet for even our smartest robots. We as humans have tried our hardest to make sure we understand the many planets in out solar system. Even though it seems impossible, the author explains very successfully that this does not mean exploring Venus is impossible, it just means Venus is a complicated puzzle, but when it is solved, everyone will be overwhelmed with satisfaction, so to the author, giving up is not an option. The author believes that one day, exploring Venus in depth will be possible, and they explain their reasoning behind it very clearly so the reader can understand that studying Venus is a worthy persuit despite the dangers it presents.\"\"\",\n",
        "\n",
        "    \"VAL_15\": \"\"\"In \"The Challenge of Exploring Venus,\" the author talks about why studying Venus is important, even though it is dangerous.\n",
        "\n",
        "First, Venus is really hot. The article says the temperature is over 800 degrees Fahrenheit. That's way hotter than most things on Earth. Second, there are clouds of sulfuric acid in the atmosphere. This makes it hard for machines to land there. Third, Venus has a lot of pressure that is 90 times stronger than on Earth. This can crush any spacecraft that tries to land. Fourth, scientists think Venus could have had oceans a long time ago and possibly life. This is interesting because it gives us an idea of what Earth might have been like too. Fifth, NASA has some ideas to study Venus. They want to send a blimp-like vehicle to float above it. This could help scientists avoid the extreme conditions on the ground. Lastly, even though Venus is challenging, the author suggests that exploring it can help us learn more about space and even ourselves.\n",
        "\n",
        "Overall, the author mentions many facts about Venus being dangerous, but doesn't explain very well why studying it is so important.\"\"\",\n",
        "\n",
        "    \"VAL_20\": \"\"\"People are facinated with the Man on the Moon and the idea of Martians, but most people do not think about life on Venus. Venus is the second planet from the sun and shares many geographical features with Earth. However, studying this planet is made difficult by the dense and toxic atmosphere, high temperatures, and violent weather. Despite this, some people think that Venus should still be explored, and the author of \"The Challenge of Exploring Venus\" is of this opinion. The idea that studying Venus is a worthy pursuit despite the dangers is well supported by the author as seen through the rewards of studying Venus and the progress that has been made towards studying Venus.\n",
        "\n",
        "First, the idea that studying Venus is a worthy pursuit despite the dangers is well supported by the author as seen through the many rewards of studying Venus. After laying out the dangers of studying Venus, the author explains why scientists continue to study the planet. \"Astronomers are fascinated by Venus because it may well have been the most Earth-like planet in our solar system\" (4). By studying Venus, astronomers and geologists can predict what might happen to Earth in the future. Gaining an understanding of Earth's future may well allow scientists to predict what happened in Earth's past. Scientists are eager to learn about the early years of Earth's past, as it is shrouded in mystery, and this thirst for knowledge motivates them to study Venus. In describing how similar Venus was to Earth, the author says, \"Long ago, Venus was probably covered largely with oceans and could have supported various forms of life\" (4). If there was once life on Venus, the similarity between it and Earth would grow. As with geology, if biologists can understand what caused life to cease on Venus, they might be able to predict how life on Venus and on Earth might have started. The author shows that scientists studying Venus reap the reward of being able to learn about Earth's geology and early life. By laying out the various rewards to be had from studying Venus, the author is strengthening his or her argument that Venus should be studied.\n",
        "\n",
        "Secondly, the idea that studying Venus is a worthy pursuit despite the dangers is well supported by the author as seen through the large amount of progress that has been made towards studying Venus. Although the author describes how Venus could be studied from the air, scientists still desire to learn about Venus from the planet's surface. One of their solutions to the problem of getting equipment to last on the surface of Venus is to expirement with new materials. \"Simplified electronics made of silicon carbide have been tested in a chamber simulating the choas of Venus's surface and have lasted of three weeks in such conditions\" (7). Research and experimentation taking place on Earth is giving scientists and astronauts more options for studying Venus. Although conditions on Venus are not hospitable to life, these new scientific advances are making it possible for data-gathering equipment to be sent to the surface of Venus and last long enough to gather data. Other scientists are moving away from traditional electronics and looking into purely mechanical systems. \"Systems that use mechanical parts can be made more resistant to pressure, heat, and other forces\" (7). The alternative that has presented itself to would-be explorers of Venus is older technology, like that found in the earliest computers. Scientists have realized that modern technology is too fragile and that more durable technologies are needed. By turning to other forms of technology, scientists are widening their options for ways to study Venus. The author mentions three different ways that scientists are making progress towards being able to study Venus - from the air, using new materials, and using old technologies. The author's postion that Venus should continue to be studied is supported by the scientific advancements that are serving to make studying Venus a reality.\n",
        "\n",
        "In conclusion, the author's opinon that Venus should continue to be studied despite the dangers is well supported by the rewards of studying another Earth-like planet and the advancements that have been made towards being able to effectively study Venus. Scientists have strong motivation for studying Venus, and new technologies are making it possible for them to overcome the challenges presented by Venus's harsh terrain. Although scientists studying Venus are unlikely to encounter any life forms, what they do discover will help them to understand Earth's past and shape our future.\"\"\",\n",
        "\n",
        "    \"VAL_25\": \"\"\"In \"the challenge of exploring venus ,\" the author suggests that studying venus is a worthy pursuit\n",
        "\n",
        "despite the dangers it presents . becauce in the text it says at paragraph eight\n",
        "\n",
        "\"striving to meet challenge presented by venus has value , not only because of the insight to be gained on the planet itself , but also becauce human curiosity will likely lwad us into many equally intimdating endeavors .\" this proves that we should try to get to mars .\n",
        "\n",
        "there is even more evidence . In paragraph four it says \" Astronomers are fascinated by venus because it may well once beeen\n",
        "\n",
        "the most earth like planet in are solar sytem . \" this just further shows the imense reasearch value .\n",
        "\n",
        "theres even more prove . in the artical at paragraph 2 it says \" often referred to as Earths \"twin,\"Venus is the closest planet to earth in terms of denisty and sise , and occasionally the closest in distance too. \" showing are planets similer history .\n",
        "\n",
        "in conclusion all this eveidince points to even though it will be hard we show try to reasearch venus more .\"\"\"\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# GROUND TRUTH SCORES - YOUR Day 1 Scores\n",
        "# =============================================================================\n",
        "\n",
        "GROUND_TRUTH = {\n",
        "    \"VAL_02\": {\"completeness\": 4, \"accuracy\": 4, \"coherence\": 3, \"conciseness\": 3},  # Authentic - repetitive, errors\n",
        "    \"VAL_04\": {\"completeness\": 4, \"accuracy\": 4, \"coherence\": 4, \"conciseness\": 3},  # Authentic - analytical, well-structured\n",
        "    \"VAL_15\": {\"completeness\": 3, \"accuracy\": 4, \"coherence\": 4, \"conciseness\": 4},  # Synthetic - list-style, moderate\n",
        "    \"VAL_20\": {\"completeness\": 4, \"accuracy\": 5, \"coherence\": 4, \"conciseness\": 2},  # Authentic - formal essay, lengthy\n",
        "    \"VAL_25\": {\"completeness\": 2, \"accuracy\": 3, \"coherence\": 3, \"conciseness\": 3},  # Authentic - short, spelling errors\n",
        "}\n",
        "\n",
        "# Quick validation\n",
        "print(\"=\" * 60)\n",
        "print(\"TEST SUMMARIES LOADED\")\n",
        "print(\"=\" * 60)\n",
        "for sid, text in TEST_SUMMARIES.items():\n",
        "    word_count = len(text.split())\n",
        "    print(f\"{sid}: {word_count} words\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚úÖ GROUND_TRUTH scores loaded from your Day 1 spreadsheet!\")\n",
        "print(\"   Source: Summary_Scoring_Template.xlsx - Main Scoring sheet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz8D8VbnIDAd",
        "outputId": "7a10f654-112e-40fe-9419-254433697f2a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TEST SUMMARIES LOADED\n",
            "============================================================\n",
            "VAL_02: 499 words\n",
            "VAL_04: 732 words\n",
            "VAL_15: 191 words\n",
            "VAL_20: 753 words\n",
            "VAL_25: 193 words\n",
            "============================================================\n",
            "\n",
            "‚úÖ GROUND_TRUTH scores loaded from your Day 1 spreadsheet!\n",
            "   Source: Summary_Scoring_Template.xlsx - Main Scoring sheet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"RUNNING EVALUATIONS ON 5 TEST SUMMARIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for summary_id, summary_text in TEST_SUMMARIES.items():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating: {summary_id}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"\\nSummary preview: {summary_text[:150]}...\")\n",
        "\n",
        "    # Use the full CoT prompt\n",
        "    prompt = create_evaluation_prompt(summary_text)\n",
        "\n",
        "    print(\"\\nGenerating evaluation...\")\n",
        "    response = generate_evaluation(prompt)\n",
        "\n",
        "    # Parse scores\n",
        "    scores = parse_scores(response)\n",
        "    results[summary_id] = {\n",
        "        'llm_scores': scores,\n",
        "        'ground_truth': GROUND_TRUTH.get(summary_id, {}),\n",
        "        'response': response\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- LLM SCORES ---\")\n",
        "    for dim, score in scores.items():\n",
        "        gt = GROUND_TRUTH.get(summary_id, {}).get(dim, \"N/A\")\n",
        "        match = \"‚úì\" if score == gt else \"‚óã\" if score and gt and abs(score - gt) == 1 else \"‚úó\"\n",
        "        print(f\"  {dim.capitalize()}: LLM={score} | Ground Truth={gt} {match}\")\n",
        "\n",
        "    print(f\"\\n--- FULL RESPONSE ---\")\n",
        "    print(response[:1500] + \"...\" if len(response) > 1500 else response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCWa-YYaIOOB",
        "outputId": "d9db8bee-d89d-4e3f-f2e1-7c3c756654d7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "RUNNING EVALUATIONS ON 5 TEST SUMMARIES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Evaluating: VAL_02\n",
            "======================================================================\n",
            "\n",
            "Summary preview: Do you guys think that venus is dangers? Well for our part venus need to get up close and personal despite the risk or maybe they should think of them...\n",
            "\n",
            "Generating evaluation...\n",
            "\n",
            "--- LLM SCORES ---\n",
            "  Completeness: LLM=2 | Ground Truth=4 ‚úó\n",
            "  Accuracy: LLM=2 | Ground Truth=4 ‚úó\n",
            "  Coherence: LLM=2 | Ground Truth=3 ‚óã\n",
            "  Conciseness: LLM=1 | Ground Truth=3 ‚úó\n",
            "\n",
            "--- FULL RESPONSE ---\n",
            "COMPLETENESS: 2\n",
            "Justification: The student identifies some of the main supporting points, such as the extreme conditions on Venus and the scientific value of studying the planet. However, they miss crucial aspects like NASA's solutions and alternative technologies, and their discussion is disjointed and lacks a clear structure.\n",
            "\n",
            "### ACCURACY: 2\n",
            "Justification: The student makes several factual errors, such as stating that Venus is \"simple to see from the distant but safe vantage point of earth\" (the text actually says it's \"simple for even an amateur stargazer to spot\"), and misrepresents the NASA solution as a blimp-like vehicle (the text describes it as a vehicle hovering 30 miles above the surface). Additionally, the student's paraphrasing of the text is often inaccurate.\n",
            "\n",
            "### COHERENCE: 2\n",
            "Justification: The student's response lacks a clear introduction and conclusion, and the paragraphs/sentences do not connect logically. The writing jumps between ideas and lacks effective transitions.\n",
            "\n",
            "### CONCISENESS: 1\n",
            "Justification: The response is excessively wordy, with many sentences repeating the same ideas and including irrelevant information. The student could significantly shorten the response without losing meaning.\n",
            "\n",
            "### OVERALL FEEDBACK:\n",
            "This response demonstrates a good effort to engage with the text, but it falls short in several areas. To improve, focus on accurately representing the author's argument, organizing your ideas clearly, and using concise language. Remember to a...\n",
            "\n",
            "======================================================================\n",
            "Evaluating: VAL_04\n",
            "======================================================================\n",
            "\n",
            "Summary preview: The author excellently supports the idea that even though it is dangerous, Venus is worth exploring. You can tell the author supports the idea of furt...\n",
            "\n",
            "Generating evaluation...\n",
            "\n",
            "--- LLM SCORES ---\n",
            "  Completeness: LLM=4 | Ground Truth=4 ‚úì\n",
            "  Accuracy: LLM=4 | Ground Truth=4 ‚úì\n",
            "  Coherence: LLM=4 | Ground Truth=4 ‚úì\n",
            "  Conciseness: LLM=3 | Ground Truth=3 ‚úì\n",
            "\n",
            "--- FULL RESPONSE ---\n",
            "COMPLETENESS: 4\n",
            "Justification: The student identifies most major supporting points, including extreme conditions, scientific value, NASA's solutions, and alternative technologies. However, they miss the point about the importance of understanding the planet's geology and weather, which is mentioned in paragraph 5.\n",
            "\n",
            "### ACCURACY: 4\n",
            "Justification: The student's factual claims are generally accurate, but there are some minor imprecisions. For example, they state that temperatures on Venus are \"toasty at around 170 degrees Fahrenheit\" when the text says \"temperatures average over 800 degrees Fahrenheit.\" Additionally, the student quotes the text accurately, but sometimes paraphrases it in a way that slightly alters the original meaning.\n",
            "\n",
            "### COHERENCE: 4\n",
            "Justification: The student's ideas flow logically, and they use some effective transitions. However, the paragraphs sometimes jump between topics, and the connections between ideas could be more explicit.\n",
            "\n",
            "### CONCISENESS: 3\n",
            "Justification: The student's response is mostly efficient, but there is some noticeable wordiness and repetition. Some sentences could be condensed without losing meaning.\n",
            "\n",
            "### OVERALL FEEDBACK:\n",
            "The student demonstrates a good understanding of the article and the author's argument. To improve, focus on including all major supporting points, refining your paraphrasing to maintain the original meaning, and streamlining your writing to eliminate unnecessary repetition.\n",
            "\n",
            "======================================================================\n",
            "Evaluating: VAL_15\n",
            "======================================================================\n",
            "\n",
            "Summary preview: In \"The Challenge of Exploring Venus,\" the author talks about why studying Venus is important, even though it is dangerous.\n",
            "\n",
            "First, Venus is really ho...\n",
            "\n",
            "Generating evaluation...\n",
            "\n",
            "--- LLM SCORES ---\n",
            "  Completeness: LLM=3 | Ground Truth=3 ‚úì\n",
            "  Accuracy: LLM=4 | Ground Truth=4 ‚úì\n",
            "  Coherence: LLM=3 | Ground Truth=4 ‚óã\n",
            "  Conciseness: LLM=3 | Ground Truth=4 ‚óã\n",
            "\n",
            "--- FULL RESPONSE ---\n",
            "COMPLETENESS: 3\n",
            "Justification: The student identifies several key points, including extreme conditions on Venus, NASA's blimp solution, and the scientific value of studying Venus. However, the student misses the point about alternative technologies (silicon carbide and mechanical computers) and the author's argument is not fully developed.\n",
            "\n",
            "### ACCURACY: 4\n",
            "Justification: The student's factual claims are generally accurate, but there are some minor imprecisions. For example, the student states that the temperature is \"way hotter than most things on Earth,\" which is a paraphrased but accurate representation of the text. However, the student does not provide precise language or details about the extreme conditions.\n",
            "\n",
            "### COHERENCE: 3\n",
            "Justification: The student's response is somewhat organized, but the ideas jump between topics, and transitions are missing in places. The student starts with a clear introduction but does not provide a clear conclusion.\n",
            "\n",
            "### CONCISENESS: 3\n",
            "Justification: The student's response is mostly efficient, but there is some repetition and wordiness. The student could have condensed the ideas and eliminated unnecessary sentences.\n",
            "\n",
            "### OVERALL FEEDBACK:\n",
            "The student demonstrates a good understanding of the article's main points but could improve by providing a more comprehensive evaluation of the author's argument and supporting evidence. To strengthen the response, the student should focus on developing a clear and logical organization, eliminating repetition,...\n",
            "\n",
            "======================================================================\n",
            "Evaluating: VAL_20\n",
            "======================================================================\n",
            "\n",
            "Summary preview: People are facinated with the Man on the Moon and the idea of Martians, but most people do not think about life on Venus. Venus is the second planet f...\n",
            "\n",
            "Generating evaluation...\n",
            "\n",
            "--- LLM SCORES ---\n",
            "  Completeness: LLM=4 | Ground Truth=4 ‚úì\n",
            "  Accuracy: LLM=4 | Ground Truth=5 ‚óã\n",
            "  Coherence: LLM=4 | Ground Truth=4 ‚úì\n",
            "  Conciseness: LLM=3 | Ground Truth=2 ‚óã\n",
            "\n",
            "--- FULL RESPONSE ---\n",
            "COMPLETENESS: 4\n",
            "Justification: The student identifies most major points, including extreme conditions, scientific value, NASA's solutions, and alternative technologies, but misses the crucial aspect of the author's argument that studying Venus is a worthy pursuit because it may have once supported life. The student mentions the author's statement about Venus being Earth-like, but doesn't fully develop this point.\n",
            "\n",
            "### ACCURACY: 4\n",
            "Justification: The student's factual claims are generally accurate, but there are minor imprecisions. For example, the student states that Venus is the second planet from the sun, which is incorrect (Mercury is the closest planet to the sun). Additionally, the student paraphrases the author's text without always maintaining the original meaning.\n",
            "\n",
            "### COHERENCE: 4\n",
            "Justification: The student's ideas are clearly organized, and transitions are mostly effective. However, the response jumps between discussing the rewards of studying Venus and the progress made towards studying the planet, which creates a slight disconnect.\n",
            "\n",
            "### CONCISENESS: 3\n",
            "Justification: The student's response is mostly efficient, but there is noticeable wordiness and some repetition. The student could have condensed the ideas and eliminated unnecessary phrases to make the response more concise.\n",
            "\n",
            "### OVERALL FEEDBACK:\n",
            "The student demonstrates a good understanding of the author's argument and provides some strong evidence to support their evaluation. However, there are areas for improvem...\n",
            "\n",
            "======================================================================\n",
            "Evaluating: VAL_25\n",
            "======================================================================\n",
            "\n",
            "Summary preview: In \"the challenge of exploring venus ,\" the author suggests that studying venus is a worthy pursuit\n",
            "\n",
            "despite the dangers it presents . becauce in the ...\n",
            "\n",
            "Generating evaluation...\n",
            "\n",
            "--- LLM SCORES ---\n",
            "  Completeness: LLM=2 | Ground Truth=2 ‚úì\n",
            "  Accuracy: LLM=2 | Ground Truth=3 ‚óã\n",
            "  Coherence: LLM=2 | Ground Truth=3 ‚óã\n",
            "  Conciseness: LLM=2 | Ground Truth=3 ‚óã\n",
            "\n",
            "--- FULL RESPONSE ---\n",
            "COMPLETENESS: 2\n",
            "Justification: The student identifies some major points, such as the extreme conditions on Venus and the scientific value, but misses crucial aspects like NASA's solutions and alternative technologies. The response lacks a clear discussion of the author's main supporting points, particularly the NASA solutions and the value of studying Venus despite the dangers.\n",
            "\n",
            "### ACCURACY: 2\n",
            "Justification: The student contains multiple significant factual errors or misrepresentations. For example, the student claims that the article suggests studying Venus is a worthy pursuit because it will lead to studying Mars, which is not supported by the text. Additionally, the student misrepresents the author's argument by stating that the article says \"striving to meet the challenge presented by Venus has value, not only because of the insight to be gained on the planet itself, but also because human curiosity will likely lead us into many equally intimidating endeavors\" to prove that we should try to get to Mars. This is a misquote and misinterpretation of the text.\n",
            "\n",
            "### COHERENCE: 2\n",
            "Justification: The organization is unclear, and ideas jump between topics. The student jumps between discussing the scientific value of Venus and the NASA solutions without a clear transition. The response lacks a clear introduction and conclusion, making it difficult to follow the student's train of thought.\n",
            "\n",
            "### CONCISENESS: 2\n",
            "Justification: The response is wordy, with unnecessary repetition and tan...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AGREEMENT ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "dimensions = ['completeness', 'accuracy', 'coherence', 'conciseness']\n",
        "\n",
        "# Calculate agreements\n",
        "exact_matches = {dim: 0 for dim in dimensions}\n",
        "adjacent_matches = {dim: 0 for dim in dimensions}  # Within 1 point\n",
        "total_valid = {dim: 0 for dim in dimensions}\n",
        "\n",
        "for summary_id, data in results.items():\n",
        "    llm = data['llm_scores']\n",
        "    gt = data['ground_truth']\n",
        "\n",
        "    for dim in dimensions:\n",
        "        if llm.get(dim) is not None and gt.get(dim) is not None:\n",
        "            total_valid[dim] += 1\n",
        "            diff = abs(llm[dim] - gt[dim])\n",
        "            if diff == 0:\n",
        "                exact_matches[dim] += 1\n",
        "                adjacent_matches[dim] += 1\n",
        "            elif diff == 1:\n",
        "                adjacent_matches[dim] += 1\n",
        "\n",
        "print(\"\\n### AGREEMENT BY DIMENSION ###\\n\")\n",
        "print(f\"{'Dimension':<15} {'Exact':<15} {'Adjacent (¬±1)':<15}\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for dim in dimensions:\n",
        "    n = total_valid[dim]\n",
        "    if n > 0:\n",
        "        exact_pct = (exact_matches[dim] / n) * 100\n",
        "        adj_pct = (adjacent_matches[dim] / n) * 100\n",
        "        print(f\"{dim.capitalize():<15} {exact_pct:>5.1f}% ({exact_matches[dim]}/{n})   {adj_pct:>5.1f}% ({adjacent_matches[dim]}/{n})\")\n",
        "    else:\n",
        "        print(f\"{dim.capitalize():<15} No valid comparisons\")\n",
        "\n",
        "# Overall\n",
        "total_exact = sum(exact_matches.values())\n",
        "total_adjacent = sum(adjacent_matches.values())\n",
        "total_n = sum(total_valid.values())\n",
        "\n",
        "print(\"-\" * 45)\n",
        "if total_n > 0:\n",
        "    print(f\"{'OVERALL':<15} {(total_exact/total_n)*100:>5.1f}% ({total_exact}/{total_n})   {(total_adjacent/total_n)*100:>5.1f}% ({total_adjacent}/{total_n})\")\n",
        "\n",
        "print(\"\\n### INTERPRETATION ###\")\n",
        "print(\"- Exact match: LLM score equals your ground truth score\")\n",
        "print(\"- Adjacent match: LLM score is within ¬±1 of ground truth\")\n",
        "print(\"- Target: Adjacent agreement ‚â•85% indicates good calibration\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdK0PZjfQMaC",
        "outputId": "a18668a2-a9fc-4ffe-e6eb-90fee59a5e4c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "AGREEMENT ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "### AGREEMENT BY DIMENSION ###\n",
            "\n",
            "Dimension       Exact           Adjacent (¬±1)  \n",
            "---------------------------------------------\n",
            "Completeness     80.0% (4/5)    80.0% (4/5)\n",
            "Accuracy         40.0% (2/5)    80.0% (4/5)\n",
            "Coherence        40.0% (2/5)   100.0% (5/5)\n",
            "Conciseness      20.0% (1/5)    80.0% (4/5)\n",
            "---------------------------------------------\n",
            "OVERALL          45.0% (9/20)    85.0% (17/20)\n",
            "\n",
            "### INTERPRETATION ###\n",
            "- Exact match: LLM score equals your ground truth score\n",
            "- Adjacent match: LLM score is within ¬±1 of ground truth\n",
            "- Target: Adjacent agreement ‚â•85% indicates good calibration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING SIMPLE PROMPT VARIATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Pick one summary to test both prompts\n",
        "test_id = \"VAL_04\"\n",
        "test_summary = TEST_SUMMARIES[test_id]\n",
        "\n",
        "print(f\"\\nTesting on: {test_id}\")\n",
        "\n",
        "# Full CoT prompt (already done above)\n",
        "full_scores = results[test_id]['llm_scores']\n",
        "\n",
        "# Simple prompt\n",
        "simple_prompt = create_simple_prompt(test_summary)\n",
        "print(\"\\nGenerating with SIMPLE prompt...\")\n",
        "simple_response = generate_evaluation(simple_prompt, max_new_tokens=400)\n",
        "simple_scores = parse_scores(simple_response)\n",
        "\n",
        "print(\"\\n### PROMPT COMPARISON ###\")\n",
        "print(f\"\\n{'Dimension':<15} {'Full CoT':<12} {'Simple':<12} {'Ground Truth':<12}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for dim in dimensions:\n",
        "    full = full_scores.get(dim, \"N/A\")\n",
        "    simp = simple_scores.get(dim, \"N/A\")\n",
        "    gt = GROUND_TRUTH[test_id].get(dim, \"N/A\")\n",
        "    print(f\"{dim.capitalize():<15} {str(full):<12} {str(simp):<12} {str(gt):<12}\")\n",
        "\n",
        "print(\"\\n### SIMPLE PROMPT RESPONSE ###\")\n",
        "print(simple_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBYcotkISpbY",
        "outputId": "4412d957-5482-43bd-e6c4-3ac6cbf404b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING SIMPLE PROMPT VARIATION\n",
            "======================================================================\n",
            "\n",
            "Testing on: VAL_04\n",
            "\n",
            "Generating with SIMPLE prompt...\n",
            "\n",
            "### PROMPT COMPARISON ###\n",
            "\n",
            "Dimension       Full CoT     Simple       Ground Truth\n",
            "-------------------------------------------------------\n",
            "Completeness    4            4            4           \n",
            "Accuracy        4            5            4           \n",
            "Coherence       4            4            4           \n",
            "Conciseness     3            3            3           \n",
            "\n",
            "### SIMPLE PROMPT RESPONSE ###\n",
            "COMPLETENESS: 4\n",
            "The student provides a good overview of the article's main points, but could have delved deeper into the supporting details.\n",
            "\n",
            "ACCURACY: 5\n",
            "The student accurately summarizes the article's content, including specific quotes and facts.\n",
            "\n",
            "COHERENCE: 4\n",
            "The essay is well-organized, but could benefit from a clearer introduction and conclusion to frame the discussion.\n",
            "\n",
            "CONCISENESS: 3\n",
            "The student could have condensed the essay by eliminating some repetitive phrases and focusing on the most essential points.\n",
            "\n",
            "BRIEF FEEDBACK: The student demonstrates a good understanding of the article's main ideas, but could improve by providing more nuanced analysis and critique of the author's arguments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Create results DataFrame\n",
        "rows = []\n",
        "for summary_id, data in results.items():\n",
        "    row = {'summary_id': summary_id}\n",
        "    for dim in dimensions:\n",
        "        row[f'llm_{dim}'] = data['llm_scores'].get(dim)\n",
        "        row[f'gt_{dim}'] = data['ground_truth'].get(dim)\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Save\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
        "output_path = f'/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/LLM_Evaluation_Results/llm_evaluation_results_{timestamp}.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Results saved to: {output_path}\")\n",
        "\n",
        "# Save full responses\n",
        "responses_path = f'/content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/LLM_Responses/llm_responses_{timestamp}.json'\n",
        "with open(responses_path, 'w') as f:\n",
        "    json.dump({k: v['response'] for k, v in results.items()}, f, indent=2)\n",
        "print(f\"Full responses saved to: {responses_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6jdRZHTTDgG",
        "outputId": "026cb56a-316d-460e-c128-23af9f1f7414"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Results saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/LLM_Evaluation_Results/llm_evaluation_results_20251203_0305.csv\n",
            "Full responses saved to: /content/drive/MyDrive/Courses/2025/3_Fall/EDUC_6192_Large_Language_Model_Applications_in_Education/Project/LLM_Responses/llm_responses_20251203_0305.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEMPERATURE EXPERIMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "test_id = \"VAL_04\"\n",
        "test_summary = TEST_SUMMARIES[test_id]\n",
        "prompt = create_evaluation_prompt(test_summary)\n",
        "\n",
        "temperatures = [0.0, 0.1, 0.3]\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\n--- Temperature: {temp} ---\")\n",
        "    response = generate_evaluation(prompt, temperature=temp)\n",
        "    scores = parse_scores(response)\n",
        "    print(f\"Scores: {scores}\")\n",
        "\n",
        "print(\"\\nNOTE: Lower temperature = more deterministic/consistent\")\n",
        "print(\"      Higher temperature = more varied/creative responses\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Next Steps\n",
        "#\n",
        "# 1. **Review the results** - Check which summaries show good agreement\n",
        "# 2. **Identify patterns** - Which dimensions are harder for the LLM?\n",
        "# 3. **Refine the prompt** - Add examples, clarify instructions\n",
        "# 4. **Run on full validation set** - Test all 25 summaries\n",
        "# 5. **Calculate Cohen's Kappa** - Formal inter-rater reliability metric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I-KXKiBvgFv",
        "outputId": "b0917e84-a8ed-43d9-cf35-aba4006efce5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TEMPERATURE EXPERIMENT\n",
            "======================================================================\n",
            "\n",
            "--- Temperature: 0.0 ---\n",
            "Scores: {'completeness': 4, 'accuracy': 4, 'coherence': 4, 'conciseness': 3}\n",
            "\n",
            "--- Temperature: 0.1 ---\n",
            "Scores: {'completeness': 4, 'accuracy': 5, 'coherence': 4, 'conciseness': 3}\n",
            "\n",
            "--- Temperature: 0.3 ---\n",
            "Scores: {'completeness': 4, 'accuracy': 4, 'coherence': 4, 'conciseness': 3}\n",
            "\n",
            "NOTE: Lower temperature = more deterministic/consistent\n",
            "      Higher temperature = more varied/creative responses\n"
          ]
        }
      ]
    }
  ]
}